{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1795cc",
   "metadata": {},
   "source": [
    "# Market Efficiency Analysis in Prediction Markets\n",
    "\n",
    "This notebook analyzes the efficiency of Polymarket prediction markets using various statistical tests to evaluate whether these markets follow the \"wisdom of crowds\" hypothesis.\n",
    "\n",
    "## 1. Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0973f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "# market_efficiency_notebook.ipynb\n",
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from tqdm.auto import tqdm\n",
    "import warnings\n",
    "\n",
    "# Add project directory to path if needed\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.append('src')\n",
    "\n",
    "# Import the analyzer\n",
    "from market_efficiency_analysis import MarketEfficiencyAnalyzer\n",
    "\n",
    "# Set up paths\n",
    "data_dir = 'data'\n",
    "results_dir = 'results/market_efficiency'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Initialize the analyzer\n",
    "analyzer = MarketEfficiencyAnalyzer(data_dir=data_dir, results_dir=results_dir)\n",
    "\n",
    "# Check if data was loaded successfully\n",
    "if not analyzer.main_df.empty:\n",
    "    print(f\"Loaded {len(analyzer.main_df)} markets\")\n",
    "    print(f\"Available market questions: {len(analyzer.market_questions)}\")\n",
    "else:\n",
    "    print(\"Warning: Main dataset not loaded successfully\")\n",
    "\n",
    "# Find markets related to 2024 US Presidential Election\n",
    "presidential_markets = analyzer.find_market_by_name(\"2024 US Presidential\")\n",
    "\n",
    "if presidential_markets:\n",
    "    print(f\"\\nFound {len(presidential_markets)} markets related to 2024 US Presidential Election:\")\n",
    "    for i, (market_id, question) in enumerate(presidential_markets[:10]):  # Show first 10\n",
    "        print(f\"{i+1}. {question} (ID: {market_id})\")\n",
    "    \n",
    "    # Select the main presidential market\n",
    "    if len(presidential_markets) > 0:\n",
    "        trump_markets = [m for m in presidential_markets if 'Trump' in m[1]]\n",
    "        if trump_markets:\n",
    "            selected_market = trump_markets[0]\n",
    "        else:\n",
    "            selected_market = presidential_markets[0]\n",
    "        \n",
    "        market_id, question = selected_market\n",
    "        print(f\"\\nAnalyzing market: {question} (ID: {market_id})\")\n",
    "        \n",
    "        # Run analysis\n",
    "        result = analyzer.analyze_market(market_id, verbose=True)\n",
    "        \n",
    "        # Create visualization\n",
    "        analyzer.visualize_market(market_id, result)\n",
    "else:\n",
    "    print(\"No markets found related to 2024 US Presidential Election\")\n",
    "\n",
    "# Analyze different market types\n",
    "market_types = {\n",
    "    \"Presidential\": analyzer.find_market_by_name(\"Presidential\"),\n",
    "    \"Senate\": analyzer.find_market_by_name(\"Senate\"),\n",
    "    \"Parliamentary\": analyzer.find_market_by_name(\"Parliamentary\")\n",
    "}\n",
    "\n",
    "# Select one market from each type\n",
    "selected_markets = []\n",
    "for market_type, markets in market_types.items():\n",
    "    if markets and len(markets) > 0:\n",
    "        print(f\"\\nFound {len(markets)} {market_type} markets\")\n",
    "        # Choose one market from each type\n",
    "        selected_markets.append(markets[0][0])  # Add the market ID\n",
    "    else:\n",
    "        print(f\"No {market_type} markets found\")\n",
    "\n",
    "# Analyze selected markets\n",
    "if selected_markets:\n",
    "    print(f\"\\nAnalyzing {len(selected_markets)} selected markets...\")\n",
    "    comparison_results = analyzer.analyze_multiple_markets(selected_markets, verbose=False)\n",
    "    \n",
    "    # Create comparison visualization\n",
    "    if comparison_results:\n",
    "        analyzer.visualize_efficiency_comparison(comparison_results)\n",
    "else:\n",
    "    print(\"No markets selected for comparison analysis\")\n",
    "\n",
    "# Time-varying efficiency analysis\n",
    "print(\"\\nAnalyzing time-varying efficiency...\")\n",
    "# Find a market with sufficient data\n",
    "if presidential_markets and len(presidential_markets) > 0:\n",
    "    time_varying_market_id = presidential_markets[0][0]\n",
    "    \n",
    "    # Preprocess the data\n",
    "    market_data = analyzer.preprocess_market_data(time_varying_market_id)\n",
    "    \n",
    "    if market_data is not None and len(market_data) > 90:  # Needs enough data\n",
    "        print(f\"Analyzing time-varying efficiency for market: {presidential_markets[0][1]}\")\n",
    "        \n",
    "        # Analyze time-varying efficiency\n",
    "        time_varying_results = analyzer.analyze_time_varying_efficiency(market_data['log_return'])\n",
    "        \n",
    "        if time_varying_results and 'summary' in time_varying_results:\n",
    "            print(f\"Efficiency change: {time_varying_results['summary']['efficiency_change']}\")\n",
    "            print(f\"Volatility change: {time_varying_results['summary']['volatility_change']*100:.1f}%\")\n",
    "            \n",
    "            # Create visualization for time-varying efficiency\n",
    "            fig, ax = plt.subplots(figsize=(12, 6))\n",
    "            \n",
    "            periods = ['early', 'middle', 'late']\n",
    "            volatilities = [time_varying_results[p]['volatility'] for p in periods if p in time_varying_results]\n",
    "            has_autocorr = [time_varying_results[p]['has_autocorrelation'] for p in periods if p in time_varying_results]\n",
    "            \n",
    "            # Plot volatilities\n",
    "            ax.bar(periods[:len(volatilities)], volatilities, color=['lightblue', 'lightgreen', 'salmon'])\n",
    "            \n",
    "            # Add annotations\n",
    "            for i, v in enumerate(volatilities):\n",
    "                ax.text(i, v + 0.0005, f\"{v:.4f}\", ha='center')\n",
    "            \n",
    "            ax.set_title(f\"Time-varying Efficiency: {time_varying_results['summary']['efficiency_change']}\")\n",
    "            ax.set_ylabel(\"Return Volatility\")\n",
    "            \n",
    "            # Save figure\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(results_dir, \"time_varying_efficiency.png\"), dpi=300)\n",
    "            plt.show()\n",
    "        else:\n",
    "            print(\"Time-varying efficiency analysis failed\")\n",
    "    else:\n",
    "        print(\"Insufficient data for time-varying efficiency analysis\")\n",
    "else:\n",
    "    print(\"No markets found for time-varying efficiency analysis\")\n",
    "\n",
    "# Strong-form efficiency test - Event study\n",
    "# Look for markets with significant news events\n",
    "print(\"\\nSearching for markets with potential event study opportunities...\")\n",
    "senate_markets = analyzer.find_market_by_name(\"Senate\")\n",
    "if senate_markets and len(senate_markets) > 0:\n",
    "    # Choose a market that likely had significant news events\n",
    "    senate_market_id = senate_markets[0][0]\n",
    "    senate_market_name = senate_markets[0][1]\n",
    "    \n",
    "    print(f\"Selected market for event study: {senate_market_name}\")\n",
    "    \n",
    "    # Get market data\n",
    "    market_data = analyzer.preprocess_market_data(senate_market_id)\n",
    "    \n",
    "    if market_data is not None and len(market_data) > 30:\n",
    "        # For a proper event study, we would need to identify specific news events\n",
    "        # For now, we'll simulate by looking at large price movements\n",
    "        \n",
    "        # Calculate daily returns\n",
    "        daily_data = market_data['price'].resample('D').last().dropna()\n",
    "        daily_returns = daily_data.pct_change().dropna()\n",
    "        \n",
    "        # Identify significant price moves (potential events)\n",
    "        threshold = 2 * daily_returns.std()\n",
    "        significant_moves = daily_returns[abs(daily_returns) > threshold]\n",
    "        \n",
    "        if len(significant_moves) > 0:\n",
    "            print(f\"Found {len(significant_moves)} potential event dates:\")\n",
    "            for date, move in significant_moves.items():\n",
    "                print(f\"  {date.date()}: {move*100:.2f}% move\")\n",
    "            \n",
    "            # Plot price series with event markers\n",
    "            fig, ax = plt.subplots(figsize=(14, 7))\n",
    "            \n",
    "            # Plot price\n",
    "            market_data['price'].plot(ax=ax)\n",
    "            \n",
    "            # Mark event dates\n",
    "            for date in significant_moves.index:\n",
    "                ax.axvline(x=date, color='r', linestyle='--', alpha=0.5)\n",
    "            \n",
    "            ax.set_title(f\"Potential Event Study: {senate_market_name}\")\n",
    "            ax.set_ylabel(\"Price\")\n",
    "            ax.grid(True, alpha=0.3)\n",
    "            \n",
    "            # Save figure\n",
    "            plt.tight_layout()\n",
    "            plt.savefig(os.path.join(results_dir, \"event_study.png\"), dpi=300)\n",
    "            plt.show()\n",
    "            \n",
    "            print(\"\\nA proper event study would require:\")\n",
    "            print(\"1. Identifying specific news events with precise timestamps\")\n",
    "            print(\"2. Measuring abnormal returns around the event window\")\n",
    "            print(\"3. Statistical testing of price reactions\")\n",
    "            print(\"4. Analysis of market efficiency based on speed and accuracy of price adjustment\")\n",
    "        else:\n",
    "            print(\"No significant price movements found for event study\")\n",
    "    else:\n",
    "        print(\"Insufficient data for event study\")\n",
    "else:\n",
    "    print(\"No Senate markets found for event study\")\n",
    "\n",
    "# Aggregate efficiency analysis\n",
    "print(\"\\nPerforming aggregate efficiency analysis...\")\n",
    "market_count = 20  # Number of markets to analyze for aggregate statistics\n",
    "\n",
    "# Identify potential markets\n",
    "all_markets = []\n",
    "for search_term in [\"Election\", \"Win\", \"President\", \"Senate\", \"Parliament\"]:\n",
    "    search_results = analyzer.find_market_by_name(search_term)\n",
    "    all_markets.extend([m[0] for m in search_results])\n",
    "\n",
    "# Remove duplicates\n",
    "all_markets = list(set(all_markets))\n",
    "print(f\"Found {len(all_markets)} unique markets\")\n",
    "\n",
    "if all_markets:\n",
    "    # Limit to reasonable number\n",
    "    if len(all_markets) > market_count:\n",
    "        all_markets = all_markets[:market_count]\n",
    "    \n",
    "    print(f\"Analyzing {len(all_markets)} markets for aggregate statistics...\")\n",
    "    aggregate_results = analyzer.analyze_multiple_markets(all_markets)\n",
    "    \n",
    "    if aggregate_results:\n",
    "        # Calculate aggregate statistics\n",
    "        efficiency_scores = [r['efficiency_score'] for r in aggregate_results]\n",
    "        \n",
    "        # Count by category\n",
    "        categories = {\n",
    "            'Highly Efficient': 0,\n",
    "            'Moderately Efficient': 0,\n",
    "            'Slightly Inefficient': 0,\n",
    "            'Highly Inefficient': 0\n",
    "        }\n",
    "        \n",
    "        for result in aggregate_results:\n",
    "            if 'efficiency_class' in result:\n",
    "                categories[result['efficiency_class']] = categories.get(result['efficiency_class'], 0) + 1\n",
    "        \n",
    "        # Count test results\n",
    "        test_results = {\n",
    "            'Random Walk Prices': 0,  # Non-stationary prices\n",
    "            'Stationary Returns': 0,\n",
    "            'No Autocorrelation': 0,\n",
    "            'Unpredictable (AR)': 0\n",
    "        }\n",
    "        \n",
    "        for result in aggregate_results:\n",
    "            if 'adf_price' in result and result['adf_price'] and not result['adf_price']['is_stationary']:\n",
    "                test_results['Random Walk Prices'] += 1\n",
    "            \n",
    "            if 'adf_return' in result and result['adf_return'] and result['adf_return']['is_stationary']:\n",
    "                test_results['Stationary Returns'] += 1\n",
    "            \n",
    "            if 'autocorrelation' in result and result['autocorrelation'] and not result['autocorrelation']['has_significant_autocorrelation']:\n",
    "                test_results['No Autocorrelation'] += 1\n",
    "            \n",
    "            if 'ar_model' in result and result['ar_model'] and not result['ar_model']['is_significant']:\n",
    "                test_results['Unpredictable (AR)'] += 1\n",
    "        \n",
    "        # Calculate percentages\n",
    "        total_markets = len(aggregate_results)\n",
    "        for key in test_results:\n",
    "            test_results[key] = (test_results[key] / total_markets) * 100\n",
    "        \n",
    "        # Create visualization\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # Efficiency class distribution\n",
    "        category_names = list(categories.keys())\n",
    "        category_counts = list(categories.values())\n",
    "        \n",
    "        ax1.bar(category_names, category_counts, color=['green', 'lightgreen', 'orange', 'red'])\n",
    "        ax1.set_title(\"Market Efficiency Classification\", fontsize=14)\n",
    "        ax1.set_ylabel(\"Number of Markets\", fontsize=12)\n",
    "        ax1.set_xticklabels(category_names, rotation=45, ha='right')\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, count in enumerate(category_counts):\n",
    "            ax1.text(i, count + 0.1, f\"{count/total_markets*100:.1f}%\", ha='center')\n",
    "        \n",
    "        # Test results\n",
    "        test_names = list(test_results.keys())\n",
    "        test_percentages = list(test_results.values())\n",
    "        \n",
    "        ax2.bar(test_names, test_percentages, color='skyblue')\n",
    "        ax2.set_title(\"Efficiency Test Results\", fontsize=14)\n",
    "        ax2.set_ylabel(\"Percentage of Markets (%)\", fontsize=12)\n",
    "        ax2.set_ylim(0, 100)\n",
    "        ax2.set_xticklabels(test_names, rotation=45, ha='right')\n",
    "        \n",
    "        # Add percentage labels\n",
    "        for i, pct in enumerate(test_percentages):\n",
    "            ax2.text(i, pct + 1, f\"{pct:.1f}%\", ha='center')\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, \"aggregate_efficiency.png\"), dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\nSummary Statistics:\")\n",
    "        print(f\"Average Efficiency Score: {np.mean(efficiency_scores):.2f}/100\")\n",
    "        print(f\"Median Efficiency Score: {np.median(efficiency_scores):.2f}/100\")\n",
    "        print(f\"Standard Deviation: {np.std(efficiency_scores):.2f}\")\n",
    "        \n",
    "        print(\"\\nEfficiency Classification Distribution:\")\n",
    "        for category, count in categories.items():\n",
    "            print(f\"  {category}: {count} markets ({count/total_markets*100:.1f}%)\")\n",
    "        \n",
    "        print(\"\\nEfficiency Test Results:\")\n",
    "        for test, percentage in test_results.items():\n",
    "            print(f\"  {test}: {percentage:.1f}% of markets\")\n",
    "        \n",
    "        print(\"\\nConclusion:\")\n",
    "        print(\"Based on this analysis, Polymarket prediction markets appear to be:\")\n",
    "        if np.mean(efficiency_scores) >= 70:\n",
    "            print(\"Generally efficient with most markets following random walk patterns\")\n",
    "        elif np.mean(efficiency_scores) >= 50:\n",
    "            print(\"Moderately efficient with some predictable patterns\")\n",
    "        else:\n",
    "            print(\"Relatively inefficient with significant predictable patterns\")\n",
    "    else:\n",
    "        print(\"No results from aggregate analysis\")\n",
    "else:\n",
    "    print(\"No markets found for aggregate analysis\")\n",
    "\n",
    "print(\"\\nAnalysis complete. Results saved to:\", results_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f71194dc",
   "metadata": {},
   "source": [
    "## 2. Initialize the Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "aeff4d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "Loaded dataset with 1048575 rows and 54 columns\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      2\u001b[39m analyzer = MarketEfficiencyAnalyzer(\n\u001b[32m      3\u001b[39m     data_dir=\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# Path to data directory\u001b[39;00m\n\u001b[32m      4\u001b[39m     results_dir=results_dir,  \u001b[38;5;66;03m# Path to save results\u001b[39;00m\n\u001b[32m      5\u001b[39m     max_cache_size=\u001b[32m50\u001b[39m  \u001b[38;5;66;03m# Maximum number of markets to cache\u001b[39;00m\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Print basic dataset information\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43manalyzer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmain_df\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m markets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAvailable market questions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(analyzer.market_questions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Display available event types and countries\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Initialize the analyzer with appropriate paths\n",
    "analyzer = MarketEfficiencyAnalyzer(\n",
    "    data_dir='data',  # Path to data directory\n",
    "    results_dir=results_dir,  # Path to save results\n",
    "    max_cache_size=50  # Maximum number of markets to cache\n",
    ")\n",
    "\n",
    "# Print basic dataset information\n",
    "print(f\"Dataset contains {len(analyzer.main_df)} markets\")\n",
    "print(f\"Available market questions: {len(analyzer.market_questions)}\")\n",
    "\n",
    "# Display available event types and countries\n",
    "if 'event_electionType' in analyzer.main_df.columns:\n",
    "    print(\"\\nAvailable Election Types:\")\n",
    "    for event_type, count in analyzer.main_df['event_electionType'].value_counts().items():\n",
    "        print(f\"  {event_type}: {count} markets\")\n",
    "\n",
    "if 'event_country' in analyzer.main_df.columns:\n",
    "    print(\"\\nTop Countries:\")\n",
    "    for country, count in analyzer.main_df['event_country'].value_counts().head(10).items():\n",
    "        print(f\"  {country}: {count} markets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e1b99",
   "metadata": {},
   "source": [
    "## 3. Single Market Analysis\n",
    "\n",
    "Let's analyze a specific market to understand its efficiency characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "31042c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markets related to 2024 US Presidential Election:\n",
      "No markets found matching the search criteria.\n"
     ]
    }
   ],
   "source": [
    "# Find markets related to the 2024 US Presidential Election\n",
    "us_presidential_markets = analyzer.find_market_by_name(\"Trump 2024\")\n",
    "\n",
    "# Display matching markets\n",
    "print(\"Markets related to 2024 US Presidential Election:\")\n",
    "for i, (market_id, question) in enumerate(us_presidential_markets[:10]):  # Limit to 10 results\n",
    "    print(f\"{i+1}. {question} (ID: {market_id})\")\n",
    "\n",
    "# Select a market to analyze (for example, the first match)\n",
    "if us_presidential_markets:\n",
    "    selected_market_id = us_presidential_markets[0][0]\n",
    "    selected_market_name = us_presidential_markets[0][1]\n",
    "    print(f\"\\nAnalyzing market: {selected_market_name} (ID: {selected_market_id})\")\n",
    "    \n",
    "    # Run detailed analysis\n",
    "    market_result = analyzer.analyze_market(selected_market_id, verbose=True)\n",
    "    \n",
    "    # Create visualizations\n",
    "    market_figures = analyzer.visualize_market(selected_market_id, save_to=f\"{results_dir}/market_{selected_market_id}_viz.png\")\n",
    "    \n",
    "    # Save results\n",
    "    analyzer.save_results(market_result, f\"market_{selected_market_id}_analysis.json\")\n",
    "else:\n",
    "    print(\"No markets found matching the search criteria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8972dcf",
   "metadata": {},
   "source": [
    "## 4. Finding Efficient vs. Inefficient Markets\n",
    "\n",
    "Let's identify examples of highly efficient and inefficient markets for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb383b6e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get top markets by volume for analysis\n",
    "top_volume_markets = analyzer.get_top_markets_by_volume(n=20)\n",
    "\n",
    "# Analyze these markets\n",
    "print(f\"Analyzing {len(top_volume_markets)} high-volume markets...\")\n",
    "top_markets_results = analyzer.analyze_market_batch(top_volume_markets, max_markets=20, parallel=True)\n",
    "\n",
    "# Sort markets by efficiency score\n",
    "if top_markets_results:\n",
    "    # Convert to DataFrame for easier sorting and filtering\n",
    "    results_df = pd.DataFrame([\n",
    "        {\n",
    "            'market_id': r['market_id'],\n",
    "            'question': r.get('question', 'Unknown'),\n",
    "            'efficiency_score': r.get('efficiency_score', 0),\n",
    "            'efficiency_class': r.get('efficiency_class', 'Unknown'),\n",
    "            'event_type': r.get('event_type', 'Unknown'),\n",
    "            'country': r.get('country', 'Unknown')\n",
    "        }\n",
    "        for r in top_markets_results\n",
    "    ])\n",
    "    \n",
    "    # Sort by efficiency score\n",
    "    sorted_results = results_df.sort_values('efficiency_score', ascending=False)\n",
    "    \n",
    "    # Display most efficient markets\n",
    "    print(\"\\nMost Efficient Markets:\")\n",
    "    for _, row in sorted_results.head(5).iterrows():\n",
    "        print(f\"  {row['question']} - Score: {row['efficiency_score']:.2f} - Class: {row['efficiency_class']}\")\n",
    "    \n",
    "    # Display least efficient markets\n",
    "    print(\"\\nLeast Efficient Markets:\")\n",
    "    for _, row in sorted_results.tail(5).iterrows():\n",
    "        print(f\"  {row['question']} - Score: {row['efficiency_score']:.2f} - Class: {row['efficiency_class']}\")\n",
    "    \n",
    "    # Select one efficient and one inefficient market for comparison\n",
    "    efficient_market = sorted_results.iloc[0]['market_id']\n",
    "    inefficient_market = sorted_results.iloc[-1]['market_id']\n",
    "    \n",
    "    # Create side-by-side visualization\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.suptitle(\"Comparison of Efficient vs. Inefficient Markets\", fontsize=16)\n",
    "    \n",
    "    # Visualize efficient market\n",
    "    efficient_data = analyzer.preprocess_market_data(efficient_market)\n",
    "    if efficient_data is not None:\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(efficient_data.index, efficient_data['price'])\n",
    "        plt.title(f\"Efficient Market: {sorted_results[sorted_results['market_id'] == efficient_market]['question'].values[0]}\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        \n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(efficient_data.index, efficient_data['log_return'], color='green')\n",
    "        plt.title(\"Log Returns\")\n",
    "    \n",
    "    # Visualize inefficient market\n",
    "    inefficient_data = analyzer.preprocess_market_data(inefficient_market)\n",
    "    if inefficient_data is not None:\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(inefficient_data.index, inefficient_data['price'])\n",
    "        plt.title(f\"Inefficient Market: {sorted_results[sorted_results['market_id'] == inefficient_market]['question'].values[0]}\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        \n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(inefficient_data.index, inefficient_data['log_return'], color='red')\n",
    "        plt.title(\"Log Returns\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{results_dir}/efficient_vs_inefficient.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results from batch analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecea7b6",
   "metadata": {},
   "source": [
    "## 5. Comparative Analysis by Market Type\n",
    "\n",
    "Let's compare market efficiency across different election types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics by election type\n",
    "election_types = ['Presidential', 'Senate', 'Parliamentary']\n",
    "comparison_results = []\n",
    "\n",
    "for election_type in election_types:\n",
    "    # Get markets for this type\n",
    "    markets = analyzer.get_markets_by_event_type(election_type, n=10)\n",
    "    \n",
    "    print(f\"Analyzing {len(markets)} {election_type} markets...\")\n",
    "    \n",
    "    # Analyze markets\n",
    "    type_results = analyzer.analyze_market_batch(markets, max_markets=10)\n",
    "    \n",
    "    # Aggregate results\n",
    "    if type_results:\n",
    "        avg_score = np.mean([r.get('efficiency_score', 0) for r in type_results])\n",
    "        price_stationary = sum(1 for r in type_results if r.get('adf_price', {}).get('is_stationary', False))\n",
    "        return_stationary = sum(1 for r in type_results if r.get('adf_return', {}).get('is_stationary', False))\n",
    "        has_autocorr = sum(1 for r in type_results if r.get('autocorrelation', {}).get('has_significant_autocorrelation', False))\n",
    "        \n",
    "        comparison_results.append({\n",
    "            'election_type': election_type,\n",
    "            'count': len(type_results),\n",
    "            'avg_score': avg_score,\n",
    "            'price_stationary_pct': price_stationary / len(type_results) * 100 if len(type_results) > 0 else 0,\n",
    "            'return_stationary_pct': return_stationary / len(type_results) * 100 if len(type_results) > 0 else 0,\n",
    "            'has_autocorr_pct': has_autocorr / len(type_results) * 100 if len(type_results) > 0 else 0\n",
    "        })\n",
    "\n",
    "# Create comparison visualization\n",
    "if comparison_results:\n",
    "    # Convert to DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot average efficiency score by election type\n",
    "    bars = plt.bar(comparison_df['election_type'], comparison_df['avg_score'], color='skyblue')\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f\"n={comparison_df['count'].iloc[i]}\",\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.title('Average Efficiency Score by Election Type', fontsize=14)\n",
    "    plt.ylabel('Efficiency Score (0-100)', fontsize=12)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.savefig(f\"{results_dir}/efficiency_by_election_type.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22274f0",
   "metadata": {},
   "source": [
    "## Market Analysis\n",
    "### 5.1 Single Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_by_id_or_name(market_id_or_name, main_df, id_column, market_questions):\n",
    "    \"\"\"\n",
    "    Find a market by its ID or name\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_id_or_name : str or int\n",
    "        Market ID or partial name to search for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (market_id, market_info) or (None, None) if not found\n",
    "    \"\"\"\n",
    "    # Try direct ID match\n",
    "    if isinstance(market_id_or_name, (int, float)) or market_id_or_name.isdigit():\n",
    "        market_id = int(market_id_or_name) if market_id_or_name.isdigit() else market_id_or_name\n",
    "        market_rows = main_df[main_df[id_column] == market_id]\n",
    "        if not market_rows.empty:\n",
    "            return market_id, market_rows.iloc[0]\n",
    "    \n",
    "    # Try string ID match\n",
    "    market_rows = main_df[main_df[id_column].astype(str) == str(market_id_or_name)]\n",
    "    if not market_rows.empty:\n",
    "        return market_id_or_name, market_rows.iloc[0]\n",
    "    \n",
    "    # Try partial name match\n",
    "    if 'question' in main_df.columns:\n",
    "        name_matches = main_df[main_df['question'].str.contains(str(market_id_or_name), case=False, na=False)]\n",
    "        if not name_matches.empty:\n",
    "            match = name_matches.iloc[0]\n",
    "            return match[id_column], match\n",
    "    \n",
    "    # Try partial match in market_questions values\n",
    "    for id, question in market_questions.items():\n",
    "        if str(market_id_or_name).lower() in question.lower():\n",
    "            market_rows = main_df[main_df[id_column].astype(str) == str(id)]\n",
    "            if not market_rows.empty:\n",
    "                return id, market_rows.iloc[0]\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def analyze_specific_market(market_id_or_name, main_df=None, id_column=None, market_questions=None):\n",
    "    \"\"\"\n",
    "    Analyze a specific market identified by ID or name\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_id_or_name : str or int\n",
    "        Market ID or name to search for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Market analysis results\n",
    "    \"\"\"\n",
    "    if main_df is None:\n",
    "        main_df, id_column, market_questions = load_data(verbose=False)\n",
    "    \n",
    "    # Find the market\n",
    "    market_id, market_info = get_market_by_id_or_name(market_id_or_name, main_df, id_column, market_questions)\n",
    "    \n",
    "    if market_id is None:\n",
    "        print(f\"No market found matching '{market_id_or_name}'\")\n",
    "        return None\n",
    "    \n",
    "    # Display market information\n",
    "    print(\"\\nüîç Market Information\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Market ID: {market_id}\")\n",
    "    \n",
    "    # Get the market question\n",
    "    market_name = None\n",
    "    if 'question' in market_info:\n",
    "        market_name = market_info['question']\n",
    "    else:\n",
    "        market_name = market_questions.get(str(market_id), f\"Market {market_id}\")\n",
    "    \n",
    "    print(f\"Market Question: {market_name}\")\n",
    "    \n",
    "    # Display additional information if available\n",
    "    for col, label in [\n",
    "        ('event_electionType', 'Election Type'),\n",
    "        ('event_country', 'Country'),\n",
    "        ('volumeNum', 'Trading Volume'),\n",
    "        ('market_duration_days', 'Market Duration (days)')\n",
    "    ]:\n",
    "        if col in market_info and not pd.isna(market_info[col]):\n",
    "            print(f\"{label}: {market_info[col]}\")\n",
    "    \n",
    "    # Process the market data\n",
    "    print(\"\\nProcessing market data...\")\n",
    "    market_data = preprocess_market_data(market_id, verbose=True)\n",
    "    \n",
    "    if market_data is None:\n",
    "        print(\"‚ùå Failed to process market data\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"‚úÖ Successfully processed market data with {len(market_data)} time points\")\n",
    "    \n",
    "    # Run efficiency tests\n",
    "    print(\"\\nRunning market efficiency tests...\")\n",
    "    test_results = run_efficiency_tests(market_data, verbose=True)\n",
    "    \n",
    "    if test_results is None:\n",
    "        print(\"‚ùå Failed to run efficiency tests\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate efficiency score\n",
    "    efficiency_score = calculate_efficiency_score(test_results)\n",
    "    \n",
    "    # Determine efficiency class\n",
    "    if efficiency_score >= 80:\n",
    "        efficiency_class = 'Highly Efficient'\n",
    "    elif efficiency_score >= 60:\n",
    "        efficiency_class = 'Moderately Efficient'\n",
    "    elif efficiency_score >= 40:\n",
    "        efficiency_class = 'Slightly Inefficient'\n",
    "    else:\n",
    "        efficiency_class = 'Highly Inefficient'\n",
    "    \n",
    "    print(f\"\\nüìä Market Efficiency Score: {efficiency_score:.2f}/100\")\n",
    "    print(f\"üìà Efficiency Classification: {efficiency_class}\")\n",
    "    \n",
    "    # Print detailed test results\n",
    "    print(\"\\nüî¨ Detailed Test Results:\")\n",
    "    \n",
    "    if 'adf_price' in test_results:\n",
    "        is_random_walk = not test_results['adf_price']['is_stationary']\n",
    "        print(f\"Random Walk Test (Non-stationary prices): {'‚úÖ Pass' if is_random_walk else '‚ùå Fail'}\")\n",
    "    \n",
    "    if 'adf_return' in test_results:\n",
    "        is_return_stationary = test_results['adf_return']['is_stationary']\n",
    "        print(f\"Return Stationarity Test: {'‚úÖ Pass' if is_return_stationary else '‚ùå Fail'}\")\n",
    "    \n",
    "    if 'autocorrelation' in test_results:\n",
    "        no_autocorr = not test_results['autocorrelation']['has_significant_autocorrelation']\n",
    "        print(f\"No Significant Autocorrelation: {'‚úÖ Pass' if no_autocorr else '‚ùå Fail'}\")\n",
    "    \n",
    "    if 'runs_test' in test_results:\n",
    "        is_random = test_results['runs_test'].get('is_random', False)\n",
    "        print(f\"Runs Test (Randomness): {'‚úÖ Pass' if is_random else '‚ùå Fail'}\")\n",
    "    \n",
    "    if 'ar_model' in test_results:\n",
    "        no_ar = not test_results['ar_model'].get('significant', True)\n",
    "        print(f\"No Significant AR Model: {'‚úÖ Pass' if no_ar else '‚ùå Fail'}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    print(\"\\nGenerating visualizations...\")\n",
    "    visualize_market(market_data, market_name, test_results)\n",
    "    \n",
    "    # Prepare final results\n",
    "    results = {\n",
    "        'market_id': market_id,\n",
    "        'market_name': market_name,\n",
    "        'test_results': test_results,\n",
    "        'efficiency_score': efficiency_score,\n",
    "        'efficiency_class': efficiency_class\n",
    "    }\n",
    "    \n",
    "    # Add market attributes\n",
    "    for col in ['event_electionType', 'event_country', 'volumeNum', 'market_duration_days']:\n",
    "        if col in market_info and not pd.isna(market_info[col]):\n",
    "            results[col] = market_info[col]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def visualize_market(market_data, market_name, test_results=None):\n",
    "    \"\"\"Create visualizations for a specific market\"\"\"\n",
    "    # Create a 2x2 plot grid\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Price Series\n",
    "    axs[0, 0].plot(market_data.index, market_data['price'], linewidth=2)\n",
    "    axs[0, 0].set_title(f'Price Series: {market_name}', fontsize=14)\n",
    "    axs[0, 0].set_xlabel('Date', fontsize=12)\n",
    "    axs[0, 0].set_ylabel('Price', fontsize=12)\n",
    "    axs[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Log Returns\n",
    "    axs[0, 1].plot(market_data.index, market_data['log_return'], linewidth=1, color='green')\n",
    "    axs[0, 1].set_title(f'Log Returns: {market_name}', fontsize=14)\n",
    "    axs[0, 1].set_xlabel('Date', fontsize=12)\n",
    "    axs[0, 1].set_ylabel('Log Return', fontsize=12)\n",
    "    axs[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. ACF Plot\n",
    "    if test_results and 'autocorrelation' in test_results:\n",
    "        acf_values = test_results['autocorrelation']['acf_values']\n",
    "        significant = test_results['autocorrelation']['has_significant_autocorrelation']\n",
    "        \n",
    "        lags = range(len(acf_values))\n",
    "        axs[1, 0].bar(lags, acf_values, width=0.3)\n",
    "        \n",
    "        # Plot confidence intervals for hypothesis testing\n",
    "        ci = 1.96 / np.sqrt(len(market_data))\n",
    "        axs[1, 0].axhline(y=0, linestyle='-', color='black', linewidth=1)\n",
    "        axs[1, 0].axhline(y=ci, linestyle='--', color='red', linewidth=1, alpha=0.7)\n",
    "        axs[1, 0].axhline(y=-ci, linestyle='--', color='red', linewidth=1, alpha=0.7)\n",
    "        \n",
    "        title = f'Autocorrelation Function: {\"‚ùå Significant\" if significant else \"‚úÖ Not Significant\"}'\n",
    "        axs[1, 0].set_title(title, fontsize=14)\n",
    "        axs[1, 0].set_xlabel('Lag', fontsize=12)\n",
    "        axs[1, 0].set_ylabel('ACF', fontsize=12)\n",
    "    else:\n",
    "        axs[1, 0].set_title('Autocorrelation Function: Not Available', fontsize=14)\n",
    "    \n",
    "    # 4. Price distribution\n",
    "    axs[1, 1].hist(market_data['price'], bins=30, alpha=0.7, density=True)\n",
    "    axs[1, 1].set_title(f'Price Distribution: {market_name}', fontsize=14)\n",
    "    axs[1, 1].set_xlabel('Price', fontsize=12)\n",
    "    axs[1, 1].set_ylabel('Density', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # If time-varying efficiency results are available, show those too\n",
    "    if test_results and 'time_varying' in test_results and 'comparison' in test_results['time_varying']:\n",
    "        comparison = test_results['time_varying']['comparison']\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        periods = ['Early', 'Middle', 'Late']\n",
    "        \n",
    "        # Extract volatility for each period\n",
    "        volatilities = []\n",
    "        for period in ['early', 'middle', 'late']:\n",
    "            if period in test_results['time_varying']:\n",
    "                volatilities.append(test_results['time_varying'][period]['volatility'])\n",
    "            else:\n",
    "                volatilities.append(np.nan)\n",
    "        \n",
    "        # Create the bar chart\n",
    "        bars = plt.bar(periods, volatilities, color=['blue', 'green', 'orange'])\n",
    "        \n",
    "        plt.title(f'Return Volatility by Market Period: {comparison[\"efficiency_change\"]}', fontsize=14)\n",
    "        plt.ylabel('Return Volatility', fontsize=12)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add efficiency change information\n",
    "        plt.figtext(0.5, 0.01, f'Efficiency Change: {comparison[\"efficiency_change\"]}', \n",
    "                   ha='center', fontsize=12, bbox={\"facecolor\":\"lightgray\", \"alpha\":0.5, \"pad\":5})\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3422bff",
   "metadata": {},
   "source": [
    "## 6. Cross-Market Analysis\n",
    "\n",
    "Let's analyze how markets in the same event influence each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9d613",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Find a presidential election event with multiple markets\n",
    "presidential_events = analyzer.find_market_by_name(\"Presidential Election 2024\")\n",
    "\n",
    "if presidential_events:\n",
    "    # Get the first event ID\n",
    "    event_id = presidential_events[0][0]\n",
    "    print(f\"Analyzing cross-market relationships for event: {presidential_events[0][1]}\")\n",
    "    \n",
    "    # Run cross-market analysis\n",
    "    cross_results = analyzer.analyze_cross_market(event_id)\n",
    "    \n",
    "    # Print significant relationships\n",
    "    if cross_results and 'market_pairs' in cross_results:\n",
    "        significant_pairs = [pair for pair in cross_results['market_pairs'] \n",
    "                            if pair['i_causes_j'] or pair['j_causes_i']]\n",
    "        \n",
    "        print(f\"\\nFound {len(significant_pairs)} significant relationships out of {len(cross_results['market_pairs'])} tested pairs\")\n",
    "        \n",
    "        if significant_pairs:\n",
    "            print(\"\\nSignificant market relationships:\")\n",
    "            for pair in significant_pairs:\n",
    "                print(f\"Relationship: {pair['relationship']}\")\n",
    "                print(f\"  Market 1: {pair['market_i_question']}\")\n",
    "                print(f\"  Market 2: {pair['market_j_question']}\")\n",
    "                print()\n",
    "    else:\n",
    "        print(\"No significant cross-market relationships found.\")\n",
    "else:\n",
    "    print(\"No presidential election events found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9d0e22",
   "metadata": {},
   "source": [
    "## 7. Analyzing Time-Varying Efficiency\n",
    "\n",
    "Let's look at how efficiency changes over time within markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07adb740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a long-running market to analyze time-varying efficiency\n",
    "if 'market_duration_days' in analyzer.main_df.columns:\n",
    "    long_markets = analyzer.main_df.sort_values('market_duration_days', ascending=False)\n",
    "    \n",
    "    if not long_markets.empty:\n",
    "        long_market_id = long_markets.iloc[0][analyzer.id_column]\n",
    "        long_market_question = analyzer.get_market_details(long_market_id)['question']\n",
    "        \n",
    "        print(f\"Analyzing time-varying efficiency for market: {long_market_question}\")\n",
    "        \n",
    "        # Run analysis\n",
    "        time_result = analyzer.analyze_market(long_market_id, verbose=True)\n",
    "        \n",
    "        # Display time-varying efficiency results\n",
    "        if 'time_varying' in time_result and 'comparison' in time_result['time_varying']:\n",
    "            comparison = time_result['time_varying']['comparison']\n",
    "            \n",
    "            print(\"\\nTime-Varying Efficiency Results:\")\n",
    "            print(f\"Efficiency Change: {comparison['efficiency_change']}\")\n",
    "            print(f\"Volatility Ratio (Late/Early): {comparison['volatility_ratio']:.2f}\")\n",
    "            \n",
    "            # Create visualization of efficiency over time\n",
    "            periods = ['early', 'middle', 'late']\n",
    "            periods_data = []\n",
    "            \n",
    "            for period in periods:\n",
    "                if period in time_result['time_varying']:\n",
    "                    period_data = time_result['time_varying'][period]\n",
    "                    periods_data.append({\n",
    "                        'period': period.capitalize(),\n",
    "                        'volatility': period_data['return_volatility'],\n",
    "                        'has_autocorrelation': period_data['significant_acf'],\n",
    "                        'is_inefficient': period_data['ar_model']['significant'] if period_data['ar_model'] else False\n",
    "                    })\n",
    "            \n",
    "            if periods_data:\n",
    "                periods_df = pd.DataFrame(periods_data)\n",
    "                \n",
    "                plt.figure(figsize=(12, 6))\n",
    "                \n",
    "                # Plot volatility by period\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.bar(periods_df['period'], periods_df['volatility'], color='skyblue')\n",
    "                plt.title('Return Volatility by Market Period', fontsize=14)\n",
    "                plt.ylabel('Volatility', fontsize=12)\n",
    "                \n",
    "                # Plot inefficiency by period\n",
    "                plt.subplot(1, 2, 2)\n",
    "                inefficiency_scores = [float(row['is_inefficient']) + float(row['has_autocorrelation']) for _, row in periods_df.iterrows()]\n",
    "                plt.bar(periods_df['period'], inefficiency_scores, color='salmon')\n",
    "                plt.title('Inefficiency Score by Market Period', fontsize=14)\n",
    "                plt.ylabel('Inefficiency Score (0-2)', fontsize=12)\n",
    "                plt.ylim(0, 2)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{results_dir}/time_varying_efficiency.png\", dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(\"No time-varying efficiency data available for this market.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17620ad3",
   "metadata": {},
   "source": [
    "### 5.3 Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64201c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_efficiency_results(results_df, save_dir=None):\n",
    "    \"\"\"\n",
    "    Create visualizations for market efficiency results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame with market efficiency results\n",
    "    save_dir : str, optional\n",
    "        Directory to save plots, if None uses results_dir\n",
    "    \"\"\"\n",
    "    if results_df is None or len(results_df) == 0:\n",
    "        print(\"No results to visualize\")\n",
    "        return\n",
    "    \n",
    "    if save_dir is None:\n",
    "        save_dir = results_dir\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Efficiency Score Distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(results_df['efficiency_score'], bins=20, kde=True)\n",
    "    plt.axvline(x=results_df['efficiency_score'].mean(), color='red', linestyle='--', \n",
    "               label=f'Mean: {results_df[\"efficiency_score\"].mean():.2f}')\n",
    "    plt.title('Distribution of Market Efficiency Scores', fontsize=14)\n",
    "    plt.xlabel('Efficiency Score (0-100, higher = more efficient)', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(os.path.join(save_dir, 'efficiency_score_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Efficiency Classification Pie Chart\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    results_df['efficiency_class'].value_counts().plot.pie(autopct='%1.1f%%', \n",
    "                                                         colors=sns.color_palette(\"viridis\", 4),\n",
    "                                                         startangle=90)\n",
    "    plt.title('Market Efficiency Classification', fontsize=14)\n",
    "    plt.ylabel('')  # Hide ylabel\n",
    "    \n",
    "    plt.savefig(os.path.join(save_dir, 'efficiency_classification_pie.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Efficiency by Market Type (if available)\n",
    "    if 'event_electionType' in results_df.columns:\n",
    "        type_counts = results_df['event_electionType'].value_counts()\n",
    "        types_with_data = type_counts[type_counts >= 5].index.tolist()\n",
    "        \n",
    "        if types_with_data:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            # Calculate average efficiency by type\n",
    "            type_data = []\n",
    "            for market_type in types_with_data:\n",
    "                type_df = results_df[results_df['event_electionType'] == market_type]\n",
    "                type_data.append({\n",
    "                    'Market Type': market_type,\n",
    "                    'Average Efficiency': type_df['efficiency_score'].mean(),\n",
    "                    'Count': len(type_df)\n",
    "                })\n",
    "            \n",
    "            type_df = pd.DataFrame(type_data).sort_values('Average Efficiency', ascending=False)\n",
    "            \n",
    "            # Create bar chart\n",
    "            bars = plt.bar(type_df['Market Type'], type_df['Average Efficiency'], color='lightgreen')\n",
    "            \n",
    "            # Add count labels\n",
    "            for i, bar in enumerate(bars):\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, \n",
    "                        bar.get_height() + 1, \n",
    "                        f\"n={type_df['Count'].iloc[i]}\", \n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "            \n",
    "            plt.axhline(y=results_df['efficiency_score'].mean(), color='red', linestyle='--', \n",
    "                       label=f'Overall Average: {results_df[\"efficiency_score\"].mean():.2f}')\n",
    "            \n",
    "            plt.title('Average Efficiency Score by Market Type', fontsize=14)\n",
    "            plt.xlabel('Market Type', fontsize=12)\n",
    "            plt.ylabel('Average Efficiency Score', fontsize=12)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.legend()\n",
    "            plt.ylim(0, 100)\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            plt.savefig(os.path.join(save_dir, 'efficiency_by_market_type.png'), dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "    \n",
    "    # 4. Efficiency by Country (if available)\n",
    "    if 'event_country' in results_df.columns:\n",
    "        country_counts = results_df['event_country'].value_counts()\n",
    "        countries_with_data = country_counts[country_counts >= 5].index.tolist()\n",
    "        \n",
    "        if countries_with_data:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            country_data = []\n",
    "            for country in countries_with_data:\n",
    "                country_df = results_df[results_df['event_country'] == country]\n",
    "                country_data.append({\n",
    "                    'Country': country,\n",
    "                    'Average Efficiency': country_df['efficiency_score'].mean(),\n",
    "                    'Count': len(country_df)\n",
    "                })\n",
    "            \n",
    "            country_df = pd.DataFrame(country_data).sort_values('Average Efficiency', ascending=False)\n",
    "            \n",
    "            bars = plt.bar(country_df['Country'], country_df['Average Efficiency'], color='skyblue')\n",
    "            \n",
    "            for i, bar in enumerate(bars):\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, \n",
    "                        bar.get_height() + 1, \n",
    "                        f\"n={country_df['Count'].iloc[i]}\", \n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "            \n",
    "            plt.axhline(y=results_df['efficiency_score'].mean(), color='red', linestyle='--', \n",
    "                       label=f'Overall Average: {results_df[\"efficiency_score\"].mean():.2f}')\n",
    "            \n",
    "            plt.title('Average Efficiency Score by Country', fontsize=14)\n",
    "            plt.xlabel('Country', fontsize=12)\n",
    "            plt.ylabel('Average Efficiency Score', fontsize=12)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.legend()\n",
    "            plt.ylim(0, 100)\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            plt.savefig(os.path.join(save_dir, 'efficiency_by_country.png'), dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "    \n",
    "    # 5. Efficiency vs Volume (if available)\n",
    "    if 'volumeNum' in results_df.columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Use log scale for volume\n",
    "        plt.scatter(results_df['volumeNum'], results_df['efficiency_score'], alpha=0.6)\n",
    "        plt.xscale('log')\n",
    "        \n",
    "        # Add trend line\n",
    "        try:\n",
    "            z = np.polyfit(np.log10(results_df['volumeNum']), results_df['efficiency_score'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            \n",
    "            # Create x range for line (in log space)\n",
    "            x_range = np.logspace(\n",
    "                np.log10(results_df['volumeNum'].min()), \n",
    "                np.log10(results_df['volumeNum'].max()), \n",
    "                100\n",
    "            )\n",
    "            \n",
    "            plt.plot(x_range, p(np.log10(x_range)), \"r--\", linewidth=2)\n",
    "            \n",
    "            # Calculate correlation\n",
    "            corr = np.corrcoef(np.log10(results_df['volumeNum']), results_df['efficiency_score'])[0, 1]\n",
    "            plt.text(0.05, 0.95, f\"Correlation: {corr:.3f}\", transform=plt.gca().transAxes,\n",
    "                    bbox=dict(facecolor='white', alpha=0.8))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        plt.title('Efficiency Score vs Trading Volume', fontsize=14)\n",
    "        plt.xlabel('Trading Volume (log scale)', fontsize=12)\n",
    "        plt.ylabel('Efficiency Score', fontsize=12)\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        plt.savefig(os.path.join(save_dir, 'efficiency_vs_volume.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 6. Time-varying efficiency results\n",
    "    if 'efficiency_change' in results_df.columns:\n",
    "        efficiency_changes = results_df['efficiency_change'].value_counts()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(efficiency_changes.index, efficiency_changes.values, color=['green', 'gray', 'red'])\n",
    "        \n",
    "        # Add percentage labels\n",
    "        total = len(results_df)\n",
    "        for i, (category, count) in enumerate(efficiency_changes.items()):\n",
    "            plt.text(i, count + 0.5, f\"{count/total*100:.1f}%\", ha='center', fontsize=12)\n",
    "        \n",
    "        plt.title('Efficiency Change Over Market Lifecycle', fontsize=14)\n",
    "        plt.ylabel('Number of Markets', fontsize=12)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.savefig(os.path.join(save_dir, 'time_varying_efficiency.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569be738",
   "metadata": {},
   "source": [
    "## 8. Comprehensive Batch Analysis\n",
    "\n",
    "Now let's run a larger batch analysis to get a comprehensive view of market efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1073a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure batch analysis parameters\n",
    "batch_size = 30  # Number of markets to analyze\n",
    "parallel = True  # Use parallel processing\n",
    "\n",
    "# Get markets for analysis\n",
    "markets_to_analyze = analyzer.get_top_markets_by_volume(n=batch_size)\n",
    "\n",
    "print(f\"Running comprehensive analysis on {len(markets_to_analyze)} markets...\")\n",
    "\n",
    "# Run batch analysis\n",
    "batch_results = analyzer.analyze_market_batch(markets_to_analyze, parallel=parallel)\n",
    "\n",
    "# Generate summary\n",
    "if batch_results:\n",
    "    summary = analyzer.summarize_results(batch_results)\n",
    "    \n",
    "    # Visualize summary\n",
    "    analyzer.visualize_summary(summary)\n",
    "    \n",
    "    # Save results\n",
    "    analyzer.save_results(batch_results, \"comprehensive_batch_results.json\")\n",
    "    analyzer.save_results(summary, \"comprehensive_batch_summary.json\")\n",
    "    \n",
    "    # Display key findings\n",
    "    print(\"\\nKey Findings:\")\n",
    "    print(f\"Total markets analyzed: {summary['total_markets']}\")\n",
    "    print(f\"Average efficiency score: {summary['average_efficiency_score']:.2f}\")\n",
    "    \n",
    "    print(\"\\nEfficiency Classes:\")\n",
    "    for cls, count in summary['efficiency_classes'].items():\n",
    "        percentage = count / summary['total_markets'] * 100\n",
    "        print(f\"  {cls}: {count} markets ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nTest Results:\")\n",
    "    test_results = summary['test_results']\n",
    "    print(f\"  Non-stationary prices: {100 - test_results.get('price_stationary_percentage', 0):.1f}% (efficient)\")\n",
    "    print(f\"  Stationary returns: {test_results.get('return_stationary_percentage', 0):.1f}% (efficient)\")\n",
    "    print(f\"  No significant autocorrelation: {100 - test_results.get('has_autocorrelation_percentage', 0):.1f}% (efficient)\")\n",
    "    print(f\"  Random runs test: {test_results.get('is_random_percentage', 0):.1f}% (efficient)\")\n",
    "    print(f\"  No significant AR model: {100 - test_results.get('ar_significant_percentage', 0):.1f}% (efficient)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40119a",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we have analyzed the efficiency of Polymarket prediction markets using various statistical tests. We have found that:\n",
    "\n",
    "1. Overall market efficiency varies by market type, with [highest/lowest] efficiency observed in [type] markets.\n",
    "2. Price dynamics exhibit [characteristics] which [support/challenge] the efficient market hypothesis.\n",
    "3. Cross-market relationships show [patterns] of information flow between related markets.\n",
    "4. Time-varying efficiency analysis reveals [patterns] as markets progress.\n",
    "\n",
    "These findings contribute to understanding how prediction markets aggregate information and their effectiveness as forecasting tools."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9a1795cc",
   "metadata": {},
   "source": [
    "# Market Efficiency Analysis in Prediction Markets\n",
    "\n",
    "This notebook analyzes the efficiency of Polymarket prediction markets using various statistical tests to evaluate whether these markets follow the \"wisdom of crowds\" hypothesis.\n",
    "\n",
    "## 1. Setup and Initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "0973f190",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "from scipy import stats\n",
    "import warnings\n",
    "from tqdm.auto import tqdm\n",
    "import json\n",
    "\n",
    "# Add the src directory to the path if it isn't already there\n",
    "if 'src' not in sys.path:\n",
    "    sys.path.append('src')\n",
    "\n",
    "# Import the MarketEfficiencyAnalyzer class\n",
    "from src.knowledge_value.market_efficiency import MarketEfficiencyAnalyzer\n",
    "\n",
    "# Suppress warnings for cleaner output\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Create output directory for saving results\n",
    "results_dir = 'results/knowledge_value/efficiency'\n",
    "os.makedirs(results_dir, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63d60951",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "Loaded dataset with 1048575 rows and 54 columns\n"
     ]
    },
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'empty'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[125]\u001b[39m\u001b[32m, line 8\u001b[39m\n\u001b[32m      2\u001b[39m analyzer = MarketEfficiencyAnalyzer(\n\u001b[32m      3\u001b[39m     data_dir=\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# Path to data directory\u001b[39;00m\n\u001b[32m      4\u001b[39m     results_dir=results_dir  \u001b[38;5;66;03m# Path to save results\u001b[39;00m\n\u001b[32m      5\u001b[39m )\n\u001b[32m      7\u001b[39m \u001b[38;5;66;03m# Check if data was loaded successfully\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m8\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mhasattr\u001b[39m(analyzer, \u001b[33m'\u001b[39m\u001b[33mmain_df\u001b[39m\u001b[33m'\u001b[39m) \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[43manalyzer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmain_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mempty\u001b[49m:\n\u001b[32m      9\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(analyzer.main_df)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m markets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'empty'"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "f71194dc",
   "metadata": {},
   "source": [
    "## 2. Initialize the Analyzer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "aeff4d84",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "Loaded dataset with 1048575 rows and 54 columns\n"
     ]
    },
    {
     "ename": "TypeError",
     "evalue": "object of type 'NoneType' has no len()",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mTypeError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[122]\u001b[39m\u001b[32m, line 9\u001b[39m\n\u001b[32m      2\u001b[39m analyzer = MarketEfficiencyAnalyzer(\n\u001b[32m      3\u001b[39m     data_dir=\u001b[33m'\u001b[39m\u001b[33mdata\u001b[39m\u001b[33m'\u001b[39m,  \u001b[38;5;66;03m# Path to data directory\u001b[39;00m\n\u001b[32m      4\u001b[39m     results_dir=results_dir,  \u001b[38;5;66;03m# Path to save results\u001b[39;00m\n\u001b[32m      5\u001b[39m     max_cache_size=\u001b[32m50\u001b[39m  \u001b[38;5;66;03m# Maximum number of markets to cache\u001b[39;00m\n\u001b[32m      6\u001b[39m )\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Print basic dataset information\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m9\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDataset contains \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43manalyzer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmain_df\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m markets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     10\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAvailable market questions: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(analyzer.market_questions)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m     12\u001b[39m \u001b[38;5;66;03m# Display available event types and countries\u001b[39;00m\n",
      "\u001b[31mTypeError\u001b[39m: object of type 'NoneType' has no len()"
     ]
    }
   ],
   "source": [
    "# Initialize the analyzer with appropriate paths\n",
    "analyzer = MarketEfficiencyAnalyzer(\n",
    "    data_dir='data',  # Path to data directory\n",
    "    results_dir=results_dir,  # Path to save results\n",
    "    max_cache_size=50  # Maximum number of markets to cache\n",
    ")\n",
    "\n",
    "# Print basic dataset information\n",
    "print(f\"Dataset contains {len(analyzer.main_df)} markets\")\n",
    "print(f\"Available market questions: {len(analyzer.market_questions)}\")\n",
    "\n",
    "# Display available event types and countries\n",
    "if 'event_electionType' in analyzer.main_df.columns:\n",
    "    print(\"\\nAvailable Election Types:\")\n",
    "    for event_type, count in analyzer.main_df['event_electionType'].value_counts().items():\n",
    "        print(f\"  {event_type}: {count} markets\")\n",
    "\n",
    "if 'event_country' in analyzer.main_df.columns:\n",
    "    print(\"\\nTop Countries:\")\n",
    "    for country, count in analyzer.main_df['event_country'].value_counts().head(10).items():\n",
    "        print(f\"  {country}: {count} markets\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a16e1b99",
   "metadata": {},
   "source": [
    "## 3. Single Market Analysis\n",
    "\n",
    "Let's analyze a specific market to understand its efficiency characteristics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31042c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Markets related to 2024 US Presidential Election:\n",
      "No markets found matching the search criteria.\n"
     ]
    }
   ],
   "source": [
    "# Find markets related to the 2024 US Presidential Election\n",
    "us_presidential_markets = analyzer.find_market_by_name(\"Trump 2024\")\n",
    "\n",
    "# Display matching markets\n",
    "print(\"Markets related to 2024 US Presidential Election:\")\n",
    "for i, (market_id, question) in enumerate(us_presidential_markets[:10]):  # Limit to 10 results\n",
    "    print(f\"{i+1}. {question} (ID: {market_id})\")\n",
    "\n",
    "# Select a market to analyze (for example, the first match)\n",
    "if us_presidential_markets:\n",
    "    selected_market_id = us_presidential_markets[0][0]\n",
    "    selected_market_name = us_presidential_markets[0][1]\n",
    "    print(f\"\\nAnalyzing market: {selected_market_name} (ID: {selected_market_id})\")\n",
    "    \n",
    "    # Run detailed analysis\n",
    "    market_result = analyzer.analyze_market(selected_market_id, verbose=True)\n",
    "    \n",
    "    # Create visualizations\n",
    "    market_figures = analyzer.visualize_market(selected_market_id, save_to=f\"{results_dir}/market_{selected_market_id}_viz.png\")\n",
    "    \n",
    "    # Save results\n",
    "    analyzer.save_results(market_result, f\"market_{selected_market_id}_analysis.json\")\n",
    "else:\n",
    "    print(\"No markets found matching the search criteria.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8972dcf",
   "metadata": {},
   "source": [
    "## 4. Finding Efficient vs. Inefficient Markets\n",
    "\n",
    "Let's identify examples of highly efficient and inefficient markets for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb383b6e",
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'NoneType' object has no attribute 'columns'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mAttributeError\u001b[39m                            Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[120]\u001b[39m\u001b[32m, line 2\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;66;03m# Get top markets by volume for analysis\u001b[39;00m\n\u001b[32m----> \u001b[39m\u001b[32m2\u001b[39m top_volume_markets = \u001b[43manalyzer\u001b[49m\u001b[43m.\u001b[49m\u001b[43mget_top_markets_by_volume\u001b[49m\u001b[43m(\u001b[49m\u001b[43mn\u001b[49m\u001b[43m=\u001b[49m\u001b[32;43m20\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Analyze these markets\u001b[39;00m\n\u001b[32m      5\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAnalyzing \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlen\u001b[39m(top_volume_markets)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m high-volume markets...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/Desktop/ML/polymarket_analysis/src/knowledge_value/market_efficiency.py:1481\u001b[39m, in \u001b[36mMarketEfficiencyAnalyzer.get_top_markets_by_volume\u001b[39m\u001b[34m(self, n)\u001b[39m\n\u001b[32m   1467\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mget_top_markets_by_volume\u001b[39m(\u001b[38;5;28mself\u001b[39m, n=\u001b[32m10\u001b[39m):\n\u001b[32m   1468\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1469\u001b[39m \u001b[33;03m    Get the top N markets by trading volume.\u001b[39;00m\n\u001b[32m   1470\u001b[39m \u001b[33;03m    \u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m   1479\u001b[39m \u001b[33;03m        List of market IDs\u001b[39;00m\n\u001b[32m   1480\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1481\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m'\u001b[39m\u001b[33mvolumeNum\u001b[39m\u001b[33m'\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmain_df\u001b[49m\u001b[43m.\u001b[49m\u001b[43mcolumns\u001b[49m:\n\u001b[32m   1482\u001b[39m         \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mVolume data not available\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1483\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m []\n",
      "\u001b[31mAttributeError\u001b[39m: 'NoneType' object has no attribute 'columns'"
     ]
    }
   ],
   "source": [
    "# Get top markets by volume for analysis\n",
    "top_volume_markets = analyzer.get_top_markets_by_volume(n=20)\n",
    "\n",
    "# Analyze these markets\n",
    "print(f\"Analyzing {len(top_volume_markets)} high-volume markets...\")\n",
    "top_markets_results = analyzer.analyze_market_batch(top_volume_markets, max_markets=20, parallel=True)\n",
    "\n",
    "# Sort markets by efficiency score\n",
    "if top_markets_results:\n",
    "    # Convert to DataFrame for easier sorting and filtering\n",
    "    results_df = pd.DataFrame([\n",
    "        {\n",
    "            'market_id': r['market_id'],\n",
    "            'question': r.get('question', 'Unknown'),\n",
    "            'efficiency_score': r.get('efficiency_score', 0),\n",
    "            'efficiency_class': r.get('efficiency_class', 'Unknown'),\n",
    "            'event_type': r.get('event_type', 'Unknown'),\n",
    "            'country': r.get('country', 'Unknown')\n",
    "        }\n",
    "        for r in top_markets_results\n",
    "    ])\n",
    "    \n",
    "    # Sort by efficiency score\n",
    "    sorted_results = results_df.sort_values('efficiency_score', ascending=False)\n",
    "    \n",
    "    # Display most efficient markets\n",
    "    print(\"\\nMost Efficient Markets:\")\n",
    "    for _, row in sorted_results.head(5).iterrows():\n",
    "        print(f\"  {row['question']} - Score: {row['efficiency_score']:.2f} - Class: {row['efficiency_class']}\")\n",
    "    \n",
    "    # Display least efficient markets\n",
    "    print(\"\\nLeast Efficient Markets:\")\n",
    "    for _, row in sorted_results.tail(5).iterrows():\n",
    "        print(f\"  {row['question']} - Score: {row['efficiency_score']:.2f} - Class: {row['efficiency_class']}\")\n",
    "    \n",
    "    # Select one efficient and one inefficient market for comparison\n",
    "    efficient_market = sorted_results.iloc[0]['market_id']\n",
    "    inefficient_market = sorted_results.iloc[-1]['market_id']\n",
    "    \n",
    "    # Create side-by-side visualization\n",
    "    plt.figure(figsize=(20, 10))\n",
    "    plt.suptitle(\"Comparison of Efficient vs. Inefficient Markets\", fontsize=16)\n",
    "    \n",
    "    # Visualize efficient market\n",
    "    efficient_data = analyzer.preprocess_market_data(efficient_market)\n",
    "    if efficient_data is not None:\n",
    "        plt.subplot(2, 2, 1)\n",
    "        plt.plot(efficient_data.index, efficient_data['price'])\n",
    "        plt.title(f\"Efficient Market: {sorted_results[sorted_results['market_id'] == efficient_market]['question'].values[0]}\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        \n",
    "        plt.subplot(2, 2, 2)\n",
    "        plt.plot(efficient_data.index, efficient_data['log_return'], color='green')\n",
    "        plt.title(\"Log Returns\")\n",
    "    \n",
    "    # Visualize inefficient market\n",
    "    inefficient_data = analyzer.preprocess_market_data(inefficient_market)\n",
    "    if inefficient_data is not None:\n",
    "        plt.subplot(2, 2, 3)\n",
    "        plt.plot(inefficient_data.index, inefficient_data['price'])\n",
    "        plt.title(f\"Inefficient Market: {sorted_results[sorted_results['market_id'] == inefficient_market]['question'].values[0]}\")\n",
    "        plt.ylabel(\"Price\")\n",
    "        \n",
    "        plt.subplot(2, 2, 4)\n",
    "        plt.plot(inefficient_data.index, inefficient_data['log_return'], color='red')\n",
    "        plt.title(\"Log Returns\")\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(f\"{results_dir}/efficient_vs_inefficient.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"No results from batch analysis.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8ecea7b6",
   "metadata": {},
   "source": [
    "## 5. Comparative Analysis by Market Type\n",
    "\n",
    "Let's compare market efficiency across different election types."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15b8ad0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get metrics by election type\n",
    "election_types = ['Presidential', 'Senate', 'Parliamentary']\n",
    "comparison_results = []\n",
    "\n",
    "for election_type in election_types:\n",
    "    # Get markets for this type\n",
    "    markets = analyzer.get_markets_by_event_type(election_type, n=10)\n",
    "    \n",
    "    print(f\"Analyzing {len(markets)} {election_type} markets...\")\n",
    "    \n",
    "    # Analyze markets\n",
    "    type_results = analyzer.analyze_market_batch(markets, max_markets=10)\n",
    "    \n",
    "    # Aggregate results\n",
    "    if type_results:\n",
    "        avg_score = np.mean([r.get('efficiency_score', 0) for r in type_results])\n",
    "        price_stationary = sum(1 for r in type_results if r.get('adf_price', {}).get('is_stationary', False))\n",
    "        return_stationary = sum(1 for r in type_results if r.get('adf_return', {}).get('is_stationary', False))\n",
    "        has_autocorr = sum(1 for r in type_results if r.get('autocorrelation', {}).get('has_significant_autocorrelation', False))\n",
    "        \n",
    "        comparison_results.append({\n",
    "            'election_type': election_type,\n",
    "            'count': len(type_results),\n",
    "            'avg_score': avg_score,\n",
    "            'price_stationary_pct': price_stationary / len(type_results) * 100 if len(type_results) > 0 else 0,\n",
    "            'return_stationary_pct': return_stationary / len(type_results) * 100 if len(type_results) > 0 else 0,\n",
    "            'has_autocorr_pct': has_autocorr / len(type_results) * 100 if len(type_results) > 0 else 0\n",
    "        })\n",
    "\n",
    "# Create comparison visualization\n",
    "if comparison_results:\n",
    "    # Convert to DataFrame\n",
    "    comparison_df = pd.DataFrame(comparison_results)\n",
    "    \n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Plot average efficiency score by election type\n",
    "    bars = plt.bar(comparison_df['election_type'], comparison_df['avg_score'], color='skyblue')\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        height = bar.get_height()\n",
    "        plt.text(bar.get_x() + bar.get_width()/2., height + 1,\n",
    "                f\"n={comparison_df['count'].iloc[i]}\",\n",
    "                ha='center', va='bottom')\n",
    "    \n",
    "    plt.title('Average Efficiency Score by Election Type', fontsize=14)\n",
    "    plt.ylabel('Efficiency Score (0-100)', fontsize=12)\n",
    "    plt.ylim(0, 100)\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    plt.savefig(f\"{results_dir}/efficiency_by_election_type.png\", dpi=300, bbox_inches='tight')\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b22274f0",
   "metadata": {},
   "source": [
    "## Market Analysis\n",
    "### 5.1 Single Market"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fa3550b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_market_by_id_or_name(market_id_or_name, main_df, id_column, market_questions):\n",
    "    \"\"\"\n",
    "    Find a market by its ID or name\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_id_or_name : str or int\n",
    "        Market ID or partial name to search for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (market_id, market_info) or (None, None) if not found\n",
    "    \"\"\"\n",
    "    # Try direct ID match\n",
    "    if isinstance(market_id_or_name, (int, float)) or market_id_or_name.isdigit():\n",
    "        market_id = int(market_id_or_name) if market_id_or_name.isdigit() else market_id_or_name\n",
    "        market_rows = main_df[main_df[id_column] == market_id]\n",
    "        if not market_rows.empty:\n",
    "            return market_id, market_rows.iloc[0]\n",
    "    \n",
    "    # Try string ID match\n",
    "    market_rows = main_df[main_df[id_column].astype(str) == str(market_id_or_name)]\n",
    "    if not market_rows.empty:\n",
    "        return market_id_or_name, market_rows.iloc[0]\n",
    "    \n",
    "    # Try partial name match\n",
    "    if 'question' in main_df.columns:\n",
    "        name_matches = main_df[main_df['question'].str.contains(str(market_id_or_name), case=False, na=False)]\n",
    "        if not name_matches.empty:\n",
    "            match = name_matches.iloc[0]\n",
    "            return match[id_column], match\n",
    "    \n",
    "    # Try partial match in market_questions values\n",
    "    for id, question in market_questions.items():\n",
    "        if str(market_id_or_name).lower() in question.lower():\n",
    "            market_rows = main_df[main_df[id_column].astype(str) == str(id)]\n",
    "            if not market_rows.empty:\n",
    "                return id, market_rows.iloc[0]\n",
    "    \n",
    "    return None, None\n",
    "\n",
    "def analyze_specific_market(market_id_or_name, main_df=None, id_column=None, market_questions=None):\n",
    "    \"\"\"\n",
    "    Analyze a specific market identified by ID or name\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_id_or_name : str or int\n",
    "        Market ID or name to search for\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Market analysis results\n",
    "    \"\"\"\n",
    "    if main_df is None:\n",
    "        main_df, id_column, market_questions = load_data(verbose=False)\n",
    "    \n",
    "    # Find the market\n",
    "    market_id, market_info = get_market_by_id_or_name(market_id_or_name, main_df, id_column, market_questions)\n",
    "    \n",
    "    if market_id is None:\n",
    "        print(f\"No market found matching '{market_id_or_name}'\")\n",
    "        return None\n",
    "    \n",
    "    # Display market information\n",
    "    print(\"\\n🔍 Market Information\")\n",
    "    print(\"-\" * 50)\n",
    "    print(f\"Market ID: {market_id}\")\n",
    "    \n",
    "    # Get the market question\n",
    "    market_name = None\n",
    "    if 'question' in market_info:\n",
    "        market_name = market_info['question']\n",
    "    else:\n",
    "        market_name = market_questions.get(str(market_id), f\"Market {market_id}\")\n",
    "    \n",
    "    print(f\"Market Question: {market_name}\")\n",
    "    \n",
    "    # Display additional information if available\n",
    "    for col, label in [\n",
    "        ('event_electionType', 'Election Type'),\n",
    "        ('event_country', 'Country'),\n",
    "        ('volumeNum', 'Trading Volume'),\n",
    "        ('market_duration_days', 'Market Duration (days)')\n",
    "    ]:\n",
    "        if col in market_info and not pd.isna(market_info[col]):\n",
    "            print(f\"{label}: {market_info[col]}\")\n",
    "    \n",
    "    # Process the market data\n",
    "    print(\"\\nProcessing market data...\")\n",
    "    market_data = preprocess_market_data(market_id, verbose=True)\n",
    "    \n",
    "    if market_data is None:\n",
    "        print(\"❌ Failed to process market data\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"✅ Successfully processed market data with {len(market_data)} time points\")\n",
    "    \n",
    "    # Run efficiency tests\n",
    "    print(\"\\nRunning market efficiency tests...\")\n",
    "    test_results = run_efficiency_tests(market_data, verbose=True)\n",
    "    \n",
    "    if test_results is None:\n",
    "        print(\"❌ Failed to run efficiency tests\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate efficiency score\n",
    "    efficiency_score = calculate_efficiency_score(test_results)\n",
    "    \n",
    "    # Determine efficiency class\n",
    "    if efficiency_score >= 80:\n",
    "        efficiency_class = 'Highly Efficient'\n",
    "    elif efficiency_score >= 60:\n",
    "        efficiency_class = 'Moderately Efficient'\n",
    "    elif efficiency_score >= 40:\n",
    "        efficiency_class = 'Slightly Inefficient'\n",
    "    else:\n",
    "        efficiency_class = 'Highly Inefficient'\n",
    "    \n",
    "    print(f\"\\n📊 Market Efficiency Score: {efficiency_score:.2f}/100\")\n",
    "    print(f\"📈 Efficiency Classification: {efficiency_class}\")\n",
    "    \n",
    "    # Print detailed test results\n",
    "    print(\"\\n🔬 Detailed Test Results:\")\n",
    "    \n",
    "    if 'adf_price' in test_results:\n",
    "        is_random_walk = not test_results['adf_price']['is_stationary']\n",
    "        print(f\"Random Walk Test (Non-stationary prices): {'✅ Pass' if is_random_walk else '❌ Fail'}\")\n",
    "    \n",
    "    if 'adf_return' in test_results:\n",
    "        is_return_stationary = test_results['adf_return']['is_stationary']\n",
    "        print(f\"Return Stationarity Test: {'✅ Pass' if is_return_stationary else '❌ Fail'}\")\n",
    "    \n",
    "    if 'autocorrelation' in test_results:\n",
    "        no_autocorr = not test_results['autocorrelation']['has_significant_autocorrelation']\n",
    "        print(f\"No Significant Autocorrelation: {'✅ Pass' if no_autocorr else '❌ Fail'}\")\n",
    "    \n",
    "    if 'runs_test' in test_results:\n",
    "        is_random = test_results['runs_test'].get('is_random', False)\n",
    "        print(f\"Runs Test (Randomness): {'✅ Pass' if is_random else '❌ Fail'}\")\n",
    "    \n",
    "    if 'ar_model' in test_results:\n",
    "        no_ar = not test_results['ar_model'].get('significant', True)\n",
    "        print(f\"No Significant AR Model: {'✅ Pass' if no_ar else '❌ Fail'}\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    print(\"\\nGenerating visualizations...\")\n",
    "    visualize_market(market_data, market_name, test_results)\n",
    "    \n",
    "    # Prepare final results\n",
    "    results = {\n",
    "        'market_id': market_id,\n",
    "        'market_name': market_name,\n",
    "        'test_results': test_results,\n",
    "        'efficiency_score': efficiency_score,\n",
    "        'efficiency_class': efficiency_class\n",
    "    }\n",
    "    \n",
    "    # Add market attributes\n",
    "    for col in ['event_electionType', 'event_country', 'volumeNum', 'market_duration_days']:\n",
    "        if col in market_info and not pd.isna(market_info[col]):\n",
    "            results[col] = market_info[col]\n",
    "    \n",
    "    return results\n",
    "\n",
    "def visualize_market(market_data, market_name, test_results=None):\n",
    "    \"\"\"Create visualizations for a specific market\"\"\"\n",
    "    # Create a 2x2 plot grid\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 12))\n",
    "    \n",
    "    # 1. Price Series\n",
    "    axs[0, 0].plot(market_data.index, market_data['price'], linewidth=2)\n",
    "    axs[0, 0].set_title(f'Price Series: {market_name}', fontsize=14)\n",
    "    axs[0, 0].set_xlabel('Date', fontsize=12)\n",
    "    axs[0, 0].set_ylabel('Price', fontsize=12)\n",
    "    axs[0, 0].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 2. Log Returns\n",
    "    axs[0, 1].plot(market_data.index, market_data['log_return'], linewidth=1, color='green')\n",
    "    axs[0, 1].set_title(f'Log Returns: {market_name}', fontsize=14)\n",
    "    axs[0, 1].set_xlabel('Date', fontsize=12)\n",
    "    axs[0, 1].set_ylabel('Log Return', fontsize=12)\n",
    "    axs[0, 1].grid(True, alpha=0.3)\n",
    "    \n",
    "    # 3. ACF Plot\n",
    "    if test_results and 'autocorrelation' in test_results:\n",
    "        acf_values = test_results['autocorrelation']['acf_values']\n",
    "        significant = test_results['autocorrelation']['has_significant_autocorrelation']\n",
    "        \n",
    "        lags = range(len(acf_values))\n",
    "        axs[1, 0].bar(lags, acf_values, width=0.3)\n",
    "        \n",
    "        # Plot confidence intervals for hypothesis testing\n",
    "        ci = 1.96 / np.sqrt(len(market_data))\n",
    "        axs[1, 0].axhline(y=0, linestyle='-', color='black', linewidth=1)\n",
    "        axs[1, 0].axhline(y=ci, linestyle='--', color='red', linewidth=1, alpha=0.7)\n",
    "        axs[1, 0].axhline(y=-ci, linestyle='--', color='red', linewidth=1, alpha=0.7)\n",
    "        \n",
    "        title = f'Autocorrelation Function: {\"❌ Significant\" if significant else \"✅ Not Significant\"}'\n",
    "        axs[1, 0].set_title(title, fontsize=14)\n",
    "        axs[1, 0].set_xlabel('Lag', fontsize=12)\n",
    "        axs[1, 0].set_ylabel('ACF', fontsize=12)\n",
    "    else:\n",
    "        axs[1, 0].set_title('Autocorrelation Function: Not Available', fontsize=14)\n",
    "    \n",
    "    # 4. Price distribution\n",
    "    axs[1, 1].hist(market_data['price'], bins=30, alpha=0.7, density=True)\n",
    "    axs[1, 1].set_title(f'Price Distribution: {market_name}', fontsize=14)\n",
    "    axs[1, 1].set_xlabel('Price', fontsize=12)\n",
    "    axs[1, 1].set_ylabel('Density', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.show()\n",
    "    \n",
    "    # If time-varying efficiency results are available, show those too\n",
    "    if test_results and 'time_varying' in test_results and 'comparison' in test_results['time_varying']:\n",
    "        comparison = test_results['time_varying']['comparison']\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        periods = ['Early', 'Middle', 'Late']\n",
    "        \n",
    "        # Extract volatility for each period\n",
    "        volatilities = []\n",
    "        for period in ['early', 'middle', 'late']:\n",
    "            if period in test_results['time_varying']:\n",
    "                volatilities.append(test_results['time_varying'][period]['volatility'])\n",
    "            else:\n",
    "                volatilities.append(np.nan)\n",
    "        \n",
    "        # Create the bar chart\n",
    "        bars = plt.bar(periods, volatilities, color=['blue', 'green', 'orange'])\n",
    "        \n",
    "        plt.title(f'Return Volatility by Market Period: {comparison[\"efficiency_change\"]}', fontsize=14)\n",
    "        plt.ylabel('Return Volatility', fontsize=12)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        # Add efficiency change information\n",
    "        plt.figtext(0.5, 0.01, f'Efficiency Change: {comparison[\"efficiency_change\"]}', \n",
    "                   ha='center', fontsize=12, bbox={\"facecolor\":\"lightgray\", \"alpha\":0.5, \"pad\":5})\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3422bff",
   "metadata": {},
   "source": [
    "## 6. Cross-Market Analysis\n",
    "\n",
    "Let's analyze how markets in the same event influence each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0eb9d613",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Error getting sample market IDs: [Errno 2] No such file or directory: 'data/trades/market_id_to_question.json'\n",
      "Error running analysis: [Errno 2] No such file or directory: 'data/trades/market_id_to_question.json'\n",
      "Analysis results not available\n",
      "\n",
      "Basic Trader Concentration Analysis:\n",
      "Trader Count Gini Coefficient: 0.7193\n",
      "Trading Volume Gini Coefficient: 0.9034\n"
     ]
    }
   ],
   "source": [
    "# Find a presidential election event with multiple markets\n",
    "presidential_events = analyzer.find_market_by_name(\"Presidential Election 2024\")\n",
    "\n",
    "if presidential_events:\n",
    "    # Get the first event ID\n",
    "    event_id = presidential_events[0][0]\n",
    "    print(f\"Analyzing cross-market relationships for event: {presidential_events[0][1]}\")\n",
    "    \n",
    "    # Run cross-market analysis\n",
    "    cross_results = analyzer.analyze_cross_market(event_id)\n",
    "    \n",
    "    # Print significant relationships\n",
    "    if cross_results and 'market_pairs' in cross_results:\n",
    "        significant_pairs = [pair for pair in cross_results['market_pairs'] \n",
    "                            if pair['i_causes_j'] or pair['j_causes_i']]\n",
    "        \n",
    "        print(f\"\\nFound {len(significant_pairs)} significant relationships out of {len(cross_results['market_pairs'])} tested pairs\")\n",
    "        \n",
    "        if significant_pairs:\n",
    "            print(\"\\nSignificant market relationships:\")\n",
    "            for pair in significant_pairs:\n",
    "                print(f\"Relationship: {pair['relationship']}\")\n",
    "                print(f\"  Market 1: {pair['market_i_question']}\")\n",
    "                print(f\"  Market 2: {pair['market_j_question']}\")\n",
    "                print()\n",
    "    else:\n",
    "        print(\"No significant cross-market relationships found.\")\n",
    "else:\n",
    "    print(\"No presidential election events found.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae9d0e22",
   "metadata": {},
   "source": [
    "## 7. Analyzing Time-Varying Efficiency\n",
    "\n",
    "Let's look at how efficiency changes over time within markets."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "07adb740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Select a long-running market to analyze time-varying efficiency\n",
    "if 'market_duration_days' in analyzer.main_df.columns:\n",
    "    long_markets = analyzer.main_df.sort_values('market_duration_days', ascending=False)\n",
    "    \n",
    "    if not long_markets.empty:\n",
    "        long_market_id = long_markets.iloc[0][analyzer.id_column]\n",
    "        long_market_question = analyzer.get_market_details(long_market_id)['question']\n",
    "        \n",
    "        print(f\"Analyzing time-varying efficiency for market: {long_market_question}\")\n",
    "        \n",
    "        # Run analysis\n",
    "        time_result = analyzer.analyze_market(long_market_id, verbose=True)\n",
    "        \n",
    "        # Display time-varying efficiency results\n",
    "        if 'time_varying' in time_result and 'comparison' in time_result['time_varying']:\n",
    "            comparison = time_result['time_varying']['comparison']\n",
    "            \n",
    "            print(\"\\nTime-Varying Efficiency Results:\")\n",
    "            print(f\"Efficiency Change: {comparison['efficiency_change']}\")\n",
    "            print(f\"Volatility Ratio (Late/Early): {comparison['volatility_ratio']:.2f}\")\n",
    "            \n",
    "            # Create visualization of efficiency over time\n",
    "            periods = ['early', 'middle', 'late']\n",
    "            periods_data = []\n",
    "            \n",
    "            for period in periods:\n",
    "                if period in time_result['time_varying']:\n",
    "                    period_data = time_result['time_varying'][period]\n",
    "                    periods_data.append({\n",
    "                        'period': period.capitalize(),\n",
    "                        'volatility': period_data['return_volatility'],\n",
    "                        'has_autocorrelation': period_data['significant_acf'],\n",
    "                        'is_inefficient': period_data['ar_model']['significant'] if period_data['ar_model'] else False\n",
    "                    })\n",
    "            \n",
    "            if periods_data:\n",
    "                periods_df = pd.DataFrame(periods_data)\n",
    "                \n",
    "                plt.figure(figsize=(12, 6))\n",
    "                \n",
    "                # Plot volatility by period\n",
    "                plt.subplot(1, 2, 1)\n",
    "                plt.bar(periods_df['period'], periods_df['volatility'], color='skyblue')\n",
    "                plt.title('Return Volatility by Market Period', fontsize=14)\n",
    "                plt.ylabel('Volatility', fontsize=12)\n",
    "                \n",
    "                # Plot inefficiency by period\n",
    "                plt.subplot(1, 2, 2)\n",
    "                inefficiency_scores = [float(row['is_inefficient']) + float(row['has_autocorrelation']) for _, row in periods_df.iterrows()]\n",
    "                plt.bar(periods_df['period'], inefficiency_scores, color='salmon')\n",
    "                plt.title('Inefficiency Score by Market Period', fontsize=14)\n",
    "                plt.ylabel('Inefficiency Score (0-2)', fontsize=12)\n",
    "                plt.ylim(0, 2)\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(f\"{results_dir}/time_varying_efficiency.png\", dpi=300, bbox_inches='tight')\n",
    "                plt.show()\n",
    "        else:\n",
    "            print(\"No time-varying efficiency data available for this market.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17620ad3",
   "metadata": {},
   "source": [
    "### 5.3 Visualize Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64201c11",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_efficiency_results(results_df, save_dir=None):\n",
    "    \"\"\"\n",
    "    Create visualizations for market efficiency results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    results_df : pd.DataFrame\n",
    "        DataFrame with market efficiency results\n",
    "    save_dir : str, optional\n",
    "        Directory to save plots, if None uses results_dir\n",
    "    \"\"\"\n",
    "    if results_df is None or len(results_df) == 0:\n",
    "        print(\"No results to visualize\")\n",
    "        return\n",
    "    \n",
    "    if save_dir is None:\n",
    "        save_dir = results_dir\n",
    "    \n",
    "    os.makedirs(save_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Efficiency Score Distribution\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    sns.histplot(results_df['efficiency_score'], bins=20, kde=True)\n",
    "    plt.axvline(x=results_df['efficiency_score'].mean(), color='red', linestyle='--', \n",
    "               label=f'Mean: {results_df[\"efficiency_score\"].mean():.2f}')\n",
    "    plt.title('Distribution of Market Efficiency Scores', fontsize=14)\n",
    "    plt.xlabel('Efficiency Score (0-100, higher = more efficient)', fontsize=12)\n",
    "    plt.ylabel('Count', fontsize=12)\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.savefig(os.path.join(save_dir, 'efficiency_score_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 2. Efficiency Classification Pie Chart\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    results_df['efficiency_class'].value_counts().plot.pie(autopct='%1.1f%%', \n",
    "                                                         colors=sns.color_palette(\"viridis\", 4),\n",
    "                                                         startangle=90)\n",
    "    plt.title('Market Efficiency Classification', fontsize=14)\n",
    "    plt.ylabel('')  # Hide ylabel\n",
    "    \n",
    "    plt.savefig(os.path.join(save_dir, 'efficiency_classification_pie.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.show()\n",
    "    \n",
    "    # 3. Efficiency by Market Type (if available)\n",
    "    if 'event_electionType' in results_df.columns:\n",
    "        type_counts = results_df['event_electionType'].value_counts()\n",
    "        types_with_data = type_counts[type_counts >= 5].index.tolist()\n",
    "        \n",
    "        if types_with_data:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            # Calculate average efficiency by type\n",
    "            type_data = []\n",
    "            for market_type in types_with_data:\n",
    "                type_df = results_df[results_df['event_electionType'] == market_type]\n",
    "                type_data.append({\n",
    "                    'Market Type': market_type,\n",
    "                    'Average Efficiency': type_df['efficiency_score'].mean(),\n",
    "                    'Count': len(type_df)\n",
    "                })\n",
    "            \n",
    "            type_df = pd.DataFrame(type_data).sort_values('Average Efficiency', ascending=False)\n",
    "            \n",
    "            # Create bar chart\n",
    "            bars = plt.bar(type_df['Market Type'], type_df['Average Efficiency'], color='lightgreen')\n",
    "            \n",
    "            # Add count labels\n",
    "            for i, bar in enumerate(bars):\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, \n",
    "                        bar.get_height() + 1, \n",
    "                        f\"n={type_df['Count'].iloc[i]}\", \n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "            \n",
    "            plt.axhline(y=results_df['efficiency_score'].mean(), color='red', linestyle='--', \n",
    "                       label=f'Overall Average: {results_df[\"efficiency_score\"].mean():.2f}')\n",
    "            \n",
    "            plt.title('Average Efficiency Score by Market Type', fontsize=14)\n",
    "            plt.xlabel('Market Type', fontsize=12)\n",
    "            plt.ylabel('Average Efficiency Score', fontsize=12)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.legend()\n",
    "            plt.ylim(0, 100)\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            plt.savefig(os.path.join(save_dir, 'efficiency_by_market_type.png'), dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "    \n",
    "    # 4. Efficiency by Country (if available)\n",
    "    if 'event_country' in results_df.columns:\n",
    "        country_counts = results_df['event_country'].value_counts()\n",
    "        countries_with_data = country_counts[country_counts >= 5].index.tolist()\n",
    "        \n",
    "        if countries_with_data:\n",
    "            plt.figure(figsize=(12, 6))\n",
    "            \n",
    "            country_data = []\n",
    "            for country in countries_with_data:\n",
    "                country_df = results_df[results_df['event_country'] == country]\n",
    "                country_data.append({\n",
    "                    'Country': country,\n",
    "                    'Average Efficiency': country_df['efficiency_score'].mean(),\n",
    "                    'Count': len(country_df)\n",
    "                })\n",
    "            \n",
    "            country_df = pd.DataFrame(country_data).sort_values('Average Efficiency', ascending=False)\n",
    "            \n",
    "            bars = plt.bar(country_df['Country'], country_df['Average Efficiency'], color='skyblue')\n",
    "            \n",
    "            for i, bar in enumerate(bars):\n",
    "                plt.text(bar.get_x() + bar.get_width()/2, \n",
    "                        bar.get_height() + 1, \n",
    "                        f\"n={country_df['Count'].iloc[i]}\", \n",
    "                        ha='center', va='bottom', fontsize=10)\n",
    "            \n",
    "            plt.axhline(y=results_df['efficiency_score'].mean(), color='red', linestyle='--', \n",
    "                       label=f'Overall Average: {results_df[\"efficiency_score\"].mean():.2f}')\n",
    "            \n",
    "            plt.title('Average Efficiency Score by Country', fontsize=14)\n",
    "            plt.xlabel('Country', fontsize=12)\n",
    "            plt.ylabel('Average Efficiency Score', fontsize=12)\n",
    "            plt.xticks(rotation=45, ha='right')\n",
    "            plt.legend()\n",
    "            plt.ylim(0, 100)\n",
    "            plt.grid(axis='y', alpha=0.3)\n",
    "            plt.tight_layout()\n",
    "            \n",
    "            plt.savefig(os.path.join(save_dir, 'efficiency_by_country.png'), dpi=300, bbox_inches='tight')\n",
    "            plt.show()\n",
    "    \n",
    "    # 5. Efficiency vs Volume (if available)\n",
    "    if 'volumeNum' in results_df.columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Use log scale for volume\n",
    "        plt.scatter(results_df['volumeNum'], results_df['efficiency_score'], alpha=0.6)\n",
    "        plt.xscale('log')\n",
    "        \n",
    "        # Add trend line\n",
    "        try:\n",
    "            z = np.polyfit(np.log10(results_df['volumeNum']), results_df['efficiency_score'], 1)\n",
    "            p = np.poly1d(z)\n",
    "            \n",
    "            # Create x range for line (in log space)\n",
    "            x_range = np.logspace(\n",
    "                np.log10(results_df['volumeNum'].min()), \n",
    "                np.log10(results_df['volumeNum'].max()), \n",
    "                100\n",
    "            )\n",
    "            \n",
    "            plt.plot(x_range, p(np.log10(x_range)), \"r--\", linewidth=2)\n",
    "            \n",
    "            # Calculate correlation\n",
    "            corr = np.corrcoef(np.log10(results_df['volumeNum']), results_df['efficiency_score'])[0, 1]\n",
    "            plt.text(0.05, 0.95, f\"Correlation: {corr:.3f}\", transform=plt.gca().transAxes,\n",
    "                    bbox=dict(facecolor='white', alpha=0.8))\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        plt.title('Efficiency Score vs Trading Volume', fontsize=14)\n",
    "        plt.xlabel('Trading Volume (log scale)', fontsize=12)\n",
    "        plt.ylabel('Efficiency Score', fontsize=12)\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        plt.savefig(os.path.join(save_dir, 'efficiency_vs_volume.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.show()\n",
    "    \n",
    "    # 6. Time-varying efficiency results\n",
    "    if 'efficiency_change' in results_df.columns:\n",
    "        efficiency_changes = results_df['efficiency_change'].value_counts()\n",
    "        \n",
    "        plt.figure(figsize=(10, 6))\n",
    "        bars = plt.bar(efficiency_changes.index, efficiency_changes.values, color=['green', 'gray', 'red'])\n",
    "        \n",
    "        # Add percentage labels\n",
    "        total = len(results_df)\n",
    "        for i, (category, count) in enumerate(efficiency_changes.items()):\n",
    "            plt.text(i, count + 0.5, f\"{count/total*100:.1f}%\", ha='center', fontsize=12)\n",
    "        \n",
    "        plt.title('Efficiency Change Over Market Lifecycle', fontsize=14)\n",
    "        plt.ylabel('Number of Markets', fontsize=12)\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        \n",
    "        plt.savefig(os.path.join(save_dir, 'time_varying_efficiency.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "569be738",
   "metadata": {},
   "source": [
    "## 8. Comprehensive Batch Analysis\n",
    "\n",
    "Now let's run a larger batch analysis to get a comprehensive view of market efficiency."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1073a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configure batch analysis parameters\n",
    "batch_size = 30  # Number of markets to analyze\n",
    "parallel = True  # Use parallel processing\n",
    "\n",
    "# Get markets for analysis\n",
    "markets_to_analyze = analyzer.get_top_markets_by_volume(n=batch_size)\n",
    "\n",
    "print(f\"Running comprehensive analysis on {len(markets_to_analyze)} markets...\")\n",
    "\n",
    "# Run batch analysis\n",
    "batch_results = analyzer.analyze_market_batch(markets_to_analyze, parallel=parallel)\n",
    "\n",
    "# Generate summary\n",
    "if batch_results:\n",
    "    summary = analyzer.summarize_results(batch_results)\n",
    "    \n",
    "    # Visualize summary\n",
    "    analyzer.visualize_summary(summary)\n",
    "    \n",
    "    # Save results\n",
    "    analyzer.save_results(batch_results, \"comprehensive_batch_results.json\")\n",
    "    analyzer.save_results(summary, \"comprehensive_batch_summary.json\")\n",
    "    \n",
    "    # Display key findings\n",
    "    print(\"\\nKey Findings:\")\n",
    "    print(f\"Total markets analyzed: {summary['total_markets']}\")\n",
    "    print(f\"Average efficiency score: {summary['average_efficiency_score']:.2f}\")\n",
    "    \n",
    "    print(\"\\nEfficiency Classes:\")\n",
    "    for cls, count in summary['efficiency_classes'].items():\n",
    "        percentage = count / summary['total_markets'] * 100\n",
    "        print(f\"  {cls}: {count} markets ({percentage:.1f}%)\")\n",
    "    \n",
    "    print(\"\\nTest Results:\")\n",
    "    test_results = summary['test_results']\n",
    "    print(f\"  Non-stationary prices: {100 - test_results.get('price_stationary_percentage', 0):.1f}% (efficient)\")\n",
    "    print(f\"  Stationary returns: {test_results.get('return_stationary_percentage', 0):.1f}% (efficient)\")\n",
    "    print(f\"  No significant autocorrelation: {100 - test_results.get('has_autocorrelation_percentage', 0):.1f}% (efficient)\")\n",
    "    print(f\"  Random runs test: {test_results.get('is_random_percentage', 0):.1f}% (efficient)\")\n",
    "    print(f\"  No significant AR model: {100 - test_results.get('ar_significant_percentage', 0):.1f}% (efficient)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae40119a",
   "metadata": {},
   "source": [
    "## 9. Conclusion\n",
    "\n",
    "In this notebook, we have analyzed the efficiency of Polymarket prediction markets using various statistical tests. We have found that:\n",
    "\n",
    "1. Overall market efficiency varies by market type, with [highest/lowest] efficiency observed in [type] markets.\n",
    "2. Price dynamics exhibit [characteristics] which [support/challenge] the efficient market hypothesis.\n",
    "3. Cross-market relationships show [patterns] of information flow between related markets.\n",
    "4. Time-varying efficiency analysis reveals [patterns] as markets progress.\n",
    "\n",
    "These findings contribute to understanding how prediction markets aggregate information and their effectiveness as forecasting tools."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1aec84c",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'src'",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mModuleNotFoundError\u001b[39m                       Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[2]\u001b[39m\u001b[32m, line 29\u001b[39m\n\u001b[32m     26\u001b[39m     sys.path.append(\u001b[33m'\u001b[39m\u001b[33m../src\u001b[39m\u001b[33m'\u001b[39m)\n\u001b[32m     28\u001b[39m \u001b[38;5;66;03m# Import utility functions\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m29\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01msrc\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mutils\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdata_loader\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m load_main_dataset, load_trade_data, get_sample_market_ids\n\u001b[32m     31\u001b[39m \u001b[38;5;66;03m# Load the main dataset\u001b[39;00m\n\u001b[32m     32\u001b[39m \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33mLoading main dataset...\u001b[39m\u001b[33m\"\u001b[39m)\n",
      "\u001b[31mModuleNotFoundError\u001b[39m: No module named 'src'"
     ]
    }
   ],
   "source": [
    "# Market Efficiency Analysis\n",
    "# -------------------------\n",
    "# This notebook provides tools for analyzing the efficiency of prediction markets.\n",
    "\n",
    "import os\n",
    "import sys\n",
    "sys.path.append(os.path.abspath('.'))\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from statsmodels.tsa.stattools import acf, pacf, adfuller\n",
    "from statsmodels.tsa.ar_model import AutoReg\n",
    "from statsmodels.graphics.tsaplots import plot_acf, plot_pacf\n",
    "import warnings\n",
    "from tqdm.notebook import tqdm\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Add the src directory to the path if it isn't already there\n",
    "if '../src' not in sys.path:\n",
    "    sys.path.append('../src')\n",
    "\n",
    "# Import utility functions\n",
    "from src.utils.data_loader import load_main_dataset, load_trade_data, get_sample_market_ids\n",
    "\n",
    "# Load the main dataset\n",
    "print(\"Loading main dataset...\")\n",
    "main_df = load_main_dataset('data/cleaned_election_data.csv')\n",
    "print(f\"Loaded dataset with {main_df.shape[0]} rows and {main_df.shape[1]} columns\")\n",
    "\n",
    "# Check column names\n",
    "print(\"\\nColumn names in the dataset:\")\n",
    "print(main_df.columns.tolist())\n",
    "\n",
    "# Determine ID column\n",
    "id_column = None\n",
    "if 'market_id' in main_df.columns:\n",
    "    id_column = 'market_id'\n",
    "elif 'id' in main_df.columns:\n",
    "    id_column = 'id'\n",
    "else:\n",
    "    # Use the first column as ID\n",
    "    id_column = main_df.columns[0]\n",
    "    print(f\"Using {id_column} as the ID column\")\n",
    "\n",
    "# Display some sample data\n",
    "print(\"\\nSample data:\")\n",
    "display(main_df.head())\n",
    "\n",
    "# Get a list of market IDs for analysis\n",
    "sort_column = 'volumeNum' if 'volumeNum' in main_df.columns else id_column\n",
    "sample_markets = main_df.sort_values(sort_column, ascending=False)[id_column].unique()[:10]\n",
    "print(f\"\\nSelected {len(sample_markets)} markets for analysis\")\n",
    "print(sample_markets)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6977502f",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Function to preprocess market data\n",
    "def preprocess_market_data(market_id, resample='1min'):\n",
    "    \"\"\"\n",
    "    Convert raw trade data to time series of prices and returns.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_id : str\n",
    "        The ID of the market to analyze\n",
    "    resample : str\n",
    "        Frequency to resample the time series (default: '1min')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with columns: timestamp, price, log_return\n",
    "    \"\"\"\n",
    "    # Load trade data for the specific market\n",
    "    trades_df = load_trade_data(market_id, trades_dir=\"data/trades\")\n",
    "    \n",
    "    if trades_df is None or len(trades_df) < 30:\n",
    "        print(f\"Insufficient trade data for market {market_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure timestamp is a datetime type\n",
    "    if not pd.api.types.is_datetime64_any_dtype(trades_df['timestamp']):\n",
    "        trades_df['timestamp'] = pd.to_datetime(trades_df['timestamp'])\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    trades_df = trades_df.sort_values('timestamp')\n",
    "    \n",
    "    # Ensure price is numeric\n",
    "    if 'price' in trades_df.columns:\n",
    "        trades_df['price'] = pd.to_numeric(trades_df['price'], errors='coerce')\n",
    "    elif 'price_num' in trades_df.columns:\n",
    "        trades_df['price'] = pd.to_numeric(trades_df['price_num'], errors='coerce')\n",
    "    else:\n",
    "        print(f\"No price column found for market {market_id}\")\n",
    "        return None\n",
    "    \n",
    "    # Drop rows with NaN prices\n",
    "    trades_df = trades_df.dropna(subset=['price'])\n",
    "    \n",
    "    # Resample to regular intervals\n",
    "    trades_df = trades_df.set_index('timestamp')\n",
    "    price_series = trades_df['price'].resample(resample).last()\n",
    "    \n",
    "    # Fill missing values using forward fill\n",
    "    price_series = price_series.ffill()\n",
    "    \n",
    "    # Calculate log returns\n",
    "    log_returns = np.log(price_series / price_series.shift(1))\n",
    "    \n",
    "    # Create DataFrame\n",
    "    result_df = pd.DataFrame({\n",
    "        'price': price_series,\n",
    "        'log_return': log_returns\n",
    "    })\n",
    "    \n",
    "    # Drop rows with NaN\n",
    "    result_df = result_df.dropna()\n",
    "    \n",
    "    return result_df\n",
    "\n",
    "# Test the preprocessing function on one market\n",
    "test_market_id = sample_markets[0]\n",
    "print(f\"\\nTesting preprocessing on market {test_market_id}\")\n",
    "market_data = preprocess_market_data(test_market_id)\n",
    "\n",
    "if market_data is not None:\n",
    "    print(f\"Successfully processed market data with {len(market_data)} rows\")\n",
    "    display(market_data.head())\n",
    "    \n",
    "    # Plot price series\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(market_data.index, market_data['price'])\n",
    "    plt.title(f'Price Series for Market {test_market_id}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Price')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "    \n",
    "    # Plot return series\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.plot(market_data.index, market_data['log_return'])\n",
    "    plt.title(f'Log Return Series for Market {test_market_id}')\n",
    "    plt.xlabel('Date')\n",
    "    plt.ylabel('Log Return')\n",
    "    plt.grid(True, alpha=0.3)\n",
    "    plt.show()\n",
    "else:\n",
    "    print(\"Failed to process market data. Let's try another market.\")\n",
    "    if len(sample_markets) > 1:\n",
    "        test_market_id = sample_markets[1]\n",
    "        print(f\"Trying market {test_market_id}\")\n",
    "        market_data = preprocess_market_data(test_market_id)\n",
    "        if market_data is not None:\n",
    "            print(f\"Successfully processed market data with {len(market_data)} rows\")\n",
    "            display(market_data.head())\n",
    "\n",
    "# Function to run autocorrelation tests\n",
    "def run_autocorrelation_tests(returns, lags=[60, 360, 1440]):\n",
    "    \"\"\"\n",
    "    Run ACF/PACF tests on return series.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    returns : pd.Series\n",
    "        Series of log returns\n",
    "    lags : list\n",
    "        List of lag periods to test (in minutes)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with ACF/PACF results and significance\n",
    "    \"\"\"\n",
    "    results = {}\n",
    "    \n",
    "    for lag in lags:\n",
    "        # Limit lag to length of series\n",
    "        effective_lag = min(lag, len(returns) - 1)\n",
    "        \n",
    "        if effective_lag < 5:  # Skip if too few observations\n",
    "            continue\n",
    "            \n",
    "        # Calculate ACF and PACF\n",
    "        acf_values = acf(returns, nlags=effective_lag, fft=True)\n",
    "        pacf_values = pacf(returns, nlags=effective_lag)\n",
    "        \n",
    "        # Create result entry\n",
    "        lag_key = f\"{effective_lag}min\"\n",
    "        results[lag_key] = {\n",
    "            'acf': acf_values.tolist(),\n",
    "            'pacf': pacf_values.tolist()\n",
    "        }\n",
    "        \n",
    "        # Create plots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(15, 5))\n",
    "        plot_acf(returns, lags=effective_lag, ax=ax1, title=f'ACF - Lag {lag_key}')\n",
    "        plot_pacf(returns, lags=effective_lag, ax=ax2, title=f'PACF - Lag {lag_key}')\n",
    "        plt.tight_layout()\n",
    "        plt.show()\n",
    "    \n",
    "    return results\n",
    "\n",
    "# Function to run ADF test\n",
    "def run_adf_test(series, series_type='price'):\n",
    "    \"\"\"\n",
    "    Run Augmented Dickey-Fuller test for unit root.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    series : pd.Series\n",
    "        Time series to test\n",
    "    series_type : str\n",
    "        Type of series ('price' or 'return')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with test results\n",
    "    \"\"\"\n",
    "    # Run ADF test\n",
    "    result = adfuller(series.dropna())\n",
    "    \n",
    "    # Format results\n",
    "    adf_result = {\n",
    "        'adf_statistic': result[0],\n",
    "        'pvalue': result[1],\n",
    "        'critical_values': result[4],\n",
    "        'is_stationary': result[1] < 0.05  # Reject unit root if p-value < 0.05\n",
    "    }\n",
    "    \n",
    "    return adf_result\n",
    "\n",
    "# Test autocorrelation and ADF test on the market data\n",
    "if market_data is not None and len(market_data) > 60:\n",
    "    print(\"\\nRunning autocorrelation tests...\")\n",
    "    acf_results = run_autocorrelation_tests(market_data['log_return'], lags=[30, 60])\n",
    "    \n",
    "    print(\"\\nRunning ADF test on price series...\")\n",
    "    adf_price = run_adf_test(market_data['price'], 'price')\n",
    "    print(\"ADF test on price series:\")\n",
    "    print(f\"ADF Statistic: {adf_price['adf_statistic']:.4f}\")\n",
    "    print(f\"p-value: {adf_price['pvalue']:.4f}\")\n",
    "    print(f\"Is stationary: {adf_price['is_stationary']}\")\n",
    "    \n",
    "    print(\"\\nRunning ADF test on return series...\")\n",
    "    adf_return = run_adf_test(market_data['log_return'], 'return')\n",
    "    print(\"ADF test on return series:\")\n",
    "    print(f\"ADF Statistic: {adf_return['adf_statistic']:.4f}\")\n",
    "    print(f\"p-value: {adf_return['pvalue']:.4f}\")\n",
    "    print(f\"Is stationary: {adf_return['is_stationary']}\")\n",
    "else:\n",
    "    print(\"Not enough data to run time series tests\")\n",
    "\n",
    "# Function to run a simplified efficiency analysis on a market\n",
    "def analyze_market_efficiency(market_id):\n",
    "    \"\"\"\n",
    "    Run a simplified market efficiency analysis on a single market.\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_id : str\n",
    "        ID of the market to analyze\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with efficiency results\n",
    "    \"\"\"\n",
    "    result = {'market_id': market_id}\n",
    "    \n",
    "    # Preprocess market data\n",
    "    market_data = preprocess_market_data(market_id)\n",
    "    if market_data is None or len(market_data) < 30:\n",
    "        return None\n",
    "    \n",
    "    # Run ADF tests\n",
    "    result['adf_price'] = run_adf_test(market_data['price'], 'price')\n",
    "    result['adf_return'] = run_adf_test(market_data['log_return'], 'return')\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    result['price_mean'] = market_data['price'].mean()\n",
    "    result['price_std'] = market_data['price'].std()\n",
    "    result['price_range'] = market_data['price'].max() - market_data['price'].min()\n",
    "    result['return_mean'] = market_data['log_return'].mean()\n",
    "    result['return_std'] = market_data['log_return'].std()\n",
    "    \n",
    "    # Check for autocorrelation (simplified)\n",
    "    acf_values = acf(market_data['log_return'], nlags=10, fft=True)\n",
    "    result['significant_autocorrelation'] = any(abs(acf_values[1:]) > 1.96 / np.sqrt(len(market_data)))\n",
    "    \n",
    "    # Fit AR(1) model\n",
    "    if len(market_data) > 10:\n",
    "        try:\n",
    "            model = AutoReg(market_data['log_return'], lags=1)\n",
    "            model_fit = model.fit()\n",
    "            \n",
    "            result['ar1_coefficient'] = model_fit.params[1] if len(model_fit.params) > 1 else 0\n",
    "            result['ar1_pvalue'] = model_fit.pvalues[1] if len(model_fit.pvalues) > 1 else 1\n",
    "            result['ar1_significant'] = result['ar1_pvalue'] < 0.05\n",
    "        except Exception as e:\n",
    "            print(f\"Error fitting AR model for market {market_id}: {e}\")\n",
    "            result['ar1_coefficient'] = 0\n",
    "            result['ar1_pvalue'] = 1\n",
    "            result['ar1_significant'] = False\n",
    "    \n",
    "    return result\n",
    "\n",
    "# Run the analysis on sample markets\n",
    "print(\"\\nRunning simplified efficiency analysis on sample markets...\")\n",
    "efficiency_results = []\n",
    "\n",
    "for market_id in tqdm(sample_markets[:5]):  # Limit to first 5 markets for quick testing\n",
    "    result = analyze_market_efficiency(market_id)\n",
    "    if result:\n",
    "        efficiency_results.append(result)\n",
    "\n",
    "# Display results\n",
    "if efficiency_results:\n",
    "    efficiency_df = pd.DataFrame(efficiency_results)\n",
    "    print(\"\\nEfficiency analysis results:\")\n",
    "    display(efficiency_df)\n",
    "    \n",
    "    # Summary of efficiency metrics\n",
    "    efficiency_summary = {\n",
    "        'markets_analyzed': len(efficiency_df),\n",
    "        'price_non_stationary': sum(~efficiency_df['adf_price'].apply(lambda x: x['is_stationary'])),\n",
    "        'return_stationary': sum(efficiency_df['adf_return'].apply(lambda x: x['is_stationary'])),\n",
    "        'significant_autocorrelation': sum(efficiency_df['significant_autocorrelation']),\n",
    "        'significant_ar1': sum(efficiency_df['ar1_significant'])\n",
    "    }\n",
    "    \n",
    "    print(\"\\nSummary of efficiency metrics:\")\n",
    "    for key, value in efficiency_summary.items():\n",
    "        print(f\"{key}: {value}\")\n",
    "    \n",
    "    # Calculate percentages\n",
    "    if len(efficiency_df) > 0:\n",
    "        print(\"\\nPercentages:\")\n",
    "        print(f\"Non-stationary price series: {efficiency_summary['price_non_stationary'] / len(efficiency_df) * 100:.1f}%\")\n",
    "        print(f\"Stationary return series: {efficiency_summary['return_stationary'] / len(efficiency_df) * 100:.1f}%\")\n",
    "        print(f\"Significant autocorrelation: {efficiency_summary['significant_autocorrelation'] / len(efficiency_df) * 100:.1f}%\")\n",
    "        print(f\"Significant AR(1) coefficient: {efficiency_summary['significant_ar1'] / len(efficiency_df) * 100:.1f}%\")\n",
    "else:\n",
    "    print(\"No efficiency results available\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

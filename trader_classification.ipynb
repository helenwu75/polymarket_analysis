{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1926d6c",
   "metadata": {},
   "source": [
    "# 1. Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ceb85e19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Warning: Could not import data_loader utilities. Some functions may not work.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import json\n",
    "from datetime import datetime\n",
    "from typing import Dict, List, Optional, Union, Tuple\n",
    "\n",
    "# Data processing imports\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "# Visualization imports\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "# Machine learning imports\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Optional imports - handle gracefully if not available\n",
    "try:\n",
    "    from scipy import stats\n",
    "    SCIPY_AVAILABLE = True\n",
    "except ImportError:\n",
    "    SCIPY_AVAILABLE = False\n",
    "\n",
    "# Add parent directory to path for importing utilities\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir) if current_dir.endswith('notebooks') else current_dir\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Import utility functions from the project\n",
    "try:\n",
    "    from src.utils.data_loader import (\n",
    "        load_main_dataset, \n",
    "        load_trade_data, \n",
    "        load_data,\n",
    "        get_token_ids_for_market,\n",
    "        find_token_id_file\n",
    "    )\n",
    "except ImportError:\n",
    "    print(\"Warning: Could not import data_loader utilities. Some functions may not work.\")\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Suppress warnings\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "b6880e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 1. Configuration\n",
    "MARKET_SELECTION = {\n",
    "    'by_name': [\n",
    "        \"Will Donald Trump win the 2024 US Presidential Election?\",\n",
    "        \"Will Kamala Harris win the 2024 US Presidential Election?\"\n",
    "    ],\n",
    "    'by_id': [],  # Add specific market IDs here if needed\n",
    "    'top_n_by_volume': 0,  # Set to a number > 0 to analyze top N markets by volume\n",
    "    'min_volume': 0,  # Minimum volume threshold\n",
    "    'date_range': None,  # Set to (start_date, end_date) to filter by date\n",
    "}\n",
    "\n",
    "# Analysis Configuration\n",
    "ANALYSIS_CONFIG = {\n",
    "    'run_trader_distribution': True,\n",
    "    'run_whale_identification': True,\n",
    "    'run_trader_classification': True,\n",
    "    'run_market_dynamics': True,\n",
    "    'whale_threshold': 0.01,  # Top 1% traders by volume are considered whales\n",
    "    'trader_clusters': 5,  # Number of trader clusters for classification\n",
    "    'save_results': True,  # Whether to save results to files\n",
    "    'results_dir': 'results/trader_analysis',\n",
    "    'generate_plots': True  # Whether to generate plots\n",
    "}\n",
    "\n",
    "# Create the results directory\n",
    "os.makedirs(ANALYSIS_CONFIG['results_dir'], exist_ok=True)\n",
    "\n",
    "# Initialize results dictionary\n",
    "all_results = {}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a33e0",
   "metadata": {},
   "source": [
    "# 2. Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "83e5f2a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trade_data_for_analysis(market_ids):\n",
    "    \"\"\"\n",
    "    Load and combine trade data for multiple markets\n",
    "    \n",
    "    Parameters:\n",
    "    ----------\n",
    "    market_ids : list\n",
    "        List of market IDs to load\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Combined trade data for all markets\n",
    "    \"\"\"\n",
    "    all_trades = []\n",
    "    \n",
    "    for market_id in market_ids:\n",
    "        print(f\"Loading trade data for market {market_id}...\")\n",
    "        \n",
    "        try:\n",
    "            # Use the imported load_trade_data function\n",
    "            market_trades = load_trade_data(market_id)\n",
    "            \n",
    "            if market_trades is not None and len(market_trades) > 0:\n",
    "                # Add market_id if not already present\n",
    "                if 'market_id' not in market_trades.columns:\n",
    "                    market_trades['market_id'] = market_id\n",
    "                \n",
    "                all_trades.append(market_trades)\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading trade data for market {market_id}: {e}\")\n",
    "    \n",
    "    if not all_trades:\n",
    "        print(\"No trade data found for selected markets\")\n",
    "        return None\n",
    "    \n",
    "    combined_trades = pd.concat(all_trades, ignore_index=True)\n",
    "    print(f\"Loaded {len(combined_trades):,} trades from {len(market_ids)} markets\")\n",
    "    \n",
    "    return combined_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7267f62f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_market_data(market_config):\n",
    "    \"\"\"\n",
    "    Load market data based on configuration\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_config : dict\n",
    "        Dictionary with market selection parameters\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (market_data, trade_data) - DataFrames with market and trade data\n",
    "    \"\"\"\n",
    "    print(\"Loading main dataset...\")\n",
    "    market_data = load_main_dataset('data/cleaned_election_data.csv')\n",
    "    \n",
    "    if market_data is None:\n",
    "        print(\"Failed to load market data\")\n",
    "        return None, None\n",
    "    \n",
    "    # Filter markets based on configuration\n",
    "    selected_markets = market_data.copy()\n",
    "    \n",
    "    # Filter by name if specified\n",
    "    if market_config['by_name'] and len(market_config['by_name']) > 0:\n",
    "        selected_markets = selected_markets[selected_markets['question'].isin(market_config['by_name'])]\n",
    "        print(f\"Selected {len(selected_markets)} markets by name\")\n",
    "    \n",
    "    # Filter by ID if specified\n",
    "    if market_config['by_id'] and len(market_config['by_id']) > 0:\n",
    "        id_filter = selected_markets['id'].isin(market_config['by_id'])\n",
    "        if len(selected_markets) > 0:\n",
    "            selected_markets = selected_markets[id_filter]\n",
    "        else:\n",
    "            selected_markets = market_data[id_filter]\n",
    "        print(f\"Selected {len(selected_markets)} markets by ID\")\n",
    "    \n",
    "    # Filter by top N by volume\n",
    "    if market_config['top_n_by_volume'] > 0:\n",
    "        if 'volumeNum' in market_data.columns:\n",
    "            top_markets = market_data.sort_values('volumeNum', ascending=False).head(\n",
    "                market_config['top_n_by_volume'])\n",
    "            \n",
    "            if len(selected_markets) > 0:\n",
    "                # Intersect with already selected markets\n",
    "                selected_markets = selected_markets[selected_markets['id'].isin(top_markets['id'])]\n",
    "            else:\n",
    "                selected_markets = top_markets\n",
    "                \n",
    "            print(f\"Selected {len(selected_markets)} top markets by volume\")\n",
    "    \n",
    "    # Apply minimum volume filter if specified\n",
    "    if market_config['min_volume'] > 0 and 'volumeNum' in market_data.columns:\n",
    "        volume_filter = selected_markets['volumeNum'] >= market_config['min_volume']\n",
    "        selected_markets = selected_markets[volume_filter]\n",
    "        print(f\"Selected {len(selected_markets)} markets with minimum volume {market_config['min_volume']}\")\n",
    "    \n",
    "    # If no markets were selected, use default selection\n",
    "    if len(selected_markets) == 0:\n",
    "        print(\"No markets matched selection criteria. Using default selection.\")\n",
    "        if market_config['top_n_by_volume'] > 0:\n",
    "            selected_markets = market_data.sort_values('volumeNum', ascending=False).head(\n",
    "                market_config['top_n_by_volume'])\n",
    "        else:\n",
    "            selected_markets = market_data.head(2)  # Default to first 2 markets\n",
    "    \n",
    "    print(f\"Final selection: {len(selected_markets)} markets\")\n",
    "    \n",
    "    # Display selected markets\n",
    "    if len(selected_markets) > 0:\n",
    "        print(\"\\nSelected Markets:\")\n",
    "        for i, (idx, row) in enumerate(selected_markets.iterrows()):\n",
    "            market_name = row['question'] if 'question' in row else f\"Market {row['id']}\"\n",
    "            print(f\"{i+1}. {market_name} (ID: {row['id']})\")\n",
    "    \n",
    "    # Load trade data for selected markets\n",
    "    market_ids = selected_markets['id'].tolist()\n",
    "    trade_data = load_trade_data_for_analysis(market_ids=market_ids)\n",
    "    \n",
    "    return selected_markets, trade_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "78b7932a",
   "metadata": {},
   "source": [
    "# 3. Data Processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "38256e4c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_trade_data(trade_data):\n",
    "    \"\"\"\n",
    "    Preprocess trade data for analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trade_data : pd.DataFrame\n",
    "        Raw trade data\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Cleaned and preprocessed trade data\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"DATA PREPROCESSING\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if trade_data is None or len(trade_data) == 0:\n",
    "        print(\"No trade data to preprocess\")\n",
    "        return None\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    df = trade_data.copy()\n",
    "    \n",
    "    # 1. Handle missing values\n",
    "    initial_rows = len(df)\n",
    "    print(f\"Initial rows: {initial_rows:,}\")\n",
    "    \n",
    "    # Check for missing values in key columns\n",
    "    missing_values = df.isnull().sum()\n",
    "    missing_cols = missing_values[missing_values > 0]\n",
    "    if len(missing_cols) > 0:\n",
    "        print(\"\\nMissing values in key columns:\")\n",
    "        for col, missing in missing_cols.items():\n",
    "            print(f\"  {col}: {missing:,} ({missing/len(df)*100:.1f}%)\")\n",
    "    \n",
    "    # Drop rows with missing critical values\n",
    "    critical_columns = ['trader_id']\n",
    "    if any(col in df.columns for col in critical_columns):\n",
    "        present_critical = [col for col in critical_columns if col in df.columns]\n",
    "        df = df.dropna(subset=present_critical)\n",
    "        print(f\"Rows after dropping missing critical values: {len(df):,}\")\n",
    "    \n",
    "    # 2. Handle timestamps\n",
    "    if 'timestamp' in df.columns:\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):\n",
    "            print(\"Converting timestamps to datetime...\")\n",
    "            try:\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "                df = df.dropna(subset=['timestamp'])\n",
    "                print(f\"Converted {len(df):,} timestamps\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error converting timestamps: {e}\")\n",
    "                # Create a sequential index if conversion fails\n",
    "                print(\"Creating sequential timestamps instead\")\n",
    "                df = df.sort_index()\n",
    "                df['timestamp'] = pd.Series(range(len(df)))\n",
    "        \n",
    "        # Sort by timestamp\n",
    "        df = df.sort_values('timestamp')\n",
    "    \n",
    "    # 3. Normalize trader IDs\n",
    "    # Ensure consistent trader ID format\n",
    "    if 'maker_id' in df.columns and 'trader_id' not in df.columns:\n",
    "        df['trader_id'] = df['maker_id']\n",
    "        print(\"Created trader_id from maker_id\")\n",
    "    elif 'maker' in df.columns and 'trader_id' not in df.columns:\n",
    "        df['trader_id'] = df['maker']\n",
    "        print(\"Created trader_id from maker column\")\n",
    "    \n",
    "    # Check if there's a trader_id column now\n",
    "    if 'trader_id' not in df.columns:\n",
    "        print(\"Warning: No trader_id column available\")\n",
    "    else:\n",
    "        # Convert trader_id to string type for consistency\n",
    "        df['trader_id'] = df['trader_id'].astype(str)\n",
    "        unique_traders = df['trader_id'].nunique()\n",
    "        print(f\"Unique traders identified: {unique_traders:,}\")\n",
    "    \n",
    "    # 4. Normalize trade amounts\n",
    "    # Check if we need to scale trade amounts\n",
    "    if 'trade_amount' in df.columns:\n",
    "        # Check if values are extremely large (likely in base units)\n",
    "        median_value = df['trade_amount'].median()\n",
    "        \n",
    "        if median_value > 10000:  # Threshold suggesting base units\n",
    "            scaling_factor = 1e6  # Standard scaling for USDC/USD\n",
    "            print(f\"Scaling trade_amount by factor of {scaling_factor:,.0f}\")\n",
    "            \n",
    "            # Store original values\n",
    "            df['trade_amount_original'] = df['trade_amount']\n",
    "            \n",
    "            # Scale values\n",
    "            df['trade_amount'] = df['trade_amount'] / scaling_factor\n",
    "    elif 'size' in df.columns and 'trade_amount' not in df.columns:\n",
    "        # Convert size to numeric if needed\n",
    "        df['size'] = pd.to_numeric(df['size'], errors='coerce')\n",
    "        \n",
    "        # Check if values are extremely large\n",
    "        median_value = df['size'].median()\n",
    "        \n",
    "        if median_value > 10000:  # Threshold suggesting base units\n",
    "            scaling_factor = 1e6  # Standard scaling for USDC/USD\n",
    "            print(f\"Creating trade_amount from size with scaling factor of {scaling_factor:,.0f}\")\n",
    "            \n",
    "            # Create scaled trade_amount\n",
    "            df['trade_amount'] = df['size'] / scaling_factor\n",
    "        else:\n",
    "            # Use size directly\n",
    "            print(\"Creating trade_amount from size (no scaling needed)\")\n",
    "            df['trade_amount'] = df['size']\n",
    "    else:\n",
    "        print(\"Warning: No trade_amount or size column available\")\n",
    "        # Create a default trade_amount column if needed\n",
    "        df['trade_amount'] = 1.0\n",
    "        print(\"Created default trade_amount column with value 1.0\")\n",
    "    \n",
    "    # 5. Add price change column if price exists\n",
    "    if 'price' in df.columns:\n",
    "        # Convert price to numeric\n",
    "        df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "        \n",
    "        # Calculate price changes\n",
    "        df['price_change'] = df['price'].diff()\n",
    "        \n",
    "        # Calculate summary statistics\n",
    "        print(\"\\nPrice statistics:\")\n",
    "        print(f\"  Min: {df['price'].min():.6f}\")\n",
    "        print(f\"  Max: {df['price'].max():.6f}\")\n",
    "        print(f\"  Mean: {df['price'].mean():.6f}\")\n",
    "        print(f\"  Std Dev: {df['price'].std():.6f}\")\n",
    "    \n",
    "    # Print summary of preprocessing\n",
    "    print(\"\\nPreprocessing complete:\")\n",
    "    print(f\"Initial rows: {initial_rows:,}\")\n",
    "    print(f\"Final rows: {len(df):,}\")\n",
    "    print(f\"Dropped rows: {initial_rows - len(df):,} ({(initial_rows - len(df))/initial_rows*100:.1f}%)\")\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "36143acc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def calculate_gini(values):\n",
    "    \"\"\"\n",
    "    Calculate Gini coefficient for an array of values\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    values : array-like\n",
    "        Array of values (e.g., trader volumes)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Gini coefficient (0 = perfect equality, 1 = perfect inequality)\n",
    "    \"\"\"\n",
    "    # Handle edge cases\n",
    "    if len(values) <= 1 or np.sum(values) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Sort values\n",
    "    sorted_values = np.sort(values)\n",
    "    n = len(sorted_values)\n",
    "    \n",
    "    # Calculate cumulative sum\n",
    "    cumsum = np.cumsum(sorted_values)\n",
    "    \n",
    "    # Calculate Gini coefficient using the formula\n",
    "    return (n + 1 - 2 * np.sum((n + 1 - np.arange(1, n+1)) * sorted_values) / np.sum(sorted_values)) / n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dabdc3",
   "metadata": {},
   "source": [
    "# 4. Analysis Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2c9ea0ca",
   "metadata": {},
   "source": [
    "## a. Trader Distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "77e8c6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 4 μs, sys: 0 ns, total: 4 μs\n",
      "Wall time: 5.96 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "def analyze_trader_distribution(trade_data, config, save_prefix='trader_distribution'):\n",
    "    \"\"\"\n",
    "    Analyze trader distribution patterns\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trade_data : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    config : dict\n",
    "        Analysis configuration\n",
    "    save_prefix : str\n",
    "        Prefix for saved files\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with analysis results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"TRADER DISTRIBUTION ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if trade_data is None or len(trade_data) == 0:\n",
    "        print(\"No trade data available for analysis\")\n",
    "        return None\n",
    "    \n",
    "    results_dir = config['results_dir']\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Calculate trader-level metrics\n",
    "    trader_metrics = trade_data.groupby('trader_id').agg({\n",
    "        'trade_amount': ['sum', 'mean', 'count'],\n",
    "        'price': ['mean', 'std'] if 'price' in trade_data.columns else None\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    trader_metrics.columns = [\n",
    "        f\"{col[0]}_{col[1]}\" if col[1] else col[0] \n",
    "        for col in trader_metrics.columns\n",
    "    ]\n",
    "    \n",
    "    # Reset index to make trader_id a column\n",
    "    trader_metrics = trader_metrics.reset_index()\n",
    "    \n",
    "    # Calculate key statistics\n",
    "    total_traders = len(trader_metrics)\n",
    "    total_volume = trader_metrics['trade_amount_sum'].sum()\n",
    "    avg_trades_per_trader = trader_metrics['trade_amount_count'].mean()\n",
    "    median_trades_per_trader = trader_metrics['trade_amount_count'].median()\n",
    "    \n",
    "    print(f\"Total traders: {total_traders:,}\")\n",
    "    print(f\"Total volume: {total_volume:,.2f}\")\n",
    "    print(f\"Average trades per trader: {avg_trades_per_trader:.2f}\")\n",
    "    print(f\"Median trades per trader: {median_trades_per_trader:.0f}\")\n",
    "    \n",
    "    # Create visualizations if enabled\n",
    "    if config['generate_plots']:\n",
    "        # 1. Trade count distribution\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Use log scale for better visualization\n",
    "        log_counts = np.log10(trader_metrics['trade_amount_count'] + 1)  # +1 to handle zeros\n",
    "        \n",
    "        plt.hist(log_counts, bins=50, alpha=0.7, color='skyblue')\n",
    "        plt.title('Trader Activity Distribution (Log Scale)')\n",
    "        plt.xlabel('Log10(Number of Trades)')\n",
    "        plt.ylabel('Number of Traders')\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # Save and display plot\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f\"{save_prefix}_activity.png\"), dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "        # 2. Volume distribution\n",
    "        plt.figure(figsize=(12, 8))\n",
    "        \n",
    "        # Use log scale for better visualization\n",
    "        log_volumes = np.log10(trader_metrics['trade_amount_sum'] + 1)  # +1 to handle zeros\n",
    "        \n",
    "        plt.hist(log_volumes, bins=50, alpha=0.7, color='green')\n",
    "        plt.title('Trader Volume Distribution (Log Scale)')\n",
    "        plt.xlabel('Log10(Trading Volume)')\n",
    "        plt.ylabel('Number of Traders')\n",
    "        plt.grid(alpha=0.3)\n",
    "        \n",
    "        # Save and display plot\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f\"{save_prefix}_volume.png\"), dpi=300)\n",
    "        plt.show()\n",
    "    \n",
    "    # Create summary statistics for return\n",
    "    deciles = [10, 20, 30, 40, 50, 60, 70, 80, 90, 95, 99]\n",
    "    volume_percentiles = {\n",
    "        f\"{p}th_percentile\": trader_metrics['trade_amount_sum'].quantile(p/100)\n",
    "        for p in deciles\n",
    "    }\n",
    "    \n",
    "    activity_percentiles = {\n",
    "        f\"{p}th_percentile\": trader_metrics['trade_amount_count'].quantile(p/100)\n",
    "        for p in deciles\n",
    "    }\n",
    "    \n",
    "    summary = {\n",
    "        'total_traders': total_traders,\n",
    "        'total_volume': total_volume,\n",
    "        'avg_trades_per_trader': avg_trades_per_trader,\n",
    "        'median_trades_per_trader': median_trades_per_trader,\n",
    "        'volume_percentiles': volume_percentiles,\n",
    "        'activity_percentiles': activity_percentiles\n",
    "    }\n",
    "    \n",
    "    # Save summary if enabled\n",
    "    if config['save_results']:\n",
    "        with open(os.path.join(results_dir, f\"{save_prefix}_summary.json\"), 'w') as f:\n",
    "            json.dump(summary, f, indent=2, default=str)\n",
    "    \n",
    "    return summary, trader_metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1009558",
   "metadata": {},
   "source": [
    "\n",
    "## b. Whale Identification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "abd033ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1 μs, sys: 0 ns, total: 1 μs\n",
      "Wall time: 1.67 μs\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "# Fix for the identify_whales function's Lorenz curve plotting\n",
    "def identify_whales(trade_data, config, save_prefix='whale_identification'):\n",
    "    \"\"\"\n",
    "    Identify whale traders based on specified criteria\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trade_data : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    config : dict\n",
    "        Analysis configuration\n",
    "    save_prefix : str\n",
    "        Prefix for saved files\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        (whale_ids, whale_results) - List of whale IDs and analysis results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"WHALE TRADER IDENTIFICATION\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if trade_data is None or len(trade_data) == 0:\n",
    "        print(\"No trade data available for analysis\")\n",
    "        return [], {}\n",
    "    \n",
    "    # Ensure we have the necessary columns\n",
    "    if 'trader_id' not in trade_data.columns or 'trade_amount' not in trade_data.columns:\n",
    "        print(\"Error: Missing required columns (trader_id, trade_amount)\")\n",
    "        return [], {}\n",
    "    \n",
    "    # Get configuration parameters\n",
    "    threshold = config['whale_threshold']\n",
    "    results_dir = config['results_dir']\n",
    "    generate_plots = config['generate_plots']\n",
    "    \n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Group trades by trader and calculate total volume\n",
    "    trader_volumes = trade_data.groupby('trader_id')['trade_amount'].sum().sort_values(ascending=False)\n",
    "    \n",
    "    # Calculate total volume\n",
    "    total_volume = trader_volumes.sum()\n",
    "    total_traders = len(trader_volumes)\n",
    "    \n",
    "    print(f\"Total traders: {total_traders:,}\")\n",
    "    print(f\"Total volume: {total_volume:,.2f}\")\n",
    "    \n",
    "    # Create cumulative volume percentages\n",
    "    cumulative_volumes = trader_volumes.cumsum()\n",
    "    cumulative_percentages = cumulative_volumes / total_volume * 100\n",
    "    \n",
    "    # Create DataFrame for analysis\n",
    "    trader_analysis = pd.DataFrame({\n",
    "        'trader_id': trader_volumes.index,\n",
    "        'volume': trader_volumes.values,\n",
    "        'cumulative_volume': cumulative_volumes.values,\n",
    "        'volume_pct': trader_volumes.values / total_volume * 100,\n",
    "        'cumulative_pct': cumulative_percentages.values\n",
    "    })\n",
    "    \n",
    "    # Calculate Gini coefficient\n",
    "    gini = calculate_gini(trader_volumes.values)\n",
    "    print(f\"Volume concentration (Gini coefficient): {gini:.4f}\")\n",
    "    \n",
    "    # Define percentile thresholds to evaluate\n",
    "    percentile_thresholds = [0.001, 0.01, 0.05, 0.1]\n",
    "    \n",
    "    # Calculate metrics for each threshold\n",
    "    threshold_metrics = []\n",
    "    for pct in percentile_thresholds:\n",
    "        num_whales = max(1, int(total_traders * pct))\n",
    "        whale_volume = trader_volumes.iloc[:num_whales].sum()\n",
    "        whale_volume_pct = whale_volume / total_volume * 100\n",
    "        \n",
    "        # Store metrics\n",
    "        threshold_metrics.append({\n",
    "            'threshold': pct,\n",
    "            'threshold_label': f\"Top {pct*100:.1f}%\",\n",
    "            'num_whales': num_whales,\n",
    "            'whale_volume': float(whale_volume),\n",
    "            'whale_volume_pct': float(whale_volume_pct),\n",
    "            'trader_pct': float(num_whales / total_traders * 100)\n",
    "        })\n",
    "        \n",
    "        print(f\"Top {pct*100:.1f}% definition ({num_whales:,} traders): {whale_volume_pct:.2f}% of volume\")\n",
    "    \n",
    "    # Calculate volume coverage thresholds\n",
    "    volume_thresholds = [50, 75, 90, 95]\n",
    "    coverage_metrics = []\n",
    "    \n",
    "    for pct in volume_thresholds:\n",
    "        # Find traders needed to reach this volume percentage\n",
    "        traders_needed = sum(cumulative_percentages < pct) + 1\n",
    "        traders_needed = min(traders_needed, len(trader_volumes))\n",
    "        \n",
    "        # Get the actual volume percentage\n",
    "        actual_pct = cumulative_percentages.iloc[traders_needed-1] if traders_needed <= len(cumulative_percentages) else 100\n",
    "        \n",
    "        coverage_metrics.append({\n",
    "            'volume_threshold': pct,\n",
    "            'threshold_label': f\"{pct}% Volume\",\n",
    "            'num_traders': int(traders_needed),\n",
    "            'actual_volume_pct': float(actual_pct),\n",
    "            'trader_pct': float(traders_needed / total_traders * 100)\n",
    "        })\n",
    "        \n",
    "        print(f\"Traders needed for {pct}% volume: {traders_needed:,} ({traders_needed/total_traders*100:.4f}% of all traders)\")\n",
    "    \n",
    "    # Create visualizations\n",
    "    if generate_plots:\n",
    "        # Create figure for combined plots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # 1. Lorenz curve - FIX: Ensure x and y arrays have same dimension\n",
    "        x_points = np.linspace(0, 100, len(trader_volumes) + 1)\n",
    "        y_points = np.concatenate(([0], cumulative_percentages.values))\n",
    "        \n",
    "        ax1.plot(x_points, y_points, 'b-', linewidth=2, label='Volume distribution')\n",
    "        ax1.plot([0, 100], [0, 100], 'k--', label='Perfect equality')\n",
    "        ax1.fill_between(x_points, y_points, x_points, alpha=0.2)\n",
    "        \n",
    "        # Add key percentiles\n",
    "        for p in [90, 95, 99, 99.9]:\n",
    "            # Calculate index for this percentile\n",
    "            idx = min(int(total_traders * (100-p)/100), len(trader_volumes)-1)\n",
    "            if idx >= 0:\n",
    "                # Get x and y coordinates\n",
    "                x = idx / total_traders * 100\n",
    "                y = cumulative_percentages.iloc[idx] if idx < len(cumulative_percentages) else 100\n",
    "                \n",
    "                # Add reference lines\n",
    "                ax1.plot([x, x], [0, y], 'r--', alpha=0.5)\n",
    "                ax1.plot([0, x], [y, y], 'r--', alpha=0.5)\n",
    "                \n",
    "                # Add label\n",
    "                ax1.text(x + 1, 10 + (p-90)*3, f'Top {100-p}%', fontsize=10)\n",
    "        \n",
    "        ax1.set_title(f'Trading Volume Distribution (Gini: {gini:.4f})')\n",
    "        ax1.set_xlabel('Cumulative % of Traders')\n",
    "        ax1.set_ylabel('Cumulative % of Volume')\n",
    "        ax1.grid(alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # 2. Whale definition comparison\n",
    "        percent_definitions = pd.DataFrame(threshold_metrics)\n",
    "        \n",
    "        # Plot bars for percentage of traders vs percentage of volume\n",
    "        bar_width = 0.35\n",
    "        x = np.arange(len(percent_definitions))\n",
    "        \n",
    "        ax2.bar(x - bar_width/2, percent_definitions['trader_pct'], \n",
    "               bar_width, label='% of Traders', color='skyblue')\n",
    "        ax2.bar(x + bar_width/2, percent_definitions['whale_volume_pct'], \n",
    "               bar_width, label='% of Volume', color='orange')\n",
    "        \n",
    "        # Set x-axis labels\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(percent_definitions['threshold_label'])\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, v in enumerate(percent_definitions['trader_pct']):\n",
    "            ax2.text(i - bar_width/2, v + 1, f\"{v:.2f}%\", ha='center', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(percent_definitions['whale_volume_pct']):\n",
    "            ax2.text(i + bar_width/2, v + 1, f\"{v:.2f}%\", ha='center', fontsize=9)\n",
    "        \n",
    "        ax2.set_title('Whale Definitions Comparison')\n",
    "        ax2.set_ylabel('Percentage')\n",
    "        ax2.set_ylim(0, 100)\n",
    "        ax2.grid(axis='y', alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, f\"{save_prefix}_analysis.png\"), dpi=300)\n",
    "        plt.show()\n",
    "        \n",
    "        print(f\"Whale definition analysis visualizations saved to {save_prefix}_analysis.png\")\n",
    "    \n",
    "    # Use the specified threshold\n",
    "    num_whales = max(1, int(total_traders * threshold))\n",
    "    whale_ids = trader_volumes.head(num_whales).index.tolist()\n",
    "    \n",
    "    print(f\"\\nUsing top {threshold*100:.1f}% definition: {num_whales:,} whales\")\n",
    "    print(f\"Selected whale threshold volume: {trader_volumes.iloc[num_whales-1] if num_whales <= len(trader_volumes) else 0:.2f}\")\n",
    "    \n",
    "    # Save results if enabled\n",
    "    results = {\n",
    "        'gini_coefficient': gini,\n",
    "        'threshold_used': threshold,\n",
    "        'num_whales': num_whales,\n",
    "        'threshold_metrics': threshold_metrics,\n",
    "        'coverage_metrics': coverage_metrics,\n",
    "        'whale_volume_percentage': float(trader_volumes.head(num_whales).sum() / total_volume * 100)\n",
    "    }\n",
    "    \n",
    "    if config['save_results']:\n",
    "        with open(os.path.join(results_dir, f\"{save_prefix}_results.json\"), 'w') as f:\n",
    "            json.dump(results, f, indent=2, default=str)\n",
    "    \n",
    "    # Return whale IDs and analysis results\n",
    "    return whale_ids, results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "07c37592",
   "metadata": {},
   "source": [
    "## d. Trader Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bce4fde2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_trader_classification_analysis(market_selection=None, results_dir='results/trader_analysis'):\n",
    "    \"\"\"\n",
    "    Run trader classification analysis\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_selection : dict, optional\n",
    "        Market selection configuration (default: None, will use MARKET_SELECTION)\n",
    "    results_dir : str\n",
    "        Directory to save results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with classification results\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # 1. Load data\n",
    "    print(\"\\nLoading main dataset...\")\n",
    "    main_df = load_main_dataset()\n",
    "    \n",
    "    if main_df is None or main_df.empty:\n",
    "        print(\"Failed to load main dataset\")\n",
    "        return None\n",
    "    \n",
    "    # 2. Select markets\n",
    "    if market_selection is None:\n",
    "        market_selection = MARKET_SELECTION\n",
    "    \n",
    "    # Find markets\n",
    "    selected_markets = main_df.copy()\n",
    "    \n",
    "    # Filter by name if specified\n",
    "    if market_selection['by_name'] and len(market_selection['by_name']) > 0:\n",
    "        selected_markets = selected_markets[selected_markets['question'].isin(market_selection['by_name'])]\n",
    "        print(f\"Selected {len(selected_markets)} markets by name\")\n",
    "    \n",
    "    # Filter by ID if specified\n",
    "    if market_selection['by_id'] and len(market_selection['by_id']) > 0:\n",
    "        id_filter = selected_markets['id'].isin(market_selection['by_id'])\n",
    "        if len(selected_markets) > 0:\n",
    "            selected_markets = selected_markets[id_filter]\n",
    "        else:\n",
    "            selected_markets = main_df[id_filter]\n",
    "        print(f\"Selected {len(selected_markets)} markets by ID\")\n",
    "    \n",
    "    # Filter by top N by volume\n",
    "    if market_selection['top_n_by_volume'] > 0:\n",
    "        if 'volumeNum' in main_df.columns:\n",
    "            top_markets = main_df.sort_values('volumeNum', ascending=False).head(\n",
    "                market_selection['top_n_by_volume'])\n",
    "            \n",
    "            if len(selected_markets) > 0:\n",
    "                # Intersect with already selected markets\n",
    "                selected_markets = selected_markets[selected_markets['id'].isin(top_markets['id'])]\n",
    "            else:\n",
    "                selected_markets = top_markets\n",
    "                \n",
    "            print(f\"Selected {len(selected_markets)} top markets by volume\")\n",
    "    \n",
    "    # Apply minimum volume filter if specified\n",
    "    if market_selection['min_volume'] > 0 and 'volumeNum' in main_df.columns:\n",
    "        volume_filter = selected_markets['volumeNum'] >= market_selection['min_volume']\n",
    "        selected_markets = selected_markets[volume_filter]\n",
    "        print(f\"Selected {len(selected_markets)} markets with minimum volume {market_selection['min_volume']}\")\n",
    "    \n",
    "    # If no markets were selected, use default selection\n",
    "    if len(selected_markets) == 0:\n",
    "        print(\"No markets matched selection criteria. Using default selection.\")\n",
    "        if market_selection['top_n_by_volume'] > 0:\n",
    "            selected_markets = main_df.sort_values('volumeNum', ascending=False).head(\n",
    "                market_selection['top_n_by_volume'])\n",
    "        else:\n",
    "            selected_markets = main_df.head(2)  # Default to first 2 markets\n",
    "    \n",
    "    print(f\"Final selection: {len(selected_markets)} markets\")\n",
    "    \n",
    "    # Display selected markets\n",
    "    if len(selected_markets) > 0:\n",
    "        print(\"\\nSelected Markets:\")\n",
    "        for i, (idx, row) in enumerate(selected_markets.iterrows()):\n",
    "            market_name = row['question'] if 'question' in row else f\"Market {row['id']}\"\n",
    "            print(f\"{i+1}. {market_name} (ID: {row['id']})\")\n",
    "    \n",
    "    # Load trade data for selected markets\n",
    "    market_ids = selected_markets['id'].tolist()\n",
    "    trade_data = load_trade_data_for_analysis(market_ids=market_ids)\n",
    "    \n",
    "    if trade_data is None:\n",
    "        print(\"Failed to load trade data\")\n",
    "        return None\n",
    "    \n",
    "    # 3. Preprocess trade data\n",
    "    processed_data = preprocess_trade_data(trade_data)\n",
    "    if processed_data is None:\n",
    "        print(\"Failed to preprocess trade data\")\n",
    "        return None\n",
    "    \n",
    "    # 4. Run trader classification\n",
    "    classification_results = run_trader_classification_analysis(\n",
    "        processed_data,\n",
    "        min_clusters=2,\n",
    "        max_clusters=5,\n",
    "        random_state=42,\n",
    "        save_dir=results_dir\n",
    "    )\n",
    "    \n",
    "    # 5. Print results summary\n",
    "    print(\"\\nTrader Classification Results:\")\n",
    "    for profile in classification_results['detailed_profiles']:\n",
    "        print(f\"\\nCluster: {profile['trader_type']}\")\n",
    "        print(f\"  Description: {profile['description']}\")\n",
    "        print(f\"  Count: {profile['count']} traders ({profile['percentage']:.1f}%)\")\n",
    "        print(f\"  Avg trades: {profile['avg_trades']:.2f}\")\n",
    "        print(f\"  Avg trade size: {profile['avg_trade_size']:.2f}\")\n",
    "        if 'volume_percentage' in profile:\n",
    "            print(f\"  Volume %: {profile['volume_percentage']:.1f}%\")\n",
    "    \n",
    "    return classification_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8367e0a7",
   "metadata": {},
   "source": [
    "## e. Market Dynamics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "546eb2f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5.4 Market Dynamics Analysis\n",
    "def analyze_market_dynamics(trade_data, whale_ids, market_data, config, save_prefix='market_dynamics'):\n",
    "    \"\"\"\n",
    "    Analyze market dynamics including whale impact and price movements\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trade_data : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    whale_ids : list\n",
    "        List of whale trader IDs\n",
    "    market_data : pd.DataFrame\n",
    "        DataFrame with market metadata\n",
    "    config : dict\n",
    "        Analysis configuration\n",
    "    save_prefix : str\n",
    "        Prefix for saved files\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with market dynamics analysis results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"MARKET DYNAMICS ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    if trade_data is None or len(trade_data) == 0:\n",
    "        print(\"No trade data available for analysis\")\n",
    "        return None\n",
    "    \n",
    "    if not whale_ids:\n",
    "        print(\"No whale traders identified for analysis\")\n",
    "        return None\n",
    "    \n",
    "    results_dir = config['results_dir']\n",
    "    generate_plots = config['generate_plots']\n",
    "    \n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    \n",
    "    # Clean the data\n",
    "    df = trade_data.copy()\n",
    "    \n",
    "    # Add whale indicator\n",
    "    df['is_whale'] = df['trader_id'].isin(whale_ids)\n",
    "    \n",
    "    # Ensure price is numeric\n",
    "    if 'price' in df.columns:\n",
    "        df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "    \n",
    "    # Split whale and non-whale trades\n",
    "    whale_trades = df[df['is_whale']]\n",
    "    non_whale_trades = df[~df['is_whale']]\n",
    "    \n",
    "    print(f\"Analyzing {len(whale_trades)} whale trades and {len(non_whale_trades)} non-whale trades\")\n",
    "    \n",
    "    # Market-level price impact analysis\n",
    "    if 'market_id' in df.columns and 'price' in df.columns:\n",
    "        market_impacts = []\n",
    "        \n",
    "        for market_id, market_df in df.groupby('market_id'):\n",
    "            # Skip markets with too few trades\n",
    "            if len(market_df) < 10:\n",
    "                continue\n",
    "                \n",
    "            # Sort by timestamp\n",
    "            if 'timestamp' in market_df.columns:\n",
    "                if not pd.api.types.is_datetime64_any_dtype(market_df['timestamp']):\n",
    "                    try:\n",
    "                        market_df['timestamp'] = pd.to_datetime(market_df['timestamp'], errors='coerce')\n",
    "                        market_df = market_df.dropna(subset=['timestamp'])\n",
    "                    except:\n",
    "                        # Create a sequential timestamp if conversion fails\n",
    "                        market_df = market_df.sort_index()\n",
    "                        market_df['timestamp'] = pd.Series(range(len(market_df)))\n",
    "                \n",
    "                market_df = market_df.sort_values('timestamp')\n",
    "            \n",
    "            # Calculate price changes\n",
    "            market_df['price_change'] = market_df['price'].diff()\n",
    "            \n",
    "            # Skip markets with no price changes\n",
    "            if market_df['price_change'].isna().all() or market_df['price_change'].abs().sum() == 0:\n",
    "                continue\n",
    "            \n",
    "            # Separate whale and non-whale trades\n",
    "            market_whale_trades = market_df[market_df['is_whale']]\n",
    "            market_non_whale_trades = market_df[~market_df['is_whale']]\n",
    "            \n",
    "            # Skip markets with no whale trades\n",
    "            if len(market_whale_trades) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Calculate average metrics\n",
    "            whale_avg_change = market_whale_trades['price_change'].mean()\n",
    "            non_whale_avg_change = market_non_whale_trades['price_change'].mean()\n",
    "            \n",
    "            # Calculate directional impact\n",
    "            whale_pos_pct = (market_whale_trades['price_change'] > 0).mean() * 100\n",
    "            whale_neg_pct = (market_whale_trades['price_change'] < 0).mean() * 100\n",
    "            non_whale_pos_pct = (market_non_whale_trades['price_change'] > 0).mean() * 100\n",
    "            non_whale_neg_pct = (market_non_whale_trades['price_change'] < 0).mean() * 100\n",
    "            \n",
    "            # Get market name if available\n",
    "            if 'question' in market_data.columns:\n",
    "                market_name = market_data.loc[market_data['id'] == market_id, 'question'].iloc[0] if not market_data.loc[market_data['id'] == market_id, 'question'].empty else f\"Market {market_id}\"\n",
    "            else:\n",
    "                market_name = f\"Market {market_id}\"\n",
    "            \n",
    "            market_impacts.append({\n",
    "                'market_id': market_id,\n",
    "                'market_name': market_name,\n",
    "                'total_trades': len(market_df),\n",
    "                'whale_trades': len(market_whale_trades),\n",
    "                'non_whale_trades': len(market_non_whale_trades),\n",
    "                'whale_trade_pct': len(market_whale_trades) / len(market_df) * 100,\n",
    "                'whale_avg_change': float(whale_avg_change),\n",
    "                'non_whale_avg_change': float(non_whale_avg_change),\n",
    "                'whale_pos_pct': float(whale_pos_pct),\n",
    "                'whale_neg_pct': float(whale_neg_pct),\n",
    "                'non_whale_pos_pct': float(non_whale_pos_pct),\n",
    "                'non_whale_neg_pct': float(non_whale_neg_pct)\n",
    "            })\n",
    "        \n",
    "        # Create markets DataFrame\n",
    "        if market_impacts:\n",
    "            markets_df = pd.DataFrame(market_impacts)\n",
    "            \n",
    "            # Calculate weighted averages\n",
    "            weighted_whale_impact = np.average(\n",
    "                markets_df['whale_avg_change'],\n",
    "                weights=markets_df['whale_trades']\n",
    "            )\n",
    "            \n",
    "            weighted_non_whale_impact = np.average(\n",
    "                markets_df['non_whale_avg_change'],\n",
    "                weights=markets_df['non_whale_trades']\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nWeighted average whale price impact: {weighted_whale_impact:.6f}\")\n",
    "            print(f\"Weighted average non-whale price impact: {weighted_non_whale_impact:.6f}\")\n",
    "            \n",
    "            # Calculate impact ratio if possible\n",
    "            if weighted_non_whale_impact != 0:\n",
    "                impact_ratio = weighted_whale_impact / weighted_non_whale_impact\n",
    "                print(f\"Impact ratio (whale/non-whale): {impact_ratio:.4f}\")\n",
    "            else:\n",
    "                impact_ratio = None\n",
    "                print(\"Impact ratio cannot be calculated (division by zero)\")\n",
    "            \n",
    "            # Create visualizations\n",
    "            if generate_plots:\n",
    "                plt.figure(figsize=(15, 12))\n",
    "                \n",
    "                # 1. Market-by-market comparison\n",
    "                plt.subplot(2, 1, 1)\n",
    "                \n",
    "                # Sort markets by whale impact\n",
    "                sorted_markets = markets_df.sort_values('whale_avg_change')\n",
    "                \n",
    "                # Plot whale vs non-whale impact by market\n",
    "                plt.scatter(range(len(sorted_markets)), sorted_markets['whale_avg_change'], \n",
    "                           label='Whale impact', alpha=0.7, s=50, color='blue')\n",
    "                plt.scatter(range(len(sorted_markets)), sorted_markets['non_whale_avg_change'], \n",
    "                           label='Non-whale impact', alpha=0.7, s=50, color='orange')\n",
    "                \n",
    "                plt.axhline(y=0, color='r', linestyle='--')\n",
    "                plt.title('Price Impact by Market')\n",
    "                plt.xlabel('Markets (sorted by whale impact)')\n",
    "                plt.ylabel('Average Price Change')\n",
    "                plt.legend()\n",
    "                plt.grid(alpha=0.3)\n",
    "                \n",
    "                # 2. Direction comparison\n",
    "                plt.subplot(2, 1, 2)\n",
    "                \n",
    "                # Calculate average positive/negative percentages\n",
    "                avg_whale_pos = markets_df['whale_pos_pct'].mean()\n",
    "                avg_whale_neg = markets_df['whale_neg_pct'].mean()\n",
    "                avg_nonwhale_pos = markets_df['non_whale_pos_pct'].mean()\n",
    "                avg_nonwhale_neg = markets_df['non_whale_neg_pct'].mean()\n",
    "                \n",
    "                # Plot directional impact\n",
    "                labels = ['Whale', 'Non-whale']\n",
    "                pos_values = [avg_whale_pos, avg_nonwhale_pos]\n",
    "                neg_values = [avg_whale_neg, avg_nonwhale_neg]\n",
    "                neutral_values = [100 - avg_whale_pos - avg_whale_neg, \n",
    "                                 100 - avg_nonwhale_pos - avg_nonwhale_neg]\n",
    "                \n",
    "                width = 0.35\n",
    "                x = np.arange(len(labels))\n",
    "                \n",
    "                plt.bar(x, pos_values, width, label='Positive impact', color='green')\n",
    "                plt.bar(x, neg_values, width, bottom=pos_values, label='Negative impact', color='red')\n",
    "                plt.bar(x, neutral_values, width, \n",
    "                       bottom=[pos_values[i] + neg_values[i] for i in range(len(pos_values))], \n",
    "                       label='Neutral', color='gray')\n",
    "                \n",
    "                plt.title('Direction of Price Impact')\n",
    "                plt.ylabel('Percentage of Trades')\n",
    "                plt.xlabel('Trader Type')\n",
    "                plt.xticks(x, labels)\n",
    "                plt.legend()\n",
    "                \n",
    "                plt.tight_layout()\n",
    "                plt.savefig(os.path.join(results_dir, f\"{save_prefix}_price_impact.png\"), dpi=300)\n",
    "                plt.show()\n",
    "                \n",
    "                print(f\"Market price impact visualization saved to {save_prefix}_price_impact.png\")\n",
    "            \n",
    "            # Save results if enabled\n",
    "            results = {\n",
    "                'market_impacts': [m for m in market_impacts if isinstance(m, dict)],\n",
    "                'weighted_whale_impact': float(weighted_whale_impact),\n",
    "                'weighted_non_whale_impact': float(weighted_non_whale_impact),\n",
    "                'impact_ratio': float(impact_ratio) if impact_ratio is not None else None,\n",
    "                'avg_whale_positive_pct': float(avg_whale_pos),\n",
    "                'avg_whale_negative_pct': float(avg_whale_neg),\n",
    "                'avg_nonwhale_positive_pct': float(avg_nonwhale_pos),\n",
    "                'avg_nonwhale_negative_pct': float(avg_nonwhale_neg)\n",
    "            }\n",
    "            \n",
    "            if config['save_results']:\n",
    "                with open(os.path.join(results_dir, f\"{save_prefix}_results.json\"), 'w') as f:\n",
    "                    json.dump(results, f, indent=2, default=str)\n",
    "            \n",
    "            return results\n",
    "    \n",
    "    # If market-level analysis was not possible, do overall analysis\n",
    "    print(\"Analyzing overall price changes...\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    whale_avg_change = whale_trades['price_change'].mean() if 'price_change' in whale_trades.columns else None\n",
    "    whale_median_change = whale_trades['price_change'].median() if 'price_change' in whale_trades.columns else None\n",
    "    whale_std_change = whale_trades['price_change'].std() if 'price_change' in whale_trades.columns else None\n",
    "    \n",
    "    non_whale_avg_change = non_whale_trades['price_change'].mean() if 'price_change' in non_whale_trades.columns else None\n",
    "    non_whale_median_change = non_whale_trades['price_change'].median() if 'price_change' in non_whale_trades.columns else None\n",
    "    non_whale_std_change = non_whale_trades['price_change'].std() if 'price_change' in non_whale_trades.columns else None\n",
    "    \n",
    "    if all(x is not None for x in [whale_avg_change, non_whale_avg_change]):\n",
    "        print(f\"\\nWhale trades average price change: {whale_avg_change:.6f}\")\n",
    "        print(f\"Non-whale trades average price change: {non_whale_avg_change:.6f}\")\n",
    "    else:\n",
    "        print(\"Price change metrics not available\")\n",
    "        \n",
    "    results = {\n",
    "        'overall_metrics': {\n",
    "            'whale_avg_change': float(whale_avg_change) if whale_avg_change is not None else None,\n",
    "            'whale_median_change': float(whale_median_change) if whale_median_change is not None else None,\n",
    "            'whale_std_change': float(whale_std_change) if whale_std_change is not None else None,\n",
    "            'non_whale_avg_change': float(non_whale_avg_change) if non_whale_avg_change is not None else None,\n",
    "            'non_whale_median_change': float(non_whale_median_change) if non_whale_median_change is not None else None,\n",
    "            'non_whale_std_change': float(non_whale_std_change) if non_whale_std_change is not None else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    if config['save_results']:\n",
    "        with open(os.path.join(results_dir, f\"{save_prefix}_results.json\"), 'w') as f:\n",
    "            json.dump(results, f, indent=2, default=str)\n",
    "    \n",
    "    return results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6ee9037e",
   "metadata": {},
   "source": [
    "## f. Temporal Analaysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5d60b76c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trader_temporal_patterns(trade_data, trader_types_df):\n",
    "    \"\"\"\n",
    "    Analyze how different trader types behave over time\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trade_data : pd.DataFrame\n",
    "        DataFrame with trade data including timestamps\n",
    "    trader_types_df : pd.DataFrame\n",
    "        DataFrame with trader classification results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with temporal analysis results\n",
    "    \"\"\"\n",
    "    # Ensure we have timestamp data\n",
    "    if 'timestamp' not in trade_data.columns:\n",
    "        print(\"Error: No timestamp data available for temporal analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure timestamp is in datetime format\n",
    "    if not pd.api.types.is_datetime64_any_dtype(trade_data['timestamp']):\n",
    "        try:\n",
    "            trade_data['timestamp'] = pd.to_datetime(trade_data['timestamp'])\n",
    "        except:\n",
    "            print(\"Error: Could not convert timestamps to datetime\")\n",
    "            return None\n",
    "    \n",
    "    # Merge trader types to trade data\n",
    "    if 'trader_id' in trade_data.columns and 'trader_id' in trader_types_df.columns and 'trader_type' in trader_types_df.columns:\n",
    "        trade_data = trade_data.merge(\n",
    "            trader_types_df[['trader_id', 'trader_type']], \n",
    "            on='trader_id', \n",
    "            how='left'\n",
    "        )\n",
    "    else:\n",
    "        print(\"Error: Cannot merge trader types - missing required columns\")\n",
    "        return None\n",
    "    \n",
    "    # Create time periods\n",
    "    trade_data['date'] = trade_data['timestamp'].dt.date\n",
    "    \n",
    "    # Find overall market start and end date\n",
    "    start_date = trade_data['date'].min()\n",
    "    end_date = trade_data['date'].max()\n",
    "    market_duration = (end_date - start_date).days\n",
    "    \n",
    "    # Define periods\n",
    "    if market_duration >= 30:\n",
    "        # For longer markets, use weeks\n",
    "        trade_data['week'] = (trade_data['timestamp'] - pd.Timestamp(start_date)).dt.days // 7\n",
    "        period_col = 'week'\n",
    "        period_name = 'Week'\n",
    "    else:\n",
    "        # For shorter markets, use days\n",
    "        trade_data['day'] = (trade_data['timestamp'] - pd.Timestamp(start_date)).dt.days\n",
    "        period_col = 'day'\n",
    "        period_name = 'Day'\n",
    "    \n",
    "    # Calculate period entry points for each trader type\n",
    "    entry_periods = {}\n",
    "    trader_entries = trade_data.groupby(['trader_id', 'trader_type'])[period_col].min().reset_index()\n",
    "    for trader_type, group in trader_entries.groupby('trader_type'):\n",
    "        entry_periods[trader_type] = {\n",
    "            'mean': group[period_col].mean(),\n",
    "            'median': group[period_col].median(),\n",
    "            'p25': group[period_col].quantile(0.25),\n",
    "            'p75': group[period_col].quantile(0.75),\n",
    "        }\n",
    "    \n",
    "    # Calculate activity by period and trader type\n",
    "    activity_by_period = trade_data.groupby([period_col, 'trader_type']).agg({\n",
    "        'trade_amount': ['sum', 'mean', 'count'],\n",
    "        'trader_id': 'nunique'\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Rename columns\n",
    "    activity_by_period.columns = [\n",
    "        period_col if c == period_col else 'trader_type' if c == 'trader_type' \n",
    "        else f\"{c[0]}_{c[1]}\" for c in activity_by_period.columns\n",
    "    ]\n",
    "    \n",
    "    # Calculate percentage of active traders by period\n",
    "    total_traders_by_type = trader_types_df.groupby('trader_type').size()\n",
    "    for trader_type in total_traders_by_type.index:\n",
    "        type_rows = activity_by_period['trader_type'] == trader_type\n",
    "        activity_by_period.loc[type_rows, 'trader_participation_pct'] = (\n",
    "            100 * activity_by_period.loc[type_rows, 'trader_id_nunique'] / total_traders_by_type[trader_type]\n",
    "        )\n",
    "    \n",
    "    # Create visualizations\n",
    "    plt.figure(figsize=(12, 8))\n",
    "    \n",
    "    # Plot volume by trader type over time\n",
    "    volume_pivot = pd.pivot_table(\n",
    "        activity_by_period, \n",
    "        values='trade_amount_sum', \n",
    "        index=period_col, \n",
    "        columns='trader_type'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    ax = volume_pivot.plot(figsize=(12, 6))\n",
    "    plt.title(f'Trading Volume by Trader Type Over Time')\n",
    "    plt.xlabel(f'{period_name} (since market start)')\n",
    "    plt.ylabel('Trading Volume')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(title='Trader Type')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/temporal_volume_by_type.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Plot trader participation\n",
    "    participation_pivot = pd.pivot_table(\n",
    "        activity_by_period, \n",
    "        values='trader_participation_pct', \n",
    "        index=period_col, \n",
    "        columns='trader_type'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    ax = participation_pivot.plot(figsize=(12, 6))\n",
    "    plt.title(f'Trader Participation Rate by Type Over Time')\n",
    "    plt.xlabel(f'{period_name} (since market start)')\n",
    "    plt.ylabel('Participation Rate (%)')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend(title='Trader Type')\n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/temporal_participation_by_type.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Return complete analysis results\n",
    "    return {\n",
    "        'market_duration': market_duration,\n",
    "        'period_type': period_name,\n",
    "        'entry_periods': entry_periods,\n",
    "        'activity_by_period': activity_by_period.to_dict('records'),\n",
    "        'total_periods': activity_by_period[period_col].max() + 1\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5ba8cd0",
   "metadata": {},
   "source": [
    "## g. Network Effects"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "23e424b3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_network_effects(trade_data, trader_types_df, whale_ids, time_window_minutes=60):\n",
    "    \"\"\"\n",
    "    Analyze network effects between trader types - how they influence each other\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trade_data : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    trader_types_df : pd.DataFrame\n",
    "        DataFrame with trader classification results\n",
    "    whale_ids : list\n",
    "        List of whale trader IDs\n",
    "    time_window_minutes : int\n",
    "        Time window for analyzing following behavior (in minutes)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with network analysis results\n",
    "    \"\"\"\n",
    "    # Ensure we have timestamp data\n",
    "    if 'timestamp' not in trade_data.columns:\n",
    "        print(\"Error: No timestamp data available for network analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure timestamp is in datetime format\n",
    "    if not pd.api.types.is_datetime64_any_dtype(trade_data['timestamp']):\n",
    "        try:\n",
    "            trade_data['timestamp'] = pd.to_datetime(trade_data['timestamp'])\n",
    "        except:\n",
    "            print(\"Error: Could not convert timestamps to datetime\")\n",
    "            return None\n",
    "    \n",
    "    # Merge trader types to trade data\n",
    "    if 'trader_id' in trade_data.columns and 'trader_id' in trader_types_df.columns and 'trader_type' in trader_types_df.columns:\n",
    "        trade_data = trade_data.merge(\n",
    "            trader_types_df[['trader_id', 'trader_type']], \n",
    "            on='trader_id', \n",
    "            how='left'\n",
    "        )\n",
    "    else:\n",
    "        print(\"Error: Cannot merge trader types - missing required columns\")\n",
    "        return None\n",
    "    \n",
    "    # Add whale indicator based on ID list\n",
    "    trade_data['is_whale'] = trade_data['trader_id'].isin(whale_ids)\n",
    "    \n",
    "    # Sort trades by timestamp\n",
    "    trade_data = trade_data.sort_values('timestamp')\n",
    "    \n",
    "    # Create time windows for analyzing following behavior\n",
    "    trade_data['timestamp_window'] = trade_data['timestamp'].dt.floor(f'{time_window_minutes}min')\n",
    "    \n",
    "    # Create side indicator if available (buy=1, sell=-1)\n",
    "    if 'side' in trade_data.columns:\n",
    "        trade_data['side_value'] = trade_data['side'].map({'buy': 1, 'sell': -1})\n",
    "    \n",
    "    # Analyze following behavior after whale trades\n",
    "    following_behavior = []\n",
    "    \n",
    "    # Group by time windows\n",
    "    for window, window_trades in trade_data.groupby('timestamp_window'):\n",
    "        # Skip windows with too few trades\n",
    "        if len(window_trades) < 3:\n",
    "            continue\n",
    "        \n",
    "        # Check if there are whale trades in this window\n",
    "        whale_trades = window_trades[window_trades['is_whale']]\n",
    "        if len(whale_trades) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Get the first whale trade in the window\n",
    "        first_whale_trade = whale_trades.iloc[0]\n",
    "        whale_timestamp = first_whale_trade['timestamp']\n",
    "        \n",
    "        # Check if there are enough trades after the whale\n",
    "        following_trades = window_trades[window_trades['timestamp'] > whale_timestamp]\n",
    "        if len(following_trades) < 2:\n",
    "            continue\n",
    "        \n",
    "        # Analyze follower behavior\n",
    "        for trader_type, type_trades in following_trades.groupby('trader_type'):\n",
    "            behavior = {\n",
    "                'window_start': window,\n",
    "                'whale_timestamp': whale_timestamp,\n",
    "                'trader_type': trader_type,\n",
    "                'follower_count': len(type_trades),\n",
    "                'follower_volume': type_trades['trade_amount'].sum() if 'trade_amount' in type_trades.columns else 0,\n",
    "                'time_to_follow': (type_trades['timestamp'].min() - whale_timestamp).total_seconds() / 60\n",
    "            }\n",
    "            \n",
    "            # If side data is available, check directional following\n",
    "            if 'side_value' in first_whale_trade and 'side_value' in type_trades.columns:\n",
    "                whale_side = first_whale_trade['side_value']\n",
    "                follower_sides = type_trades['side_value']\n",
    "                same_direction = (follower_sides == whale_side).sum()\n",
    "                opposite_direction = (follower_sides != whale_side).sum()\n",
    "                \n",
    "                behavior['same_direction_count'] = same_direction\n",
    "                behavior['opposite_direction_count'] = opposite_direction\n",
    "                behavior['same_direction_pct'] = 100 * same_direction / len(follower_sides) if len(follower_sides) > 0 else 0\n",
    "            \n",
    "            following_behavior.append(behavior)\n",
    "    \n",
    "    # Aggregate following behavior by trader type\n",
    "    following_stats = {}\n",
    "    following_df = pd.DataFrame(following_behavior)\n",
    "    \n",
    "    if not following_df.empty:\n",
    "        for trader_type, group in following_df.groupby('trader_type'):\n",
    "            following_stats[trader_type] = {\n",
    "                'avg_follower_count': group['follower_count'].mean(),\n",
    "                'avg_follower_volume': group['follower_volume'].mean(),\n",
    "                'avg_time_to_follow': group['time_to_follow'].mean()\n",
    "            }\n",
    "            \n",
    "            if 'same_direction_pct' in group.columns:\n",
    "                following_stats[trader_type]['avg_same_direction_pct'] = group['same_direction_pct'].mean()\n",
    "    \n",
    "    # Create visualizations\n",
    "    if not following_df.empty and 'same_direction_pct' in following_df.columns:\n",
    "        plt.figure(figsize=(10, 6))\n",
    "        \n",
    "        # Create directional following visualization\n",
    "        trader_types = list(following_stats.keys())\n",
    "        same_direction_pcts = [following_stats[t]['avg_same_direction_pct'] for t in trader_types]\n",
    "        \n",
    "        bars = plt.bar(trader_types, same_direction_pcts)\n",
    "        \n",
    "        plt.axhline(y=50, color='r', linestyle='--', label='Random (50%)')\n",
    "        \n",
    "        plt.title('Percentage of Trades in Same Direction as Whale Trades')\n",
    "        plt.xlabel('Trader Type')\n",
    "        plt.ylabel('Same Direction %')\n",
    "        plt.grid(axis='y', alpha=0.3)\n",
    "        plt.ylim(0, 100)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/network_directional_following.png', dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    # Return results\n",
    "    return {\n",
    "        'following_behavior': following_behavior,\n",
    "        'following_stats': following_stats,\n",
    "        'time_window_minutes': time_window_minutes\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5e52a8c",
   "metadata": {},
   "source": [
    "## h. Market Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "87b6d50b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_market_impact(trade_data, trader_types_df, min_trades=3):\n",
    "    \"\"\"\n",
    "    Analyze how trades by different trader types impact market prices\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trade_data : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    trader_types_df : pd.DataFrame\n",
    "        DataFrame with trader classification results\n",
    "    min_trades : int\n",
    "        Minimum number of trades for analysis\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with market impact analysis results\n",
    "    \"\"\"\n",
    "    # Check for required columns\n",
    "    required_cols = ['timestamp', 'price', 'trade_amount', 'trader_id']\n",
    "    missing_cols = [col for col in required_cols if col not in trade_data.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"Error: Missing required columns for market impact analysis: {missing_cols}\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure timestamp is in datetime format\n",
    "    if not pd.api.types.is_datetime64_any_dtype(trade_data['timestamp']):\n",
    "        try:\n",
    "            trade_data['timestamp'] = pd.to_datetime(trade_data['timestamp'])\n",
    "        except:\n",
    "            print(\"Error: Could not convert timestamps to datetime\")\n",
    "            return None\n",
    "    \n",
    "    # Merge trader types\n",
    "    trade_data = trade_data.merge(\n",
    "        trader_types_df[['trader_id', 'trader_type']], \n",
    "        on='trader_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    trade_data = trade_data.sort_values('timestamp')\n",
    "    \n",
    "    # Calculate price changes\n",
    "    trade_data['next_price'] = trade_data['price'].shift(-1)\n",
    "    trade_data['price_change'] = trade_data['next_price'] - trade_data['price']\n",
    "    trade_data['price_change_pct'] = 100 * trade_data['price_change'] / trade_data['price']\n",
    "    \n",
    "    # Add volume bins\n",
    "    trade_data['volume_quantile'] = pd.qcut(\n",
    "        trade_data['trade_amount'], \n",
    "        q=5, \n",
    "        labels=['Very Small', 'Small', 'Medium', 'Large', 'Very Large']\n",
    "    )\n",
    "    \n",
    "    # Calculate immediate price impact by trader type\n",
    "    impact_by_type = trade_data.groupby('trader_type').agg({\n",
    "        'price_change': ['mean', 'median', 'std', 'count'],\n",
    "        'price_change_pct': ['mean', 'median', 'std']\n",
    "    })\n",
    "    \n",
    "    # Flatten column names\n",
    "    impact_by_type.columns = [f'{col[0]}_{col[1]}' for col in impact_by_type.columns]\n",
    "    \n",
    "    # Filter to types with enough trades\n",
    "    impact_by_type = impact_by_type[impact_by_type['price_change_count'] >= min_trades]\n",
    "    \n",
    "    # Calculate impact by trader type and volume\n",
    "    impact_by_type_volume = trade_data.groupby(['trader_type', 'volume_quantile']).agg({\n",
    "        'price_change': ['mean', 'count'],\n",
    "        'price_change_pct': ['mean']\n",
    "    })\n",
    "    \n",
    "    # Flatten columns\n",
    "    impact_by_type_volume.columns = [f'{col[0]}_{col[1]}' for col in impact_by_type_volume.columns]\n",
    "    \n",
    "    # Filter to combinations with enough trades\n",
    "    impact_by_type_volume = impact_by_type_volume[impact_by_type_volume['price_change_count'] >= min_trades]\n",
    "    \n",
    "    # Convert to records for easier JSON serialization\n",
    "    impact_by_type_records = []\n",
    "    for trader_type, row in impact_by_type.iterrows():\n",
    "        impact_by_type_records.append({\n",
    "            'trader_type': trader_type,\n",
    "            'avg_price_change': float(row['price_change_mean']),\n",
    "            'median_price_change': float(row['price_change_median']),\n",
    "            'price_change_std': float(row['price_change_std']),\n",
    "            'trade_count': int(row['price_change_count']),\n",
    "            'avg_price_change_pct': float(row['price_change_pct_mean']),\n",
    "            'median_price_change_pct': float(row['price_change_pct_median'])\n",
    "        })\n",
    "    \n",
    "    # Convert the multiindex dataframe to records\n",
    "    impact_by_type_volume_records = []\n",
    "    for (trader_type, volume), row in impact_by_type_volume.iterrows():\n",
    "        impact_by_type_volume_records.append({\n",
    "            'trader_type': trader_type,\n",
    "            'volume_quantile': volume,\n",
    "            'avg_price_change': float(row['price_change_mean']),\n",
    "            'trade_count': int(row['price_change_count']),\n",
    "            'avg_price_change_pct': float(row['price_change_pct_mean'])\n",
    "        })\n",
    "    \n",
    "    # Create visualizations\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Create bar plot of average price impact by trader type\n",
    "    trader_types = impact_by_type.index.tolist()\n",
    "    price_impacts = impact_by_type['price_change_mean'].values\n",
    "    \n",
    "    bars = plt.bar(trader_types, price_impacts)\n",
    "    \n",
    "    # Add color based on positive/negative impact\n",
    "    for i, bar in enumerate(bars):\n",
    "        bar.set_color('green' if price_impacts[i] > 0 else 'red')\n",
    "    \n",
    "    plt.axhline(y=0, color='k', linestyle='--')\n",
    "    \n",
    "    plt.title('Average Price Impact by Trader Type')\n",
    "    plt.xlabel('Trader Type')\n",
    "    plt.ylabel('Average Price Change')\n",
    "    plt.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # Add count labels\n",
    "    for i, bar in enumerate(bars):\n",
    "        count = impact_by_type['price_change_count'].iloc[i]\n",
    "        plt.text(i, bar.get_height() + (0.001 if bar.get_height() >= 0 else -0.003),\n",
    "                 f'n={count:,}', \n",
    "                 ha='center', va='bottom' if bar.get_height() >= 0 else 'top',\n",
    "                 fontsize=8)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('results/price_impact_by_trader_type.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    # Create visualization of impact by volume\n",
    "    if len(impact_by_type_volume_records) > 0:\n",
    "        # Convert to DataFrame for easier plotting\n",
    "        impact_volume_df = pd.DataFrame(impact_by_type_volume_records)\n",
    "        \n",
    "        # Create heatmap of price impact by trader type and volume\n",
    "        pivot_df = impact_volume_df.pivot_table(\n",
    "            index='trader_type',\n",
    "            columns='volume_quantile',\n",
    "            values='avg_price_change'\n",
    "        )\n",
    "        \n",
    "        plt.figure(figsize=(12, 8))\n",
    "        sns.heatmap(pivot_df, annot=True, cmap='RdYlGn', center=0, fmt='.4f')\n",
    "        plt.title('Price Impact by Trader Type and Trade Size')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/price_impact_heatmap.png', dpi=300)\n",
    "        plt.close()\n",
    "    \n",
    "    return {\n",
    "        'impact_by_type': impact_by_type_records,\n",
    "        'impact_by_type_volume': impact_by_type_volume_records\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08bd601d",
   "metadata": {},
   "source": [
    "## i. Trading Strategy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "bdd07850",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trading_strategies(trade_data, trader_types_df):\n",
    "    \"\"\"\n",
    "    Analyze trading strategies of different trader types\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trade_data : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    trader_types_df : pd.DataFrame\n",
    "        DataFrame with trader classification results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with trading strategy analysis results\n",
    "    \"\"\"\n",
    "    # Check for required columns\n",
    "    required_cols = ['timestamp', 'price', 'trader_id']\n",
    "    missing_cols = [col for col in required_cols if col not in trade_data.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"Error: Missing required columns for strategy analysis: {missing_cols}\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure timestamp is in datetime format\n",
    "    if not pd.api.types.is_datetime64_any_dtype(trade_data['timestamp']):\n",
    "        try:\n",
    "            trade_data['timestamp'] = pd.to_datetime(trade_data['timestamp'])\n",
    "        except:\n",
    "            print(\"Error: Could not convert timestamps to datetime\")\n",
    "            return None\n",
    "    \n",
    "    # Merge trader types\n",
    "    trade_data = trade_data.merge(\n",
    "        trader_types_df[['trader_id', 'trader_type']], \n",
    "        on='trader_id', \n",
    "        how='left'\n",
    "    )\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    trade_data = trade_data.sort_values('timestamp')\n",
    "    \n",
    "    # Calculate price metrics\n",
    "    trade_data['prev_price'] = trade_data['price'].shift(1)\n",
    "    trade_data['price_change'] = trade_data['price'] - trade_data['prev_price']\n",
    "    \n",
    "    # Determine if price is rising or falling\n",
    "    trade_data['price_rising'] = trade_data['price_change'] > 0\n",
    "    trade_data['price_falling'] = trade_data['price_change'] < 0\n",
    "    \n",
    "    # Get trading side if available\n",
    "    if 'side' in trade_data.columns:\n",
    "        trade_data['is_buy'] = trade_data['side'] == 'buy'\n",
    "        \n",
    "        # Calculate strategy metrics by trader\n",
    "        strategy_by_trader = []\n",
    "        \n",
    "        for trader_id, trader_type in trader_types_df[['trader_id', 'trader_type']].values:\n",
    "            trader_trades = trade_data[trade_data['trader_id'] == trader_id]\n",
    "            \n",
    "            if len(trader_trades) < 5:  # Skip traders with too few trades\n",
    "                continue\n",
    "            \n",
    "            # Calculate strategy metrics\n",
    "            buy_count = trader_trades['is_buy'].sum()\n",
    "            buy_pct = 100 * buy_count / len(trader_trades)\n",
    "            \n",
    "            # Calculate buy on rising vs falling\n",
    "            buys_on_rising = trader_trades[trader_trades['is_buy'] & trader_trades['price_rising']].shape[0]\n",
    "            buys_on_falling = trader_trades[trader_trades['is_buy'] & trader_trades['price_falling']].shape[0]\n",
    "            \n",
    "            sells_on_rising = trader_trades[~trader_trades['is_buy'] & trader_trades['price_rising']].shape[0]\n",
    "            sells_on_falling = trader_trades[~trader_trades['is_buy'] & trader_trades['price_falling']].shape[0]\n",
    "            \n",
    "            # Calculate percentages\n",
    "            rising_count = trader_trades['price_rising'].sum()\n",
    "            falling_count = trader_trades['price_falling'].sum()\n",
    "            \n",
    "            if rising_count > 0:\n",
    "                buy_on_rising_pct = 100 * buys_on_rising / rising_count\n",
    "                sell_on_rising_pct = 100 * sells_on_rising / rising_count\n",
    "            else:\n",
    "                buy_on_rising_pct = 0\n",
    "                sell_on_rising_pct = 0\n",
    "                \n",
    "            if falling_count > 0:\n",
    "                buy_on_falling_pct = 100 * buys_on_falling / falling_count\n",
    "                sell_on_falling_pct = 100 * sells_on_falling / falling_count\n",
    "            else:\n",
    "                buy_on_falling_pct = 0\n",
    "                sell_on_falling_pct = 0\n",
    "            \n",
    "            # Calculate momentum score (-1 to 1, positive = momentum, negative = contrarian)\n",
    "            strategy_score = 0\n",
    "            \n",
    "            if (rising_count + falling_count) > 0:\n",
    "                momentum_buys = buys_on_rising + sells_on_falling\n",
    "                contrarian_buys = buys_on_falling + sells_on_rising\n",
    "                total_trades = rising_count + falling_count\n",
    "                \n",
    "                strategy_score = (momentum_buys - contrarian_buys) / total_trades\n",
    "            \n",
    "            # Determine strategy type\n",
    "            if strategy_score > 0.3:\n",
    "                strategy = \"Momentum\"\n",
    "            elif strategy_score < -0.3:\n",
    "                strategy = \"Contrarian\"\n",
    "            else:\n",
    "                strategy = \"Mixed/Neutral\"\n",
    "            \n",
    "            # Bullish/bearish bias\n",
    "            if buy_pct > 65:\n",
    "                bias = \"Bullish\"\n",
    "            elif buy_pct < 35:\n",
    "                bias = \"Bearish\"\n",
    "            else:\n",
    "                bias = \"Neutral\"\n",
    "            \n",
    "            strategy_by_trader.append({\n",
    "                'trader_id': trader_id,\n",
    "                'trader_type': trader_type,\n",
    "                'trade_count': len(trader_trades),\n",
    "                'buy_pct': buy_pct,\n",
    "                'strategy_score': strategy_score,\n",
    "                'strategy': strategy,\n",
    "                'bias': bias,\n",
    "                'buys_on_rising': buys_on_rising,\n",
    "                'buys_on_falling': buys_on_falling,\n",
    "                'sells_on_rising': sells_on_rising,\n",
    "                'sells_on_falling': sells_on_falling\n",
    "            })\n",
    "        \n",
    "        # Convert to DataFrame\n",
    "        strategy_df = pd.DataFrame(strategy_by_trader)\n",
    "        \n",
    "        # Calculate strategy distribution by trader type\n",
    "        strategy_by_type = {}\n",
    "        \n",
    "        for trader_type, group in strategy_df.groupby('trader_type'):\n",
    "            strategy_counts = group['strategy'].value_counts()\n",
    "            bias_counts = group['bias'].value_counts()\n",
    "            \n",
    "            strategy_pcts = 100 * strategy_counts / len(group)\n",
    "            bias_pcts = 100 * bias_counts / len(group)\n",
    "            \n",
    "            strategy_by_type[trader_type] = {\n",
    "                'count': len(group),\n",
    "                'avg_strategy_score': group['strategy_score'].mean(),\n",
    "                'strategy_distribution': {\n",
    "                    strategy: float(pct) for strategy, pct in strategy_pcts.items()\n",
    "                },\n",
    "                'bias_distribution': {\n",
    "                    bias: float(pct) for bias, pct in bias_pcts.items()\n",
    "                }\n",
    "            }\n",
    "        \n",
    "        # Create visualizations\n",
    "        # 1. Strategy distribution by trader type\n",
    "        strategy_types = list(strategy_by_type.keys())\n",
    "        momentum_pcts = [strategy_by_type[t]['strategy_distribution'].get('Momentum', 0) for t in strategy_types]\n",
    "        contrarian_pcts = [strategy_by_type[t]['strategy_distribution'].get('Contrarian', 0) for t in strategy_types]\n",
    "        neutral_pcts = [strategy_by_type[t]['strategy_distribution'].get('Mixed/Neutral', 0) for t in strategy_types]\n",
    "        \n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        x = np.arange(len(strategy_types))\n",
    "        width = 0.25\n",
    "        \n",
    "        plt.bar(x - width, momentum_pcts, width, label='Momentum')\n",
    "        plt.bar(x, contrarian_pcts, width, label='Contrarian')\n",
    "        plt.bar(x + width, neutral_pcts, width, label='Mixed/Neutral')\n",
    "        \n",
    "        plt.xlabel('Trader Type')\n",
    "        plt.ylabel('Percentage of Traders')\n",
    "        plt.title('Trading Strategy Distribution by Trader Type')\n",
    "        plt.xticks(x, strategy_types)\n",
    "        plt.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('results/strategy_distribution.png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        return {\n",
    "            'strategy_by_trader': strategy_by_trader,\n",
    "            'strategy_by_type': strategy_by_type\n",
    "        }\n",
    "    else:\n",
    "        print(\"Warning: Side data not available for strategy analysis\")\n",
    "        return None"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d50d24ac",
   "metadata": {},
   "source": [
    "# 5. Results Summary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dc585a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_summary_report(all_results, results_dir):\n",
    "    \"\"\"\n",
    "    Generate a summary report of all analysis results\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    all_results : dict\n",
    "        Dictionary with analysis results\n",
    "    results_dir : str\n",
    "        Directory to save the report\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"GENERATING SUMMARY REPORT\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Create report dictionary\n",
    "    report = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'summary': {}\n",
    "    }\n",
    "    \n",
    "    # Add trader distribution summary\n",
    "    if 'trader_distribution' in all_results:\n",
    "        dist = all_results['trader_distribution'][0] if isinstance(all_results['trader_distribution'], tuple) else all_results['trader_distribution']\n",
    "        report['summary']['trader_distribution'] = {\n",
    "            'total_traders': dist.get('total_traders'),\n",
    "            'total_volume': dist.get('total_volume'),\n",
    "            'avg_trades_per_trader': dist.get('avg_trades_per_trader'),\n",
    "            'median_trades_per_trader': dist.get('median_trades_per_trader')\n",
    "        }\n",
    "    \n",
    "    # Add whale identification summary\n",
    "    if 'whale_identification' in all_results:\n",
    "        whale = all_results['whale_identification'][1] if isinstance(all_results['whale_identification'], tuple) else all_results['whale_identification']\n",
    "        report['summary']['whale_identification'] = {\n",
    "            'gini': whale.get('gini_coefficient'),\n",
    "            'whale_threshold': whale.get('threshold_used'),\n",
    "            'num_whales': whale.get('num_whales')\n",
    "        }\n",
    "    \n",
    "    # Add trader classification summary\n",
    "    if 'trader_classification' in all_results and all_results['trader_classification']:\n",
    "        class_results = all_results['trader_classification']\n",
    "        if 'cluster_profiles' in class_results:\n",
    "            profiles = class_results.get('cluster_profiles')\n",
    "            report['summary']['trader_classification'] = {\n",
    "                'num_clusters': len(profiles),\n",
    "                'cluster_types': class_results.get('cluster_names'),\n",
    "                'feature_importance': class_results.get('feature_importance')\n",
    "            }\n",
    "    \n",
    "    # Add market dynamics summary\n",
    "    if 'market_dynamics' in all_results:\n",
    "        dynamics = all_results['market_dynamics']\n",
    "        if 'weighted_whale_impact' in dynamics:\n",
    "            report['summary']['market_dynamics'] = {\n",
    "                'weighted_whale_impact': dynamics.get('weighted_whale_impact'),\n",
    "                'weighted_non_whale_impact': dynamics.get('weighted_non_whale_impact'),\n",
    "                'impact_ratio': dynamics.get('impact_ratio'),\n",
    "                'direction_metrics': {\n",
    "                    'whale_positive_pct': dynamics.get('avg_whale_positive_pct'),\n",
    "                    'whale_negative_pct': dynamics.get('avg_whale_negative_pct'),\n",
    "                    'non_whale_positive_pct': dynamics.get('avg_nonwhale_positive_pct'),\n",
    "                    'non_whale_negative_pct': dynamics.get('avg_nonwhale_negative_pct')\n",
    "                }\n",
    "            }\n",
    "        elif 'overall_metrics' in dynamics:\n",
    "            report['summary']['market_dynamics'] = dynamics.get('overall_metrics')\n",
    "    \n",
    "    # Save report as JSON\n",
    "    with open(os.path.join(results_dir, 'analysis_summary.json'), 'w') as f:\n",
    "        json.dump(report, f, indent=2, default=str)\n",
    "    \n",
    "    # Generate text report for quick reference\n",
    "    with open(os.path.join(results_dir, 'analysis_summary.txt'), 'w') as f:\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(\"TRADER ANALYSIS SUMMARY REPORT\\n\")\n",
    "        f.write(\"=\"*80 + \"\\n\")\n",
    "        f.write(f\"Generated: {report['timestamp']}\\n\\n\")\n",
    "        \n",
    "        # Add trader distribution\n",
    "        if 'trader_distribution' in report['summary']:\n",
    "            dist = report['summary']['trader_distribution']\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(\"TRADER DISTRIBUTION\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(f\"Total Traders: {dist.get('total_traders'):,}\\n\")\n",
    "            f.write(f\"Total Volume: {dist.get('total_volume'):,.2f}\\n\")\n",
    "            f.write(f\"Avg Trades per Trader: {dist.get('avg_trades_per_trader'):.2f}\\n\")\n",
    "            f.write(f\"Median Trades per Trader: {dist.get('median_trades_per_trader'):.0f}\\n\\n\")\n",
    "        \n",
    "        # Add whale identification\n",
    "        if 'whale_identification' in report['summary']:\n",
    "            whale = report['summary']['whale_identification']\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(\"WHALE IDENTIFICATION\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(f\"Gini Coefficient: {whale.get('gini'):.4f}\\n\")\n",
    "            f.write(f\"Whale Threshold: Top {whale.get('whale_threshold')*100:.1f}%\\n\")\n",
    "            f.write(f\"Number of Whales: {whale.get('num_whales'):,}\\n\\n\")\n",
    "        \n",
    "        # Add trader classification\n",
    "        if 'trader_classification' in report['summary']:\n",
    "            class_results = report['summary']['trader_classification']\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(\"TRADER CLASSIFICATION\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(f\"Number of Trader Types: {class_results.get('num_clusters')}\\n\")\n",
    "            f.write(\"Trader Types Identified:\\n\")\n",
    "            for cluster_id, name in class_results.get('cluster_types', {}).items():\n",
    "                f.write(f\"  - {name}\\n\")\n",
    "            f.write(\"\\nMost Important Features:\\n\")\n",
    "            sorted_features = sorted(class_results.get('feature_importance', {}).items(), \n",
    "                                   key=lambda x: x[1], reverse=True)\n",
    "            for feature, importance in sorted_features[:3]:\n",
    "                f.write(f\"  - {feature}: {importance:.4f}\\n\")\n",
    "            f.write(\"\\n\")\n",
    "        \n",
    "        # Add market dynamics\n",
    "        if 'market_dynamics' in report['summary']:\n",
    "            dynamics = report['summary']['market_dynamics']\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            f.write(\"MARKET DYNAMICS\\n\")\n",
    "            f.write(\"-\"*30 + \"\\n\")\n",
    "            if 'weighted_whale_impact' in dynamics:\n",
    "                f.write(f\"Whale Price Impact: {dynamics.get('weighted_whale_impact'):.6f}\\n\")\n",
    "                f.write(f\"Non-Whale Price Impact: {dynamics.get('weighted_non_whale_impact'):.6f}\\n\")\n",
    "                if dynamics.get('impact_ratio'):\n",
    "                    f.write(f\"Impact Ratio: {dynamics.get('impact_ratio'):.4f}\\n\")\n",
    "                if 'direction_metrics' in dynamics:\n",
    "                    dir_metrics = dynamics.get('direction_metrics', {})\n",
    "                    f.write(\"\\nPrice Direction:\\n\")\n",
    "                    f.write(f\"  Whale Positive: {dir_metrics.get('whale_positive_pct', 0):.2f}%\\n\")\n",
    "                    f.write(f\"  Whale Negative: {dir_metrics.get('whale_negative_pct', 0):.2f}%\\n\")\n",
    "                    f.write(f\"  Non-Whale Positive: {dir_metrics.get('non_whale_positive_pct', 0):.2f}%\\n\")\n",
    "                    f.write(f\"  Non-Whale Negative: {dir_metrics.get('non_whale_negative_pct', 0):.2f}%\\n\")\n",
    "            elif 'whale_avg_change' in dynamics:\n",
    "                f.write(f\"Whale Avg Change: {dynamics.get('whale_avg_change'):.6f}\\n\")\n",
    "                f.write(f\"Non-Whale Avg Change: {dynamics.get('non_whale_avg_change'):.6f}\\n\")\n",
    "    \n",
    "    print(f\"Analysis summary saved to {os.path.join(results_dir, 'analysis_summary.txt')}\")\n",
    "    print(f\"Full JSON results saved to {os.path.join(results_dir, 'analysis_summary.json')}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95cf8a61",
   "metadata": {},
   "source": [
    "# 6. Main Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "925cc869",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Main analysis function that calls all the specialized analyses\n",
    "def run_comprehensive_trader_analysis(\n",
    "    market_ids=None, \n",
    "    data_path='data/cleaned_election_data.csv', \n",
    "    results_dir='results/trader_analysis'\n",
    "):\n",
    "    \"\"\"\n",
    "    Run comprehensive trader analysis across all analysis dimensions\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_ids : list, optional\n",
    "        List of market IDs to analyze (None = auto-select)\n",
    "    data_path : str\n",
    "        Path to the main dataset\n",
    "    results_dir : str\n",
    "        Path to save results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with comprehensive analysis results\n",
    "    \"\"\"\n",
    "    # Create output directory\n",
    "    os.makedirs(results_dir, exist_ok=True)\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"STARTING POLYMARKET TRADER ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    # Load main dataset and select markets\n",
    "    main_df = load_data(data_path)\n",
    "    if main_df is None:\n",
    "        print(\"Failed to load main dataset\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Loading main dataset...\")\n",
    "    print(f\"Loaded dataset with {main_df.shape[0]} rows and {main_df.shape[1]} columns\")\n",
    "    \n",
    "    # Select markets to analyze\n",
    "    selected_markets = []\n",
    "    \n",
    "    if market_ids is not None:\n",
    "        # Use provided market IDs\n",
    "        for market_id in market_ids:\n",
    "            market_info = main_df[main_df['id'] == market_id]\n",
    "            if not market_info.empty:\n",
    "                selected_markets.append((market_id, market_info.iloc[0]['question'] if 'question' in market_info.columns else f\"Market {market_id}\"))\n",
    "    else:\n",
    "        # Default to presidential election markets\n",
    "        search_terms = [\"Trump 2024\", \"Harris 2024\", \"Presidential Election 2024\"]\n",
    "        \n",
    "        for term in search_terms:\n",
    "            matching_markets = main_df[main_df['question'].str.contains(term, case=False, na=False)]\n",
    "            \n",
    "            for _, row in matching_markets.iterrows():\n",
    "                selected_markets.append((row['id'], row['question']))\n",
    "    \n",
    "    # If no markets found, use top 2 by volume\n",
    "    if not selected_markets and 'volumeNum' in main_df.columns:\n",
    "        top_markets = main_df.sort_values('volumeNum', ascending=False).head(2)\n",
    "        for _, row in top_markets.iterrows():\n",
    "            selected_markets.append((row['id'], row['question'] if 'question' in row.index else f\"Market {row['id']}\"))\n",
    "    \n",
    "    print(f\"Selected {len(selected_markets)} markets by name\")\n",
    "    \n",
    "    if not selected_markets:\n",
    "        print(\"No markets selected for analysis\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Selected Markets:\")\n",
    "    for i, (market_id, question) in enumerate(selected_markets):\n",
    "        print(f\"{i+1}. {question} (ID: {market_id})\")\n",
    "    \n",
    "    # Load trade data for selected markets\n",
    "    all_trades = []\n",
    "    \n",
    "    for market_id, question in selected_markets:\n",
    "        print(f\"Loading trade data for market {market_id}...\")\n",
    "        \n",
    "        # Use load_trade_data from your data_loader.py module\n",
    "        market_trades = load_trade_data(market_id, trades_dir=\"data/trades\")\n",
    "        \n",
    "        if market_trades is not None and len(market_trades) > 0:\n",
    "            all_trades.append(market_trades)\n",
    "        else:\n",
    "            print(f\"No trade data found for market {market_id}\")\n",
    "    \n",
    "    if not all_trades:\n",
    "        print(\"No trade data found for any selected markets\")\n",
    "        return None\n",
    "    \n",
    "    # Combine trade data\n",
    "    trade_data = pd.concat(all_trades, ignore_index=True)\n",
    "    print(f\"Loaded {len(trade_data):,} trades from {len(selected_markets)} markets\")\n",
    "    \n",
    "    # Preprocess the trade data\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"DATA PREPROCESSING\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    processed_data = preprocess_trade_data(trade_data)\n",
    "    if processed_data is None:\n",
    "        print(\"Failed to preprocess trade data\")\n",
    "        return None\n",
    "    \n",
    "    # 1. Trader Distribution Analysis\n",
    "    print(\"Running trader distribution analysis...\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRADER DISTRIBUTION ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    distribution_results, trader_metrics = analyze_trader_distribution(processed_data)\n",
    "    \n",
    "    # 2. Whale Identification\n",
    "    print(\"Running whale identification...\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"WHALE TRADER IDENTIFICATION\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    whale_ids, whale_results = identify_whales(\n",
    "        processed_data, \n",
    "        threshold=0.01,  # Top 1%\n",
    "        save_prefix=f\"{results_dir}/whale_identification\"\n",
    "    )\n",
    "    \n",
    "    # 3. Enhanced Trader Classification\n",
    "    print(\"Running trader classification...\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRADER CLASSIFICATION ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    classification_results = ????(\n",
    "        processed_data,\n",
    "        min_clusters=2,\n",
    "        max_clusters=4,\n",
    "        random_state=42,\n",
    "        save_dir=results_dir\n",
    "    )\n",
    "    \n",
    "    # Extract trader types dataframe\n",
    "    trader_types_df = classification_results['trader_features']\n",
    "    \n",
    "    # 4. Temporal Analysis\n",
    "    print(\"Running temporal analysis...\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TEMPORAL ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    temporal_results = analyze_trader_temporal_patterns(\n",
    "        processed_data, \n",
    "        trader_types_df\n",
    "    )\n",
    "    \n",
    "    # 5. Network Effect Analysis\n",
    "    print(\"Running network effect analysis...\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"NETWORK EFFECT ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    network_results = analyze_network_effects(\n",
    "        processed_data, \n",
    "        trader_types_df, \n",
    "        whale_ids,\n",
    "        time_window_minutes=30\n",
    "    )\n",
    "    \n",
    "    # 6. Market Impact Analysis\n",
    "    print(\"Running market impact analysis...\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"MARKET IMPACT ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    impact_results = analyze_market_impact(\n",
    "        processed_data, \n",
    "        trader_types_df\n",
    "    )\n",
    "    \n",
    "    # 7. Trading Strategy Analysis\n",
    "    print(\"Running trading strategy analysis...\")\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"TRADING STRATEGY ANALYSIS\")\n",
    "    print(f\"{'='*80}\")\n",
    "    \n",
    "    strategy_results = analyze_trading_strategies(\n",
    "        processed_data, \n",
    "        trader_types_df\n",
    "    )\n",
    "    \n",
    "    # Compile comprehensive results\n",
    "    comprehensive_results = {\n",
    "        'markets_analyzed': selected_markets,\n",
    "        'trader_distribution': distribution_results,\n",
    "        'whale_identification': whale_results,\n",
    "        'trader_classification': classification_results,\n",
    "        'temporal_analysis': temporal_results,\n",
    "        'network_effects': network_results,\n",
    "        'market_impact': impact_results,\n",
    "        'trading_strategies': strategy_results\n",
    "    }\n",
    "    \n",
    "    # Save comprehensive results\n",
    "    if ANALYSIS_CONFIG['save_results']:\n",
    "        results_file = os.path.join(results_dir, 'comprehensive_results.json')\n",
    "        \n",
    "        with open(results_file, 'w') as f:\n",
    "            # Convert non-serializable values to strings\n",
    "            json_results = json.dumps(comprehensive_results, default=str, indent=2)\n",
    "            f.write(json_results)\n",
    "        \n",
    "        print(f\"Saved comprehensive results to {results_file}\")\n",
    "    \n",
    "    # Print summary\n",
    "    print(f\"\\n{'='*80}\")\n",
    "    print(f\"ANALYSIS COMPLETE\")\n",
    "    print(f\"{'='*80}\")\n",
    "    print(f\"Results saved to {results_dir}\")\n",
    "    \n",
    "    # Display key metrics\n",
    "    print(f\"\\nTotal traders analyzed: {distribution_results['total_traders']:,}\")\n",
    "    print(f\"Gini coefficient: {whale_results['gini']:.4f}\")\n",
    "    print(f\"Whales identified: {whale_results['selected_num_whales']:,}\")\n",
    "    \n",
    "    print(\"\\nTrader types identified:\")\n",
    "    for trader_type, profile in classification_results['detailed_profiles'].items():\n",
    "        print(f\"- {profile['trader_type']}\")\n",
    "    \n",
    "    return comprehensive_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7ea3ec4e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

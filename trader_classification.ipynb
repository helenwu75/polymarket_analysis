{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1926d6c",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fd99a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src directory to path for importing utility functions\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir) if current_dir.endswith('notebooks') else current_dir\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Import utility functions\n",
    "from src.utils.data_loader import load_main_dataset, load_trade_data\n",
    "\n",
    "# Create results directory\n",
    "results_dir = 'results/trader_analysis'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Cell 2: Helper Functions (Remove function definitions, just define the functions)\n",
    "def calculate_gini(values):\n",
    "    if len(values) <= 1 or np.sum(values) == 0:\n",
    "        return 0\n",
    "    \n",
    "    sorted_values = np.sort(values)\n",
    "    n = len(sorted_values)\n",
    "    cumsum = np.cumsum(sorted_values)\n",
    "    return (n + 1 - 2 * np.sum((n + 1 - np.arange(1, n+1)) * sorted_values) / np.sum(sorted_values)) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f00d5e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cell 3: Load Market Data\n",
    "print(\"Loading main dataset...\")\n",
    "market_data = load_main_dataset('data/cleaned_election_data.csv')\n",
    "\n",
    "if market_data is not None:\n",
    "    print(f\"Successfully loaded {len(market_data)} markets\")\n",
    "    \n",
    "    # Explore trader-related metrics\n",
    "    trader_cols = [col for col in market_data.columns if any(term in col.lower() \n",
    "                   for term in ['trader', 'trade', 'concentration'])]\n",
    "    \n",
    "    print(\"\\nAvailable trader-related columns:\")\n",
    "    for col in trader_cols:\n",
    "        print(f\"- {col}\")\n",
    "        \n",
    "    # Display basic statistics for key trader metrics\n",
    "    trader_metrics = ['unique_traders_count', 'trader_to_trade_ratio', \n",
    "                     'two_way_traders_ratio', 'new_trader_influx']\n",
    "    available_metrics = [col for col in trader_metrics if col in market_data.columns]\n",
    "    \n",
    "    if available_metrics:\n",
    "        print(\"\\nSummary statistics for trader metrics:\")\n",
    "        print(market_data[available_metrics].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a33e0",
   "metadata": {},
   "source": [
    "# Load Trade Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "9023db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trade_data_for_analysis(market_ids=None, max_trades_per_market=None):\n",
    "    \"\"\"\n",
    "    Load trade data for specific market IDs\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_ids : list, optional\n",
    "        List of specific market IDs to load\n",
    "    max_trades_per_market : int, optional\n",
    "        Maximum number of trades per market (None for all trades)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Combined trade data from specified markets\n",
    "    \"\"\"\n",
    "    print(\"Loading market data...\")\n",
    "    market_data = load_main_dataset('data/cleaned_election_data.csv')\n",
    "    \n",
    "    if market_data is None:\n",
    "        print(\"Failed to load market data\")\n",
    "        return None\n",
    "    \n",
    "    # If market_ids not provided, use all markets\n",
    "    if market_ids is None:\n",
    "        market_ids = market_data['id'].tolist()\n",
    "    \n",
    "    print(f\"Selected {len(market_ids)} markets for analysis\")\n",
    "    \n",
    "    from src.utils.data_loader import load_trade_data, get_token_ids_for_market\n",
    "    \n",
    "    all_trades = []\n",
    "    for i, market_id in enumerate(market_ids):\n",
    "        try:\n",
    "            # Get market name if available\n",
    "            market_name = market_data.loc[market_data['id'] == market_id, 'question'].iloc[0] \\\n",
    "                         if 'question' in market_data.columns else f\"Market {market_id}\"\n",
    "            \n",
    "            print(f\"\\nLoading trades for market {i+1}/{len(market_ids)}: {market_name}\")\n",
    "            print(f\"Market ID: {market_id}\")\n",
    "            \n",
    "            # Try to load trade data using utility function\n",
    "            trades = load_trade_data(market_id)\n",
    "            \n",
    "            if trades is not None and len(trades) > 0:\n",
    "                print(f\"Successfully loaded {len(trades)} trades\")\n",
    "                \n",
    "                # Add market identifier\n",
    "                trades['market_id'] = market_id\n",
    "                \n",
    "                # Sample if max_trades_per_market is specified\n",
    "                if max_trades_per_market is not None and len(trades) > max_trades_per_market:\n",
    "                    print(f\"Sampling {max_trades_per_market} trades from {len(trades)} total\")\n",
    "                    trades = trades.sample(max_trades_per_market, random_state=42)\n",
    "                \n",
    "                all_trades.append(trades)\n",
    "            else:\n",
    "                print(\"No trades found using default method, trying alternative approaches\")\n",
    "                \n",
    "                # Try to get token IDs for this market\n",
    "                token_ids = get_token_ids_for_market(market_id, main_df=market_data)\n",
    "                \n",
    "                if token_ids and len(token_ids) > 0:\n",
    "                    print(f\"Found {len(token_ids)} token IDs for market {market_id}\")\n",
    "                    \n",
    "                    # Try to locate token files directly\n",
    "                    from src.utils.data_loader import find_token_id_file\n",
    "                    \n",
    "                    market_trades = []\n",
    "                    for token_id in token_ids:\n",
    "                        try:\n",
    "                            token_file = find_token_id_file(token_id)\n",
    "                            if token_file:\n",
    "                                print(f\"Found token file: {os.path.basename(token_file)}\")\n",
    "                                \n",
    "                                # Load this token's trades\n",
    "                                import pyarrow.parquet as pq\n",
    "                                token_trades = pq.read_table(token_file).to_pandas()\n",
    "                                token_trades['market_id'] = market_id\n",
    "                                token_trades['token_id'] = token_id\n",
    "                                \n",
    "                                market_trades.append(token_trades)\n",
    "                                print(f\"Loaded {len(token_trades)} trades for token {token_id}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error loading token {token_id}: {e}\")\n",
    "                    \n",
    "                    if market_trades:\n",
    "                        combined_market_trades = pd.concat(market_trades, ignore_index=True)\n",
    "                        \n",
    "                        # Sample if specified\n",
    "                        if max_trades_per_market is not None and len(combined_market_trades) > max_trades_per_market:\n",
    "                            print(f\"Sampling {max_trades_per_market} trades from {len(combined_market_trades)} total\")\n",
    "                            combined_market_trades = combined_market_trades.sample(max_trades_per_market, random_state=42)\n",
    "                        \n",
    "                        all_trades.append(combined_market_trades)\n",
    "                    else:\n",
    "                        print(f\"No trade data found for any tokens in market {market_id}\")\n",
    "                else:\n",
    "                    print(f\"No token IDs found for market {market_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading trades for market {market_id}: {e}\")\n",
    "    \n",
    "    if not all_trades:\n",
    "        print(\"No trade data loaded for any markets\")\n",
    "        return None\n",
    "    \n",
    "    # Combine all trade data\n",
    "    combined_trades = pd.concat(all_trades, ignore_index=True)\n",
    "    print(f\"\\nTotal trades loaded: {len(combined_trades)} from {len(all_trades)} markets\")\n",
    "    \n",
    "    # Standardize and prepare trade data (same as before)\n",
    "    if 'timestamp' in combined_trades.columns and not pd.api.types.is_datetime64_any_dtype(combined_trades['timestamp']):\n",
    "        try:\n",
    "            combined_trades['timestamp'] = pd.to_numeric(combined_trades['timestamp'], errors='coerce')\n",
    "            combined_trades['timestamp'] = pd.to_datetime(combined_trades['timestamp'], unit='s', errors='coerce')\n",
    "            combined_trades = combined_trades.dropna(subset=['timestamp'])\n",
    "            print(f\"Converted {len(combined_trades)} valid timestamps\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting timestamps: {e}\")\n",
    "    \n",
    "    # Standardize trader ID and other columns (same as before)\n",
    "    if 'maker' in combined_trades.columns and 'maker_id' not in combined_trades.columns:\n",
    "        combined_trades['maker_id'] = combined_trades['maker']\n",
    "    if 'taker' in combined_trades.columns and 'taker_id' not in combined_trades.columns:\n",
    "        combined_trades['taker_id'] = combined_trades['taker']\n",
    "    \n",
    "    # Create trader_id column\n",
    "    combined_trades['trader_id'] = combined_trades['maker_id']\n",
    "    \n",
    "    # Create trade_amount column if not present\n",
    "    if 'trade_amount' not in combined_trades.columns:\n",
    "        if 'size' in combined_trades.columns:\n",
    "            combined_trades['trade_amount'] = combined_trades['size']\n",
    "        else:\n",
    "            combined_trades['trade_amount'] = 1.0\n",
    "    \n",
    "    # Additional logging\n",
    "    unique_makers = combined_trades['maker_id'].nunique() if 'maker_id' in combined_trades.columns else 0\n",
    "    unique_takers = combined_trades['taker_id'].nunique() if 'taker_id' in combined_trades.columns else 0\n",
    "    unique_traders = combined_trades['trader_id'].nunique() if 'trader_id' in combined_trades.columns else 0\n",
    "    \n",
    "    print(f\"Unique traders identified: {unique_traders} (makers: {unique_makers}, takers: {unique_takers})\")\n",
    "    \n",
    "    return combined_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "414f7cba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "Loading market data...\n",
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "Selected 2 markets for analysis\n",
      "\n",
      "Loading trades for market 1/2: Will Donald Trump win the 2024 US Presidential Election?\n",
      "Market ID: 253591.0\n",
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "Successfully loaded 1185000 trades\n",
      "\n",
      "Loading trades for market 2/2: Will Kamala Harris win the 2024 US Presidential Election?\n",
      "Market ID: 253597.0\n",
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "No trade data found for market 253597.0\n",
      "No trades found using default method, trying alternative approaches\n",
      "Found 2 token IDs for market 253597.0\n",
      "Found token file: 69236923620077691027083946871148646972011131466059644796654161903044970987404.parquet 18-30-01-221.parquet\n",
      "Loaded 802000 trades for token 69236923620077691027083946871148646972011131466059644796654161903044970987404\n",
      "Found token file: 87584955359245246404952128082451897287778571240979823316620093987046202296181.parquet 18-30-01-396.parquet\n",
      "Loaded 444000 trades for token 87584955359245246404952128082451897287778571240979823316620093987046202296181\n",
      "\n",
      "Total trades loaded: 2431000 from 2 markets\n",
      "Converted 1246000 valid timestamps\n",
      "Unique traders identified: 74002 (makers: 74002, takers: 71396)\n",
      "\n",
      "Total trades loaded: 1246000\n",
      "Unique markets: 1\n",
      "Unique traders: 74002\n"
     ]
    }
   ],
   "source": [
    "target_markets = [\n",
    "    \"Will Donald Trump win the 2024 US Presidential Election?\", \n",
    "    \"Will Kamala Harris win the 2024 US Presidential Election?\"\n",
    "]\n",
    "\n",
    "# Load main dataset\n",
    "market_data = load_main_dataset('data/cleaned_election_data.csv')\n",
    "\n",
    "# Filter to specific markets\n",
    "selected_markets = market_data[market_data['question'].isin(target_markets)]\n",
    "market_ids = selected_markets['id'].tolist()\n",
    "\n",
    "# Load ALL trades for these markets\n",
    "trade_data = load_trade_data_for_analysis(\n",
    "    market_ids=market_ids, \n",
    "    max_trades_per_market=None  # Load all trades\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal trades loaded: {len(trade_data)}\")\n",
    "print(f\"Unique markets: {trade_data['market_id'].nunique()}\")\n",
    "print(f\"Unique traders: {trade_data['trader_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e15cf566",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Detailed Market Information:\n",
      "Market ID: 253591.0\n",
      "Question: Will Donald Trump win the 2024 US Presidential Election?\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'get_token_ids_for_market' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[68]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mMarket ID: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      5\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mQuestion: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mrow[\u001b[33m'\u001b[39m\u001b[33mquestion\u001b[39m\u001b[33m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mTokens: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[43mget_token_ids_for_market\u001b[49m(row[\u001b[33m'\u001b[39m\u001b[33mid\u001b[39m\u001b[33m'\u001b[39m],\u001b[38;5;250m \u001b[39mmain_df=market_data)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n\u001b[32m      7\u001b[39m     \u001b[38;5;28mprint\u001b[39m(\u001b[33m\"\u001b[39m\u001b[33m-\u001b[39m\u001b[33m\"\u001b[39m * \u001b[32m50\u001b[39m)\n\u001b[32m      9\u001b[39m \u001b[38;5;66;03m# Modify the loading to explicitly handle both markets\u001b[39;00m\n",
      "\u001b[31mNameError\u001b[39m: name 'get_token_ids_for_market' is not defined"
     ]
    }
   ],
   "source": [
    "# Debug print statements to understand market loading\n",
    "print(\"\\nDetailed Market Information:\")\n",
    "for index, row in selected_markets.iterrows():\n",
    "    print(f\"Market ID: {row['id']}\")\n",
    "    print(f\"Question: {row['question']}\")\n",
    "    print(f\"Tokens: {get_token_ids_for_market(row['id'], main_df=market_data)}\")\n",
    "    print(\"-\" * 50)\n",
    "\n",
    "# Modify the loading to explicitly handle both markets\n",
    "market_ids = selected_markets['id'].tolist()\n",
    "print(\"\\nMarket IDs:\", market_ids)\n",
    "\n",
    "trade_data = load_trade_data_for_analysis(\n",
    "    market_ids=market_ids, \n",
    "    max_trades_per_market=None  # Load all trades\n",
    ")\n",
    "\n",
    "print(f\"\\nTotal trades loaded: {len(trade_data)}\")\n",
    "print(f\"Unique markets: {trade_data['market_id'].nunique()}\")\n",
    "print(f\"Unique traders: {trade_data['trader_id'].nunique()}\")\n",
    "print(\"\\nMarket breakdown:\")\n",
    "print(trade_data['market_id'].value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "287ef71d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trader Classification and Analysis\n",
    "\n",
    "# 1. Basic Market Overview\n",
    "print(\"Market Trade Statistics:\")\n",
    "print(f\"Total Trades: {len(trade_data)}\")\n",
    "print(f\"Unique Markets: {trade_data['market_id'].nunique()}\")\n",
    "print(f\"Unique Traders: {trade_data['trader_id'].nunique()}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1009558",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 2. Identify Potential Whale Traders\n",
    "def identify_whales(trades_df, threshold=0.05):\n",
    "    \"\"\"\n",
    "    Identify whale traders based on trading volume\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    threshold : float\n",
    "        Percentage of top traders to consider as whales\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    list\n",
    "        List of whale trader IDs\n",
    "    \"\"\"\n",
    "    # Group trades by trader and calculate total volume\n",
    "    trader_volumes = trades_df.groupby('trader_id')['trade_amount'].sum().sort_values(ascending=False)\n",
    "    \n",
    "    # Calculate number of whales\n",
    "    whale_count = max(1, int(len(trader_volumes) * threshold))\n",
    "    \n",
    "    # Identify whale traders\n",
    "    whale_ids = trader_volumes.head(whale_count).index.tolist()\n",
    "    \n",
    "    print(\"\\nWhale Trader Analysis:\")\n",
    "    print(f\"Total Traders: {len(trader_volumes)}\")\n",
    "    print(f\"Number of Whales: {whale_count}\")\n",
    "    print(f\"Total Volume of Whales: {trader_volumes.head(whale_count).sum()}\")\n",
    "    print(f\"Whale Volume Percentage: {trader_volumes.head(whale_count).sum() / trader_volumes.sum() * 100:.2f}%\")\n",
    "    \n",
    "    return whale_ids\n",
    "\n",
    "# Identify whales\n",
    "whale_ids = identify_whales(trade_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f762ea67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 3. Whale Trade Impact Analysis\n",
    "def analyze_whale_impact(trades_df, whale_ids):\n",
    "    \"\"\"\n",
    "    Analyze the impact of whale trades on market prices\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    whale_ids : list\n",
    "        List of whale trader IDs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Analysis of whale trade impacts\n",
    "    \"\"\"\n",
    "    # Separate whale and non-whale trades\n",
    "    whale_trades = trades_df[trades_df['trader_id'].isin(whale_ids)]\n",
    "    non_whale_trades = trades_df[~trades_df['trader_id'].isin(whale_ids)]\n",
    "    \n",
    "    # Analyze price changes around whale trades\n",
    "    def calculate_price_impact(trades):\n",
    "        # Sort trades by timestamp\n",
    "        trades_sorted = trades.sort_values('timestamp')\n",
    "        \n",
    "        # Calculate price changes\n",
    "        trades_sorted['price_change'] = trades_sorted['price'].diff()\n",
    "        \n",
    "        return {\n",
    "            'avg_price_change': trades_sorted['price_change'].mean(),\n",
    "            'median_price_change': trades_sorted['price_change'].median(),\n",
    "            'volatility': trades_sorted['price_change'].std()\n",
    "        }\n",
    "    \n",
    "    whale_impact = calculate_price_impact(whale_trades)\n",
    "    non_whale_impact = calculate_price_impact(non_whale_trades)\n",
    "    \n",
    "    print(\"\\nWhale Trade Impact:\")\n",
    "    print(\"Whale Trades Price Changes:\")\n",
    "    for k, v in whale_impact.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    \n",
    "    print(\"\\nNon-Whale Trades Price Changes:\")\n",
    "    for k, v in non_whale_impact.items():\n",
    "        print(f\"{k}: {v}\")\n",
    "    \n",
    "    return {\n",
    "        'whale_impact': whale_impact,\n",
    "        'non_whale_impact': non_whale_impact\n",
    "    }\n",
    "\n",
    "# Analyze whale trade impact\n",
    "whale_impact_results = analyze_whale_impact(trade_data, whale_ids)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0061f84",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 4. Trader Classification\n",
    "def classify_traders(trades_df):\n",
    "    \"\"\"\n",
    "    Classify traders based on their trading behavior\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Trader classification results\n",
    "    \"\"\"\n",
    "    # Calculate trader metrics\n",
    "    trader_metrics = trades_df.groupby('trader_id').agg({\n",
    "        'trade_amount': ['sum', 'mean', 'count'],\n",
    "        'price': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    trader_metrics.columns = ['trader_id', 'total_volume', 'avg_trade_size', 'trade_count', \n",
    "                               'avg_price', 'price_volatility']\n",
    "    \n",
    "    # Add classification logic\n",
    "    def classify_trader(row):\n",
    "        if row['total_volume'] > trader_metrics['total_volume'].quantile(0.95):\n",
    "            return 'Whale'\n",
    "        elif row['trade_count'] > trader_metrics['trade_count'].quantile(0.8):\n",
    "            return 'Active Trader'\n",
    "        elif row['avg_trade_size'] > trader_metrics['avg_trade_size'].quantile(0.8):\n",
    "            return 'Large Trade Trader'\n",
    "        else:\n",
    "            return 'Casual Trader'\n",
    "    \n",
    "    trader_metrics['trader_type'] = trader_metrics.apply(classify_trader, axis=1)\n",
    "    \n",
    "    # Print classification summary\n",
    "    print(\"\\nTrader Classification:\")\n",
    "    print(trader_metrics['trader_type'].value_counts(normalize=True))\n",
    "    \n",
    "    return trader_metrics\n",
    "\n",
    "# Classify traders\n",
    "trader_classification = classify_traders(trade_data)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55083382",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# 5. Market Dynamics Visualization\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Trader Volume Distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(trader_classification['total_volume'], bins=50, kde=True)\n",
    "plt.title('Trader Volume Distribution')\n",
    "plt.xlabel('Total Trading Volume')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Trader Type Distribution\n",
    "plt.subplot(2, 2, 2)\n",
    "trader_classification['trader_type'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Trader Type Distribution')\n",
    "\n",
    "# Price Changes by Trader Type\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(x='trader_type', y='total_volume', data=trader_classification)\n",
    "plt.title('Volume by Trader Type')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Trade Frequency Distribution\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(trader_classification['trade_count'], bins=50, kde=True)\n",
    "plt.title('Trade Frequency Distribution')\n",
    "plt.xlabel('Number of Trades')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('trader_analysis_plots.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nAnalysis complete. Visualization saved as trader_analysis_plots.png\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42a6deae",
   "metadata": {},
   "source": [
    "# Trader Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "3c324bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_traders(trades_df, n_clusters=5):\n",
    "    \"\"\"\n",
    "    Classify traders into different types based on their behavior\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    n_clusters : int\n",
    "        Number of clusters to create\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with classification results\n",
    "    \"\"\"\n",
    "    # Create a combined trader ID using both maker and taker\n",
    "    if 'maker_id' in trades_df.columns and 'taker_id' in trades_df.columns:\n",
    "        # Get all unique trader IDs from both maker and taker columns\n",
    "        all_traders = set(trades_df['maker_id'].dropna().unique()) | set(trades_df['taker_id'].dropna().unique())\n",
    "        all_trader_ids = list(all_traders)\n",
    "        \n",
    "        print(f\"Analyzing {len(all_trader_ids)} unique traders from maker/taker columns\")\n",
    "    elif 'trader_id' in trades_df.columns:\n",
    "        all_trader_ids = trades_df['trader_id'].unique()\n",
    "        print(f\"Analyzing {len(all_trader_ids)} unique traders from trader_id column\")\n",
    "    else:\n",
    "        print(\"Error: No trader identifier columns found\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Calculating trader features...\")\n",
    "    \n",
    "    # Group by trader_id and calculate features\n",
    "    trader_features = []\n",
    "    \n",
    "    # For each trader, calculate features based on their maker and taker activities\n",
    "    for trader_id in all_trader_ids:\n",
    "        # Get all trades where this trader was involved (as maker or taker)\n",
    "        if 'maker_id' in trades_df.columns and 'taker_id' in trades_df.columns:\n",
    "            maker_trades = trades_df[trades_df['maker_id'] == trader_id]\n",
    "            taker_trades = trades_df[trades_df['taker_id'] == trader_id]\n",
    "            trader_trades = pd.concat([maker_trades, taker_trades]).drop_duplicates()\n",
    "        else:\n",
    "            trader_trades = trades_df[trades_df['trader_id'] == trader_id]\n",
    "        \n",
    "        # Skip traders with too few trades\n",
    "        if len(trader_trades) < 3:\n",
    "            continue\n",
    "            \n",
    "        # Basic activity metrics\n",
    "        trade_count = len(trader_trades)\n",
    "        \n",
    "        # Trade size metrics\n",
    "        if 'trade_amount' in trader_trades.columns:\n",
    "            avg_trade_size = trader_trades['trade_amount'].mean()\n",
    "            total_volume = trader_trades['trade_amount'].sum()\n",
    "            trade_size_volatility = trader_trades['trade_amount'].std() / avg_trade_size if avg_trade_size > 0 else 0\n",
    "        elif 'size' in trader_trades.columns:\n",
    "            avg_trade_size = trader_trades['size'].mean()\n",
    "            total_volume = trader_trades['size'].sum()\n",
    "            trade_size_volatility = trader_trades['size'].std() / avg_trade_size if avg_trade_size > 0 else 0\n",
    "        else:\n",
    "            avg_trade_size = np.nan\n",
    "            total_volume = np.nan\n",
    "            trade_size_volatility = np.nan\n",
    "        \n",
    "        # Trader diversity (market participation)\n",
    "        if 'market_id' in trader_trades.columns:\n",
    "            market_count = trader_trades['market_id'].nunique()\n",
    "            market_concentration = (trader_trades.groupby('market_id').size() / trade_count).max()\n",
    "        else:\n",
    "            market_count = 1\n",
    "            market_concentration = 1.0\n",
    "            \n",
    "        # Trading frequency\n",
    "        if 'timestamp' in trader_trades.columns:\n",
    "            trader_trades = trader_trades.sort_values('timestamp')\n",
    "            if len(trader_trades) > 1:\n",
    "                # Convert timestamp to datetime if it's not already\n",
    "                if not pd.api.types.is_datetime64_any_dtype(trader_trades['timestamp']):\n",
    "                    trader_trades['timestamp'] = pd.to_datetime(trader_trades['timestamp'])\n",
    "                \n",
    "                # Calculate time between trades in minutes\n",
    "                time_diffs = trader_trades['timestamp'].diff().dropna()\n",
    "                if len(time_diffs) > 0:\n",
    "                    try:\n",
    "                        avg_time_between_trades = time_diffs.mean().total_seconds() / 60\n",
    "                        trade_timing_regularity = time_diffs.std().total_seconds() / avg_time_between_trades if avg_time_between_trades > 0 else np.nan\n",
    "                    except:\n",
    "                        avg_time_between_trades = np.nan\n",
    "                        trade_timing_regularity = np.nan\n",
    "                else:\n",
    "                    avg_time_between_trades = np.nan\n",
    "                    trade_timing_regularity = np.nan\n",
    "            else:\n",
    "                avg_time_between_trades = np.nan\n",
    "                trade_timing_regularity = np.nan\n",
    "        else:\n",
    "            avg_time_between_trades = np.nan\n",
    "            trade_timing_regularity = np.nan\n",
    "            \n",
    "        # Trading direction bias\n",
    "        if 'side' in trader_trades.columns:\n",
    "            buy_count = (trader_trades['side'] == 'buy').sum()\n",
    "            sell_count = (trader_trades['side'] == 'sell').sum()\n",
    "            if buy_count + sell_count > 0:\n",
    "                buy_ratio = buy_count / (buy_count + sell_count)\n",
    "            else:\n",
    "                buy_ratio = 0.5\n",
    "        elif 'trade_direction' in trader_trades.columns:\n",
    "            buy_count = (trader_trades['trade_direction'] == 'buy').sum()\n",
    "            sell_count = (trader_trades['trade_direction'] == 'sell').sum()\n",
    "            if buy_count + sell_count > 0:\n",
    "                buy_ratio = buy_count / (buy_count + sell_count)\n",
    "            else:\n",
    "                buy_ratio = 0.5\n",
    "        else:\n",
    "            buy_ratio = 0.5\n",
    "            \n",
    "        # Store features\n",
    "        trader_features.append({\n",
    "            'trader_id': trader_id,\n",
    "            'trade_count': trade_count,\n",
    "            'avg_trade_size': avg_trade_size,\n",
    "            'total_volume': total_volume,\n",
    "            'trade_size_volatility': trade_size_volatility,\n",
    "            'market_count': market_count,\n",
    "            'market_concentration': market_concentration,\n",
    "            'avg_time_between_trades': avg_time_between_trades,\n",
    "            'trade_timing_regularity': trade_timing_regularity,\n",
    "            'buy_ratio': buy_ratio\n",
    "        })\n",
    "    \n",
    "    if not trader_features:\n",
    "        print(\"No trader features calculated\")\n",
    "        return None\n",
    "        \n",
    "    # Create DataFrame\n",
    "    trader_df = pd.DataFrame(trader_features)\n",
    "    print(f\"Calculated features for {len(trader_df)} traders\")\n",
    "    \n",
    "    # Select features for clustering\n",
    "    features_for_clustering = [\n",
    "        'trade_count', 'avg_trade_size', 'market_concentration', \n",
    "        'buy_ratio', 'trade_size_volatility'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available features and remove any with all NaN values\n",
    "    available_features = []\n",
    "    for f in features_for_clustering:\n",
    "        if f in trader_df.columns and not trader_df[f].isna().all():\n",
    "            available_features.append(f)\n",
    "    \n",
    "    print(f\"Using {len(available_features)} features for clustering: {available_features}\")\n",
    "    \n",
    "    if len(available_features) < 2:\n",
    "        print(\"Insufficient features for clustering\")\n",
    "        return None\n",
    "        \n",
    "    # Handle missing values\n",
    "    X = trader_df[available_features].copy()\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(\"Performing clustering...\")\n",
    "    \n",
    "    # Apply K-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    trader_df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Calculate cluster profiles\n",
    "    cluster_profiles = trader_df.groupby('cluster')[available_features].mean()\n",
    "    cluster_sizes = trader_df['cluster'].value_counts().sort_index()\n",
    "    cluster_profiles['size'] = cluster_sizes.values\n",
    "    cluster_profiles['percentage'] = 100 * cluster_sizes / cluster_sizes.sum()\n",
    "    \n",
    "    # Interpret clusters\n",
    "    cluster_names = {}\n",
    "    for cluster_id in range(n_clusters):\n",
    "        profile = cluster_profiles.loc[cluster_id]\n",
    "        \n",
    "        # Calculate z-scores for this cluster compared to others\n",
    "        z_scores = {}\n",
    "        for feature in available_features:\n",
    "            feature_mean = cluster_profiles[feature].mean()\n",
    "            feature_std = cluster_profiles[feature].std()\n",
    "            if feature_std > 0:\n",
    "                z_scores[feature] = (profile[feature] - feature_mean) / feature_std\n",
    "            else:\n",
    "                z_scores[feature] = 0\n",
    "                \n",
    "        # Determine cluster type based on most extreme z-scores\n",
    "        top_feature = max(z_scores.items(), key=lambda x: abs(x[1]))\n",
    "        \n",
    "        if top_feature[0] == 'trade_count' and top_feature[1] > 1:\n",
    "            name = \"High Frequency Traders\"\n",
    "        elif top_feature[0] == 'avg_trade_size' and top_feature[1] > 1:\n",
    "            name = \"Whale Traders\"\n",
    "        elif top_feature[0] == 'market_concentration' and top_feature[1] > 1:\n",
    "            name = \"Market Specialists\" \n",
    "        elif top_feature[0] == 'buy_ratio':\n",
    "            if top_feature[1] > 1:\n",
    "                name = \"Bullish Traders\"\n",
    "            else:\n",
    "                name = \"Bearish Traders\"\n",
    "        elif top_feature[0] == 'trade_size_volatility' and top_feature[1] > 1:\n",
    "            name = \"Opportunistic Traders\"\n",
    "        else:\n",
    "            name = \"Balanced Traders\"\n",
    "            \n",
    "        cluster_names[cluster_id] = name\n",
    "    \n",
    "    # Add names to profiles\n",
    "    cluster_profiles['type'] = [cluster_names[i] for i in cluster_profiles.index]\n",
    "    \n",
    "    # Create visualizations\n",
    "    \n",
    "    # 1. PCA visualization of clusters\n",
    "    if len(available_features) >= 2:\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        # Create visualization DataFrame\n",
    "        viz_df = pd.DataFrame({\n",
    "            'PC1': X_pca[:, 0],\n",
    "            'PC2': X_pca[:, 1],\n",
    "            'Cluster': trader_df['cluster'],\n",
    "            'Type': trader_df['cluster'].map(cluster_names)\n",
    "        })\n",
    "        \n",
    "        # Calculate explained variance\n",
    "        explained_variance = pca.explained_variance_ratio_\n",
    "        \n",
    "        # Create PCA plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.scatterplot(data=viz_df, x='PC1', y='PC2', hue='Type', palette='viridis', s=50, alpha=0.7)\n",
    "        plt.title('Trader Types - PCA Visualization')\n",
    "        plt.xlabel(f'PC1 ({explained_variance[0]:.1%} variance)')\n",
    "        plt.ylabel(f'PC2 ({explained_variance[1]:.1%} variance)')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, 'trader_clusters_pca.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Radar chart of cluster profiles\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Normalize profiles for radar chart\n",
    "        radar_df = cluster_profiles[available_features].copy()\n",
    "        for feature in available_features:\n",
    "            feature_max = radar_df[feature].max()\n",
    "            if feature_max > 0:\n",
    "                radar_df[feature] = radar_df[feature] / feature_max\n",
    "                \n",
    "        # Number of features\n",
    "        N = len(available_features)\n",
    "        \n",
    "        # Create angles for radar chart\n",
    "        angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Close the loop\n",
    "        \n",
    "        # Create subplot with polar projection\n",
    "        ax = plt.subplot(111, polar=True)\n",
    "        \n",
    "        # Add feature labels\n",
    "        plt.xticks(angles[:-1], available_features, size=12)\n",
    "        \n",
    "        # Plot each cluster\n",
    "        for cluster_id, name in cluster_names.items():\n",
    "            values = radar_df.loc[cluster_id].tolist()\n",
    "            values += values[:1]  # Close the loop\n",
    "            \n",
    "            ax.plot(angles, values, linewidth=2, label=name)\n",
    "            ax.fill(angles, values, alpha=0.1)\n",
    "            \n",
    "        plt.title('Trader Type Profiles', size=15)\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "        plt.savefig(os.path.join(results_dir, 'trader_type_radar.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Bar chart of cluster sizes\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Sort by size\n",
    "        sorted_profiles = cluster_profiles.sort_values('size', ascending=False)\n",
    "        \n",
    "        # Create bar chart\n",
    "        plt.bar(\n",
    "            range(len(sorted_profiles)), \n",
    "            sorted_profiles['size'],\n",
    "            tick_label=[f\"{cluster_names[i]}\\n({sorted_profiles.loc[i, 'percentage']:.1f}%)\" \n",
    "                       for i in sorted_profiles.index]\n",
    "        )\n",
    "        \n",
    "        plt.title('Trader Type Distribution')\n",
    "        plt.ylabel('Number of Traders')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, 'trader_type_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    return {\n",
    "        'trader_features': trader_df,\n",
    "        'cluster_profiles': cluster_profiles,\n",
    "        'cluster_names': cluster_names,\n",
    "        'feature_importance': feature_importance\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12cd490a",
   "metadata": {},
   "source": [
    "# Whales"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a36085ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_whales(trades_df, threshold=0.05, method='volume'):\n",
    "    \"\"\"\n",
    "    Identify whale traders based on trading volume or frequency\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    threshold : float\n",
    "        Threshold for defining whales (e.g., top 5%)\n",
    "    method : str\n",
    "        Method for identifying whales ('volume' or 'frequency')\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with whale identification results\n",
    "    \"\"\"\n",
    "    print(f\"Identifying whale traders (top {threshold*100:.1f}%)...\")\n",
    "    \n",
    "    # Create a trader metrics dataframe\n",
    "    trader_metrics = []\n",
    "    \n",
    "    # Find all unique trader IDs\n",
    "    if 'maker_id' in trades_df.columns and 'taker_id' in trades_df.columns:\n",
    "        all_traders = set(trades_df['maker_id'].dropna().unique()) | set(trades_df['taker_id'].dropna().unique())\n",
    "    elif 'trader_id' in trades_df.columns:\n",
    "        all_traders = set(trades_df['trader_id'].dropna().unique())\n",
    "    else:\n",
    "        print(\"Error: No trader identifier columns found\")\n",
    "        return None\n",
    "    \n",
    "    print(f\"Calculating metrics for {len(all_traders)} traders...\")\n",
    "    \n",
    "    # Calculate volume and frequency for each trader\n",
    "    for trader_id in all_traders:\n",
    "        # Get all trades where this trader was involved (as maker or taker)\n",
    "        if 'maker_id' in trades_df.columns and 'taker_id' in trades_df.columns:\n",
    "            maker_trades = trades_df[trades_df['maker_id'] == trader_id]\n",
    "            taker_trades = trades_df[trades_df['taker_id'] == trader_id]\n",
    "            trader_trades = pd.concat([maker_trades, taker_trades]).drop_duplicates()\n",
    "        else:\n",
    "            trader_trades = trades_df[trades_df['trader_id'] == trader_id]\n",
    "        \n",
    "        # Calculate volume\n",
    "        if 'trade_amount' in trader_trades.columns:\n",
    "            total_volume = trader_trades['trade_amount'].sum()\n",
    "        elif 'size' in trader_trades.columns:\n",
    "            total_volume = trader_trades['size'].sum()\n",
    "        else:\n",
    "            total_volume = len(trader_trades)\n",
    "        \n",
    "        # Store metrics\n",
    "        trader_metrics.append({\n",
    "            'trader_id': trader_id,\n",
    "            'volume': total_volume,\n",
    "            'trade_count': len(trader_trades)\n",
    "        })\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    metrics_df = pd.DataFrame(trader_metrics)\n",
    "    \n",
    "    # Determine metric to use for whale identification\n",
    "    if method == 'volume':\n",
    "        metric_col = 'volume'\n",
    "    else:  # frequency\n",
    "        metric_col = 'trade_count'\n",
    "    \n",
    "    # Sort by metric in descending order\n",
    "    metrics_df = metrics_df.sort_values(metric_col, ascending=False)\n",
    "    \n",
    "    # Define whales as top % of traders\n",
    "    whale_count = max(1, int(len(metrics_df) * threshold))\n",
    "    whales = metrics_df.head(whale_count).copy()\n",
    "    whale_ids = whales['trader_id'].tolist()\n",
    "    \n",
    "    print(f\"Identified {whale_count} whales out of {len(metrics_df)} traders\")\n",
    "    \n",
    "    # Calculate whale concentration\n",
    "    whale_concentration = whales[metric_col].sum() / metrics_df[metric_col].sum()\n",
    "    print(f\"Whales control {whale_concentration*100:.2f}% of total {method}\")\n",
    "    \n",
    "    # Calculate average metric for whales vs non-whales\n",
    "    whale_avg = whales[metric_col].mean()\n",
    "    non_whale_avg = metrics_df.iloc[whale_count:][metric_col].mean() if len(metrics_df) > whale_count else 0\n",
    "    whale_ratio = whale_avg / non_whale_avg if non_whale_avg > 0 else float('inf')\n",
    "    \n",
    "    print(f\"Average whale {method} is {whale_ratio:.1f}x higher than non-whale {method}\")\n",
    "    \n",
    "    # Visualize whale distribution\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Create histogram of volume/frequency distribution with log scale\n",
    "    plt.hist(metrics_df[metric_col], bins=50, log=True, alpha=0.7)\n",
    "    \n",
    "    # Add line for whale threshold\n",
    "    min_whale_value = whales[metric_col].min()\n",
    "    plt.axvline(min_whale_value, color='red', linestyle='--', \n",
    "                label=f'Whale threshold: {min_whale_value:.0f}')\n",
    "    \n",
    "    plt.title(f'Distribution of Trader {method.capitalize()} (Log Scale)')\n",
    "    plt.xlabel(metric_col.capitalize())\n",
    "    plt.ylabel('Count (Log Scale)')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_dir, f'whale_distribution_{method}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create Lorenz curve\n",
    "    plt.figure(figsize=(10, 6))\n",
    "    \n",
    "    # Sort values for Lorenz curve\n",
    "    sorted_values = np.sort(metrics_df[metric_col].values)\n",
    "    cumulative_pct = np.cumsum(sorted_values) / np.sum(sorted_values)\n",
    "    \n",
    "    # Plot Lorenz curve\n",
    "    plt.plot([0] + list(range(1, len(cumulative_pct) + 1)), [0] + list(cumulative_pct), \n",
    "             label='Lorenz curve')\n",
    "    \n",
    "    # Plot line of equality\n",
    "    plt.plot([0, len(cumulative_pct)], [0, 1], 'k--', label='Line of equality')\n",
    "    \n",
    "    # Highlight area representing Gini coefficient\n",
    "    plt.fill_between(range(len(cumulative_pct) + 1), \n",
    "                    [0] + list(np.linspace(0, 1, len(cumulative_pct))),\n",
    "                    [0] + list(cumulative_pct), \n",
    "                    alpha=0.2)\n",
    "    \n",
    "    # Calculate Gini coefficient\n",
    "    gini = 1 - 2 * np.trapz(cumulative_pct) / len(cumulative_pct)\n",
    "    \n",
    "    plt.title(f'Lorenz Curve of Trader {method.capitalize()} Distribution (Gini: {gini:.4f})')\n",
    "    plt.xlabel('Cumulative % of Traders')\n",
    "    plt.ylabel(f'Cumulative % of {method.capitalize()}')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_dir, f'lorenz_curve_{method}.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        'whale_ids': whale_ids,\n",
    "        'whales': whales,\n",
    "        'whale_concentration': whale_concentration,\n",
    "        'whale_to_non_whale_ratio': whale_ratio,\n",
    "        'gini_coefficient': gini\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "22af4ebd",
   "metadata": {},
   "source": [
    "## Price Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6e1e8bac",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_whale_price_impact(trades_df, whale_ids, window=5):\n",
    "    \"\"\"\n",
    "    Analyze the price impact of whale trades\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    whale_ids : list\n",
    "        List of whale trader IDs\n",
    "    window : int\n",
    "        Number of trades to consider for price impact\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with price impact analysis results\n",
    "    \"\"\"\n",
    "    if 'price' not in trades_df.columns:\n",
    "        print(\"Error: price column not found\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Analyzing price impact of whale trades...\")\n",
    "    \n",
    "    # Identify whale trades\n",
    "    if 'maker_id' in trades_df.columns and 'taker_id' in trades_df.columns:\n",
    "        whale_trades = trades_df[(trades_df['maker_id'].isin(whale_ids)) | \n",
    "                               (trades_df['taker_id'].isin(whale_ids))]\n",
    "        non_whale_trades = trades_df[~((trades_df['maker_id'].isin(whale_ids)) | \n",
    "                                     (trades_df['taker_id'].isin(whale_ids)))]\n",
    "    elif 'trader_id' in trades_df.columns:\n",
    "        whale_trades = trades_df[trades_df['trader_id'].isin(whale_ids)]\n",
    "        non_whale_trades = trades_df[~trades_df['trader_id'].isin(whale_ids)]\n",
    "    else:\n",
    "        print(\"Error: No trader identifier columns found\")\n",
    "        return None\n",
    "    \n",
    "    if len(whale_trades) == 0:\n",
    "        print(\"No whale trades found\")\n",
    "        return None\n",
    "        \n",
    "    print(f\"Found {len(whale_trades)} whale trades out of {len(trades_df)} total trades\")\n",
    "    \n",
    "    # Ensure trades are sorted by timestamp\n",
    "    if 'timestamp' in trades_df.columns:\n",
    "        trades_df = trades_df.sort_values('timestamp')\n",
    "    \n",
    "    # Calculate price impact for each whale trade\n",
    "    whale_impacts = []\n",
    "    \n",
    "    # Group by market_id to analyze within each market\n",
    "    for market_id, market_trades in trades_df.groupby('market_id'):\n",
    "        market_trades = market_trades.sort_values('timestamp').reset_index(drop=True)\n",
    "        \n",
    "        # Get whale trades in this market\n",
    "        if 'maker_id' in market_trades.columns and 'taker_id' in market_trades.columns:\n",
    "            market_whale_trades = market_trades[(market_trades['maker_id'].isin(whale_ids)) | \n",
    "                                             (market_trades['taker_id'].isin(whale_ids))]\n",
    "        else:\n",
    "            market_whale_trades = market_trades[market_trades['trader_id'].isin(whale_ids)]\n",
    "        \n",
    "        for _, whale_trade in market_whale_trades.iterrows():\n",
    "            # Find the position of this trade in the market trades\n",
    "            if 'timestamp' in whale_trade:\n",
    "                # Find trades with the same timestamp\n",
    "                try:\n",
    "                    same_time_trades = market_trades[market_trades['timestamp'] == whale_trade['timestamp']]\n",
    "                    if len(same_time_trades) == 0:\n",
    "                        continue\n",
    "                    \n",
    "                    trade_idx = same_time_trades.index[0]  # Use the first one if multiple\n",
    "                except:\n",
    "                    # Skip if timestamp comparison fails\n",
    "                    continue\n",
    "            else:\n",
    "                # Skip if no timestamp\n",
    "                continue\n",
    "                \n",
    "            # Get price before trade (window trades before)\n",
    "            before_indices = market_trades.index[market_trades.index < trade_idx]\n",
    "            if len(before_indices) >= window:\n",
    "                before_idx = before_indices[-window]  # window trades before\n",
    "                price_before = market_trades.loc[before_idx, 'price']\n",
    "            elif len(before_indices) > 0:\n",
    "                before_idx = before_indices[0]  # first available trade\n",
    "                price_before = market_trades.loc[before_idx, 'price']\n",
    "            else:\n",
    "                continue  # Skip if not enough prior trades\n",
    "                \n",
    "            # Get price after trade (window trades after)\n",
    "            after_indices = market_trades.index[market_trades.index > trade_idx]\n",
    "            if len(after_indices) >= window:\n",
    "                after_idx = after_indices[window-1]  # window trades after\n",
    "                price_after = market_trades.loc[after_idx, 'price']\n",
    "            elif len(after_indices) > 0:\n",
    "                after_idx = after_indices[-1]  # last available trade\n",
    "                price_after = market_trades.loc[after_idx, 'price']\n",
    "            else:\n",
    "                continue  # Skip if not enough subsequent trades\n",
    "                \n",
    "            # Calculate price impact\n",
    "            price_impact = price_after - price_before\n",
    "            \n",
    "            # Determine trader role (maker or taker)\n",
    "            if 'maker_id' in market_trades.columns and whale_trade['maker_id'] in whale_ids:\n",
    "                role = 'maker'\n",
    "                trader_id = whale_trade['maker_id']\n",
    "            elif 'taker_id' in market_trades.columns and whale_trade['taker_id'] in whale_ids:\n",
    "                role = 'taker'\n",
    "                trader_id = whale_trade['taker_id']\n",
    "            else:\n",
    "                role = 'unknown'\n",
    "                trader_id = whale_trade.get('trader_id', 'unknown')\n",
    "            \n",
    "            # Calculate trade size\n",
    "            if 'trade_amount' in whale_trade:\n",
    "                trade_size = whale_trade['trade_amount']\n",
    "            elif 'size' in whale_trade:\n",
    "                trade_size = whale_trade['size']\n",
    "            else:\n",
    "                trade_size = 1.0\n",
    "            \n",
    "            # Store result\n",
    "            whale_impacts.append({\n",
    "                'market_id': market_id,\n",
    "                'trader_id': trader_id,\n",
    "                'role': role,\n",
    "                'trade_size': trade_size,\n",
    "                'timestamp': whale_trade['timestamp'] if 'timestamp' in whale_trade else None,\n",
    "                'price_before': price_before,\n",
    "                'trade_price': whale_trade['price'],\n",
    "                'price_after': price_after,\n",
    "                'price_impact': price_impact,\n",
    "                'abs_price_impact': abs(price_impact),\n",
    "                'relative_impact': price_impact / price_before if price_before > 0 else 0\n",
    "            })\n",
    "    \n",
    "    if not whale_impacts:\n",
    "        print(\"No whale price impacts could be calculated\")\n",
    "        return None\n",
    "        \n",
    "    # Convert to DataFrame\n",
    "    impacts_df = pd.DataFrame(whale_impacts)\n",
    "    \n",
    "    # Calculate average impact\n",
    "    avg_impact = impacts_df['price_impact'].mean()\n",
    "    avg_abs_impact = impacts_df['abs_price_impact'].mean()\n",
    "    avg_rel_impact = impacts_df['relative_impact'].mean() * 100  # as percentage\n",
    "    \n",
    "    print(f\"Average price impact: {avg_impact:.6f}\")\n",
    "    print(f\"Average absolute price impact: {avg_abs_impact:.6f}\")\n",
    "    print(f\"Average relative impact: {avg_rel_impact:.2f}%\")\n",
    "    \n",
    "    # Calculate positive and negative impacts\n",
    "    positive_impacts = impacts_df[impacts_df['price_impact'] > 0]\n",
    "    negative_impacts = impacts_df[impacts_df['price_impact'] < 0]\n",
    "    \n",
    "    positive_pct = len(positive_impacts) / len(impacts_df) * 100 if len(impacts_df) > 0 else 0\n",
    "    print(f\"Positive impacts: {positive_pct:.1f}% of trades\")\n",
    "    \n",
    "    # Calculate following ratio\n",
    "    following_ratio = calculate_following_ratio(trades_df, whale_ids)\n",
    "    \n",
    "    # Create histogram of price impacts\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    sns.histplot(impacts_df['price_impact'], kde=True, bins=30)\n",
    "    plt.axvline(0, color='red', linestyle='--', label='No impact')\n",
    "    plt.axvline(avg_impact, color='green', linestyle='-', \n",
    "                label=f'Mean impact: {avg_impact:.4f}')\n",
    "    plt.title('Distribution of Whale Trade Price Impacts')\n",
    "    plt.xlabel('Price Impact')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.savefig(os.path.join(results_dir, 'whale_price_impacts.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    # Create scatter plot of trade size vs price impact\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    plt.scatter(impacts_df['trade_size'], impacts_df['price_impact'], alpha=0.5)\n",
    "    plt.axhline(0, color='red', linestyle='--')\n",
    "    plt.title('Trade Size vs Price Impact')\n",
    "    plt.xlabel('Trade Size')\n",
    "    plt.ylabel('Price Impact')\n",
    "    plt.savefig(os.path.join(results_dir, 'trade_size_vs_impact.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        'impacts': impacts_df,\n",
    "        'avg_impact': avg_impact,\n",
    "        'avg_abs_impact': avg_abs_impact,\n",
    "        'avg_rel_impact': avg_rel_impact,\n",
    "        'positive_pct': positive_pct,\n",
    "        'following_ratio': following_ratio\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c7ce1d3c",
   "metadata": {},
   "source": [
    "## Following Ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e699eb36",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_following_ratio(trades_df, whale_ids, window_minutes=30):\n",
    "    \"\"\"\n",
    "    Calculate how often non-whale traders follow whale trades in the same direction\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    whale_ids : list\n",
    "        List of whale trader IDs\n",
    "    window_minutes : int\n",
    "        Time window in minutes to consider for following behavior\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    float\n",
    "        Ratio of non-whale trades following whale trades in same direction\n",
    "    \"\"\"\n",
    "    # Check if we have trade direction information\n",
    "    if 'side' in trades_df.columns:\n",
    "        direction_col = 'side'\n",
    "    elif 'trade_direction' in trades_df.columns:\n",
    "        direction_col = 'trade_direction'\n",
    "    else:\n",
    "        print(\"Warning: No trade direction information available\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure trades are sorted by timestamp\n",
    "    if 'timestamp' not in trades_df.columns:\n",
    "        print(\"Warning: No timestamp information for following ratio analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Ensure timestamp is datetime\n",
    "    if not pd.api.types.is_datetime64_any_dtype(trades_df['timestamp']):\n",
    "        trades_df = trades_df.copy()\n",
    "        trades_df['timestamp'] = pd.to_datetime(trades_df['timestamp'])\n",
    "    \n",
    "    trades_df = trades_df.sort_values('timestamp')\n",
    "    \n",
    "    # Identify whale and non-whale trades\n",
    "    if 'maker_id' in trades_df.columns and 'taker_id' in trades_df.columns:\n",
    "        whale_trades = trades_df[(trades_df['maker_id'].isin(whale_ids)) | \n",
    "                                (trades_df['taker_id'].isin(whale_ids))]\n",
    "        non_whale_trades = trades_df[~((trades_df['maker_id'].isin(whale_ids)) | \n",
    "                                     (trades_df['taker_id'].isin(whale_ids)))]\n",
    "    elif 'trader_id' in trades_df.columns:\n",
    "        whale_trades = trades_df[trades_df['trader_id'].isin(whale_ids)]\n",
    "        non_whale_trades = trades_df[~trades_df['trader_id'].isin(whale_ids)]\n",
    "    else:\n",
    "        print(\"Error: No trader identifier columns found\")\n",
    "        return None\n",
    "    \n",
    "    if len(whale_trades) == 0 or len(non_whale_trades) == 0:\n",
    "        print(\"Not enough trades to calculate following ratio\")\n",
    "        return None\n",
    "    \n",
    "    following_count = 0\n",
    "    total_count = 0\n",
    "    \n",
    "    # Group by market_id to analyze within each market\n",
    "    for market_id, market_trades in trades_df.groupby('market_id'):\n",
    "        market_trades = market_trades.sort_values('timestamp')\n",
    "        \n",
    "        # Get whale trades in this market\n",
    "        if 'maker_id' in market_trades.columns and 'taker_id' in market_trades.columns:\n",
    "            market_whale_trades = market_trades[(market_trades['maker_id'].isin(whale_ids)) | \n",
    "                                             (market_trades['taker_id'].isin(whale_ids))]\n",
    "            market_non_whale_trades = market_trades[~((market_trades['maker_id'].isin(whale_ids)) | \n",
    "                                                   (market_trades['taker_id'].isin(whale_ids)))]\n",
    "        else:\n",
    "            market_whale_trades = market_trades[market_trades['trader_id'].isin(whale_ids)]\n",
    "            market_non_whale_trades = market_trades[~market_trades['trader_id'].isin(whale_ids)]\n",
    "        \n",
    "        # Skip if not enough trades\n",
    "        if len(market_whale_trades) == 0 or len(market_non_whale_trades) == 0:\n",
    "            continue\n",
    "        \n",
    "        # Check each whale trade\n",
    "        for _, whale_trade in market_whale_trades.iterrows():\n",
    "            # Get whale trade direction\n",
    "            if direction_col in whale_trade:\n",
    "                whale_direction = whale_trade[direction_col]\n",
    "            else:\n",
    "                continue\n",
    "            \n",
    "            # Define time window for subsequent trades\n",
    "            whale_time = whale_trade['timestamp']\n",
    "            end_time = whale_time + pd.Timedelta(minutes=window_minutes)\n",
    "            \n",
    "            # Find non-whale trades within window\n",
    "            subsequent_trades = market_non_whale_trades[\n",
    "                (market_non_whale_trades['timestamp'] > whale_time) & \n",
    "                (market_non_whale_trades['timestamp'] <= end_time)\n",
    "            ]\n",
    "            \n",
    "            if len(subsequent_trades) == 0:\n",
    "                continue\n",
    "            \n",
    "            # Count trades in same direction\n",
    "            same_direction_trades = subsequent_trades[subsequent_trades[direction_col] == whale_direction]\n",
    "            \n",
    "            following_count += len(same_direction_trades)\n",
    "            total_count += len(subsequent_trades)\n",
    "    \n",
    "    # Calculate ratio\n",
    "    following_ratio = following_count / total_count if total_count > 0 else 0\n",
    "    print(f\"Non-whale traders follow whale trade direction {following_ratio*100:.1f}% of the time\")\n",
    "    \n",
    "    return following_ratio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3bea1898",
   "metadata": {},
   "source": [
    "## Granger Causality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe8744f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def test_granger_causality(trades_df, whale_ids, max_lag=5):\n",
    "    \"\"\"\n",
    "    Test if whale trades Granger-cause price movements\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    whale_ids : list\n",
    "        List of whale trader IDs\n",
    "    max_lag : int\n",
    "        Maximum number of lags to test\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with Granger causality results\n",
    "    \"\"\"\n",
    "    from statsmodels.tsa.stattools import grangercausalitytests\n",
    "    \n",
    "    if 'price' not in trades_df.columns:\n",
    "        print(\"Error: price column not found\")\n",
    "        return None\n",
    "        \n",
    "    if 'timestamp' not in trades_df.columns:\n",
    "        print(\"Error: timestamp column required for time series analysis\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Testing if whale trades Granger-cause price movements...\")\n",
    "    \n",
    "    # Ensure timestamp is datetime type\n",
    "    if not pd.api.types.is_datetime64_any_dtype(trades_df['timestamp']):\n",
    "        trades_df = trades_df.copy()\n",
    "        trades_df['timestamp'] = pd.to_datetime(trades_df['timestamp'])\n",
    "    \n",
    "    # Group by market_id to analyze each market separately\n",
    "    market_results = {}\n",
    "    \n",
    "    for market_id, market_trades in trades_df.groupby('market_id'):\n",
    "        print(f\"Testing market {market_id}...\")\n",
    "        \n",
    "        # Sort by timestamp\n",
    "        market_trades = market_trades.sort_values('timestamp')\n",
    "        \n",
    "        # Create indicator for whale activity (1 if trade involves a whale, 0 otherwise)\n",
    "        if 'maker_id' in market_trades.columns and 'taker_id' in market_trades.columns:\n",
    "            market_trades['is_whale'] = ((market_trades['maker_id'].isin(whale_ids)) | \n",
    "                                       (market_trades['taker_id'].isin(whale_ids))).astype(int)\n",
    "        else:\n",
    "            market_trades['is_whale'] = market_trades['trader_id'].isin(whale_ids).astype(int)\n",
    "        \n",
    "        # Resample to regular intervals\n",
    "        try:\n",
    "            # Set timestamp as index\n",
    "            market_trades = market_trades.set_index('timestamp')\n",
    "            \n",
    "            # Resample to 5-minute intervals\n",
    "            prices = market_trades['price'].resample('5T').last().ffill()\n",
    "            whale_activity = market_trades['is_whale'].resample('5T').sum().fillna(0)\n",
    "            \n",
    "            # Align the series and ensure sufficient data points\n",
    "            aligned_data = pd.concat([prices, whale_activity], axis=1).dropna()\n",
    "            aligned_data.columns = ['price', 'whale_activity']\n",
    "            \n",
    "            if len(aligned_data) <= max_lag + 2:\n",
    "                print(f\"  Insufficient data points for market {market_id} after resampling\")\n",
    "                continue\n",
    "                \n",
    "            # Run Granger causality test (whale_activity → price)\n",
    "            try:\n",
    "                gc_result = grangercausalitytests(\n",
    "                    aligned_data[['price', 'whale_activity']], \n",
    "                    maxlag=max_lag, \n",
    "                    verbose=False\n",
    "                )\n",
    "                \n",
    "                # Extract p-values for each lag\n",
    "                p_values = {lag: result[0]['ssr_chi2test'][1] for lag, result in gc_result.items()}\n",
    "                \n",
    "                # Find significant lags (p < 0.05)\n",
    "                significant_lags = [lag for lag, p in p_values.items() if p < 0.05]\n",
    "                \n",
    "                # Store results\n",
    "                market_results[market_id] = {\n",
    "                    'p_values': p_values,\n",
    "                    'significant_lags': significant_lags,\n",
    "                    'min_p_value': min(p_values.values()) if p_values else 1.0,\n",
    "                    'best_lag': min(p_values, key=p_values.get) if p_values else None,\n",
    "                    'is_significant': len(significant_lags) > 0\n",
    "                }\n",
    "                \n",
    "                result_str = \"SIGNIFICANT\" if len(significant_lags) > 0 else \"not significant\"\n",
    "                print(f\"  Result: {result_str} (best lag: {market_results[market_id]['best_lag']})\")\n",
    "            except Exception as e:\n",
    "                print(f\"  Error in Granger causality test: {e}\")\n",
    "        except Exception as e:\n",
    "            print(f\"  Error processing market {market_id}: {e}\")\n",
    "    \n",
    "    if not market_results:\n",
    "        print(\"No Granger causality results obtained\")\n",
    "        return None\n",
    "        \n",
    "    # Summarize results\n",
    "    significant_markets = sum(1 for r in market_results.values() if r['is_significant'])\n",
    "    total_markets = len(market_results)\n",
    "    \n",
    "    significance_ratio = significant_markets / total_markets if total_markets > 0 else 0\n",
    "    print(f\"\\nGranger causality is significant in {significant_markets} of {total_markets} markets ({significance_ratio*100:.1f}%)\")\n",
    "    \n",
    "    # Calculate average lag of significant effects\n",
    "    if significant_markets > 0:\n",
    "        best_lags = [r['best_lag'] for r in market_results.values() if r['is_significant']]\n",
    "        avg_lag = sum(best_lags) / len(best_lags) if best_lags else 0\n",
    "        print(f\"Average lag of significant effects: {avg_lag:.1f} intervals\")\n",
    "    \n",
    "    # Create visualization of p-values\n",
    "    plt.figure(figsize=(12, 6))\n",
    "    \n",
    "    # Extract min p-values for each market\n",
    "    market_ids = list(market_results.keys())\n",
    "    min_p_values = [market_results[m]['min_p_value'] for m in market_ids]\n",
    "    \n",
    "    # Sort by p-value\n",
    "    sorted_indices = np.argsort(min_p_values)\n",
    "    sorted_markets = [market_ids[i] for i in sorted_indices]\n",
    "    sorted_p_values = [min_p_values[i] for i in sorted_indices]\n",
    "    \n",
    "    # Create bar chart\n",
    "    bars = plt.bar(range(len(sorted_markets)), sorted_p_values, color='skyblue')\n",
    "    \n",
    "    # Highlight significant markets\n",
    "    for i, p_value in enumerate(sorted_p_values):\n",
    "        if p_value < 0.05:\n",
    "            bars[i].set_color('green')\n",
    "    \n",
    "    # Add significance threshold line\n",
    "    plt.axhline(0.05, color='red', linestyle='--', label='Significance threshold (p=0.05)')\n",
    "    \n",
    "    plt.title('Granger Causality Test: Do Whale Trades Predict Price Movements?')\n",
    "    plt.ylabel('Minimum p-value')\n",
    "    plt.xlabel('Markets (sorted by p-value)')\n",
    "    plt.xticks([])  # Hide x-tick labels for cleaner visualization\n",
    "    plt.legend()\n",
    "    plt.tight_layout()\n",
    "    plt.savefig(os.path.join(results_dir, 'granger_causality_results.png'), dpi=300, bbox_inches='tight')\n",
    "    plt.close()\n",
    "    \n",
    "    return {\n",
    "        'market_results': market_results,\n",
    "        'significant_ratio': significance_ratio,\n",
    "        'significant_markets': significant_markets,\n",
    "        'total_markets': total_markets,\n",
    "        'avg_lag': avg_lag if significant_markets > 0 else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dd7449b",
   "metadata": {},
   "source": [
    "## Trader Profitability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c587854",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trader_profitability(trades_df, classification_results=None):\n",
    "    \"\"\"\n",
    "    Analyze trader profitability and success rates if profit data is available\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    classification_results : dict, optional\n",
    "        Dictionary with trader classification results\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with profitability analysis results\n",
    "    \"\"\"\n",
    "    if 'profit' not in trades_df.columns:\n",
    "        print(\"Warning: profit column not found, trying to calculate\")\n",
    "        # Try to calculate profit using price changes\n",
    "        if 'price' in trades_df.columns and 'trade_amount' in trades_df.columns and 'trade_direction' in trades_df.columns:\n",
    "            try:\n",
    "                # This is a simplified calculation and may not be accurate\n",
    "                # A proper calculation would require entry and exit prices for each position\n",
    "                trades_df['profit'] = trades_df['price'] * trades_df['trade_amount'] * (\n",
    "                    trades_df['trade_direction'].map({'buy': 1, 'sell': -1})\n",
    "                )\n",
    "                print(\"Created simple profit proxy based on price and direction\")\n",
    "            except Exception as e:\n",
    "                print(f\"Error calculating profit: {e}\")\n",
    "                return None\n",
    "        else:\n",
    "            print(\"Cannot calculate or find profit information\")\n",
    "            return None\n",
    "    \n",
    "    print(\"Analyzing trader profitability...\")\n",
    "    \n",
    "    # Calculate profitability by trader\n",
    "    trader_profit = trades_df.groupby('trader_id')['profit'].agg(['sum', 'mean', 'count'])\n",
    "    trader_profit.columns = ['total_profit', 'avg_profit_per_trade', 'trade_count']\n",
    "    \n",
    "    # Calculate win rate (if profit values are reliable)\n",
    "    trader_win_rate = trades_df.groupby('trader_id')['profit'].apply(\n",
    "        lambda x: (x > 0).mean()\n",
    "    ).rename('win_rate')\n",
    "    \n",
    "    # Combine metrics\n",
    "    trader_metrics = pd.concat([trader_profit, trader_win_rate], axis=1)\n",
    "    \n",
    "    # Sort by total profit\n",
    "    trader_metrics = trader_metrics.sort_values('total_profit', ascending=False)\n",
    "    \n",
    "    # Calculate profit concentration (Gini coefficient)\n",
    "    profit_gini = calculate_gini(trader_metrics['total_profit'].values)\n",
    "    print(f\"Profit concentration (Gini): {profit_gini:.4f}\")\n",
    "    \n",
    "    # Calculate average metrics\n",
    "    avg_win_rate = trader_metrics['win_rate'].mean()\n",
    "    print(f\"Average win rate: {avg_win_rate:.1%}\")\n",
    "    \n",
    "    # If trader classification is available, analyze by type\n",
    "    type_metrics = None\n",
    "    if classification_results is not None and 'trader_features' in classification_results:\n",
    "        # Merge with trader types\n",
    "        trader_features = classification_results['trader_features']\n",
    "        trader_metrics_with_type = trader_metrics.reset_index().merge(\n",
    "            trader_features[['trader_id', 'cluster']],\n",
    "            on='trader_id',\n",
    "            how='left'\n",
    "        )\n",
    "        \n",
    "        # Add trader type labels\n",
    "        cluster_names = classification_results.get('cluster_names', {})\n",
    "        trader_metrics_with_type['trader_type'] = trader_metrics_with_type['cluster'].map(\n",
    "            lambda x: cluster_names.get(x, f\"Cluster {x}\")\n",
    "        )\n",
    "        \n",
    "        # Calculate metrics by trader type\n",
    "        type_metrics = trader_metrics_with_type.groupby('trader_type').agg({\n",
    "            'total_profit': ['mean', 'sum'],\n",
    "            'avg_profit_per_trade': 'mean',\n",
    "            'win_rate': 'mean',\n",
    "            'trade_count': ['mean', 'sum', 'count']\n",
    "        })\n",
    "        \n",
    "        # Flatten column names\n",
    "        type_metrics.columns = ['_'.join(col).strip() for col in type_metrics.columns.values]\n",
    "        \n",
    "        # Rename count column\n",
    "        type_metrics = type_metrics.rename(columns={'trade_count_count': 'trader_count'})\n",
    "        \n",
    "        # Calculate profit per trader\n",
    "        type_metrics['profit_per_trader'] = type_metrics['total_profit_sum'] / type_metrics['trader_count']\n",
    "        \n",
    "        print(\"\\nProfitability by trader type:\")\n",
    "        print(type_metrics[['trader_count', 'win_rate_mean', 'profit_per_trader']])\n",
    "        \n",
    "        # Create visualization of profitability by trader type\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Sort by profit per trader\n",
    "        sorted_types = type_metrics.sort_values('profit_per_trader', ascending=False)\n",
    "        \n",
    "        # Create bar chart\n",
    "        bars = plt.bar(sorted_types.index, sorted_types['profit_per_trader'])\n",
    "        \n",
    "        # Add trader count labels\n",
    "        for i, bar in enumerate(bars):\n",
    "            trader_count = sorted_types.iloc[i]['trader_count']\n",
    "            plt.text(\n",
    "                bar.get_x() + bar.get_width()/2, \n",
    "                bar.get_height() + (0.05 * sorted_types['profit_per_trader'].max()), \n",
    "                f\"n={trader_count:.0f}\",\n",
    "                ha='center'\n",
    "            )\n",
    "        \n",
    "        plt.title('Average Profit per Trader by Trader Type')\n",
    "        plt.ylabel('Profit per Trader')\n",
    "        plt.xticks(rotation=45, ha='right')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, 'profit_by_trader_type.png'), dpi=300, bbox_inches='tight')\n",
    "    \n",
    "    return {\n",
    "        'trader_metrics': trader_metrics,\n",
    "        'profit_gini': profit_gini,\n",
    "        'avg_win_rate': avg_win_rate,\n",
    "        'type_metrics': type_metrics\n",
    "    }\n",
    "\n",
    "# Run profitability analysis if trade data is available\n",
    "profitability_results = None\n",
    "if trade_data is not None and 'trader_id' in trade_data.columns:\n",
    "    profitability_results = analyze_trader_profitability(\n",
    "        trade_data, \n",
    "        classification_results=classification_results if 'classification_results' in locals() else None\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "02e21d87",
   "metadata": {},
   "source": [
    "# Aggregated Analysis "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b50f2f3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def run_trader_analysis():\n",
    "    \"\"\"\n",
    "    Run the complete trader analysis pipeline and generate report\n",
    "    \"\"\"\n",
    "    print(\"=\"*80)\n",
    "    print(\"TRADER ANALYSIS FOR PREDICTION MARKETS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Step 1: Load trade data\n",
    "    print(\"\\nStep 1: Loading trade data...\")\n",
    "    trade_data = load_trade_data_for_analysis(n_markets=5, max_trades_per_market=50000)\n",
    "    \n",
    "    if trade_data is None or len(trade_data) == 0:\n",
    "        print(\"Error: No trade data available for analysis\")\n",
    "        return\n",
    "    \n",
    "    # Step 2: Classify trader types\n",
    "    print(\"\\nStep 2: Classifying trader types...\")\n",
    "    classification_results = classify_traders(trade_data, n_clusters=5)\n",
    "    \n",
    "    # Step 3: Identify whale traders\n",
    "    print(\"\\nStep 3: Identifying whale traders...\")\n",
    "    whale_results = identify_whales(trade_data, threshold=0.05, method='volume')\n",
    "    \n",
    "    if whale_results is None or 'whale_ids' not in whale_results:\n",
    "        print(\"Error: Could not identify whale traders\")\n",
    "        return\n",
    "    \n",
    "    # Step 4: Analyze price impact\n",
    "    print(\"\\nStep 4: Analyzing price impact of whale traders...\")\n",
    "    impact_results = analyze_whale_price_impact(trade_data, whale_results['whale_ids'])\n",
    "    \n",
    "    # Step 5: Test Granger causality\n",
    "    print(\"\\nStep 5: Testing Granger causality...\")\n",
    "    gc_results = test_granger_causality(trade_data, whale_results['whale_ids'])\n",
    "    \n",
    "    # Step 6: Generate comprehensive report\n",
    "    print(\"\\nStep 6: Generating final report...\")\n",
    "    \n",
    "    report = {\n",
    "        'timestamp': datetime.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "        'data_summary': {\n",
    "            'total_trades': len(trade_data),\n",
    "            'unique_traders': trade_data['trader_id'].nunique() if 'trader_id' in trade_data.columns else 0,\n",
    "            'markets_analyzed': trade_data['market_id'].nunique() if 'market_id' in trade_data.columns else 0\n",
    "        },\n",
    "        'trader_types': {\n",
    "            'num_types': len(classification_results['cluster_profiles']) if classification_results is not None else 0,\n",
    "            'types': {name: float(classification_results['cluster_profiles'].loc[i, 'percentage']) \n",
    "                     for i, name in classification_results['cluster_names'].items()} \n",
    "                     if classification_results is not None else {}\n",
    "        },\n",
    "        \"whale_analysis\": {\n",
    "            \"whale_concentration\": float(whale_results['whale_concentration']) if 'whale_results' in locals() and whale_results is not None else None,\n",
    "            \"whale_impact\": float(impact_results['avg_impact']) if 'impact_results' in locals() and impact_results is not None else None,\n",
    "            \"following_ratio\": float(impact_results['following_ratio']) if 'impact_results' in locals() and impact_results is not None else None\n",
    "        },\n",
    "        \"causality\": {\n",
    "            \"significant_ratio\": float(gc_results['significant_ratio']) if 'gc_results' in locals() and gc_results is not None else None\n",
    "        },\n",
    "        \"profitability\": {\n",
    "            \"profit_gini\": float(profitability_results['profit_gini']) if 'profitability_results' in locals() and profitability_results is not None else None\n",
    "        }\n",
    "    }\n",
    "    \n",
    "    # Save as JSON\n",
    "    import json\n",
    "    with open(os.path.join(results_dir, 'thesis_summary.json'), 'w') as f:\n",
    "        json.dump(thesis_summary, f, indent=2)\n",
    "    print(f\"\\nSaved thesis summary to {os.path.join(results_dir, 'thesis_summary.json')}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

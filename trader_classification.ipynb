{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "a1926d6c",
   "metadata": {},
   "source": [
    "# Set Up"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "7fd99a9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.decomposition import PCA\n",
    "from statsmodels.tsa.stattools import grangercausalitytests\n",
    "import warnings\n",
    "import json\n",
    "from datetime import datetime\n",
    "\n",
    "# Add src directory to path for importing utility functions\n",
    "current_dir = os.getcwd()\n",
    "parent_dir = os.path.dirname(current_dir) if current_dir.endswith('notebooks') else current_dir\n",
    "if parent_dir not in sys.path:\n",
    "    sys.path.append(parent_dir)\n",
    "\n",
    "# Import utility functions\n",
    "from src.utils.data_loader import load_main_dataset, load_trade_data\n",
    "\n",
    "# Create results directory\n",
    "results_dir = 'results/trader_analysis'\n",
    "os.makedirs(results_dir, exist_ok=True)\n",
    "\n",
    "# Suppress warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Set plotting style\n",
    "plt.style.use('seaborn-v0_8-whitegrid')\n",
    "sns.set_palette(\"viridis\")\n",
    "\n",
    "# Cell 2: Helper Functions (Remove function definitions, just define the functions)\n",
    "def calculate_gini(values):\n",
    "    if len(values) <= 1 or np.sum(values) == 0:\n",
    "        return 0\n",
    "    \n",
    "    sorted_values = np.sort(values)\n",
    "    n = len(sorted_values)\n",
    "    cumsum = np.cumsum(sorted_values)\n",
    "    return (n + 1 - 2 * np.sum((n + 1 - np.arange(1, n+1)) * sorted_values) / np.sum(sorted_values)) / n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "f00d5e8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading main dataset...\n",
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "Successfully loaded 1048575 markets\n",
      "\n",
      "Available trader-related columns:\n",
      "- last_trade_price\n",
      "- unique_traders_count\n",
      "- trader_to_trade_ratio\n",
      "- two_way_traders_ratio\n",
      "- trader_concentration\n",
      "- new_trader_influx\n",
      "- comment_per_trader\n",
      "\n",
      "Summary statistics for trader metrics:\n",
      "       unique_traders_count  trader_to_trade_ratio  two_way_traders_ratio  \\\n",
      "count            489.000000             489.000000             489.000000   \n",
      "mean            2192.934560               4.409763               0.312478   \n",
      "std             5783.946414               3.273783               0.230296   \n",
      "min               31.000000               1.227342               0.007680   \n",
      "25%              295.000000               2.786284               0.134066   \n",
      "50%              610.000000               3.389163               0.229508   \n",
      "75%             1824.000000               4.644178               0.476971   \n",
      "max            72183.000000              24.593060               0.870273   \n",
      "\n",
      "       new_trader_influx  \n",
      "count         489.000000  \n",
      "mean            0.295171  \n",
      "std             0.299848  \n",
      "min             0.000000  \n",
      "25%             0.027054  \n",
      "50%             0.191223  \n",
      "75%             0.498695  \n",
      "max             1.000000  \n"
     ]
    }
   ],
   "source": [
    "# Cell 3: Load Market Data\n",
    "print(\"Loading main dataset...\")\n",
    "market_data = load_main_dataset('data/cleaned_election_data.csv')\n",
    "\n",
    "if market_data is not None:\n",
    "    print(f\"Successfully loaded {len(market_data)} markets\")\n",
    "    \n",
    "    # Explore trader-related metrics\n",
    "    trader_cols = [col for col in market_data.columns if any(term in col.lower() \n",
    "                   for term in ['trader', 'trade', 'concentration'])]\n",
    "    \n",
    "    print(\"\\nAvailable trader-related columns:\")\n",
    "    for col in trader_cols:\n",
    "        print(f\"- {col}\")\n",
    "        \n",
    "    # Display basic statistics for key trader metrics\n",
    "    trader_metrics = ['unique_traders_count', 'trader_to_trade_ratio', \n",
    "                     'two_way_traders_ratio', 'new_trader_influx']\n",
    "    available_metrics = [col for col in trader_metrics if col in market_data.columns]\n",
    "    \n",
    "    if available_metrics:\n",
    "        print(\"\\nSummary statistics for trader metrics:\")\n",
    "        print(market_data[available_metrics].describe())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b6a33e0",
   "metadata": {},
   "source": [
    "# Load Trade Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "9023db12",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_trade_data_for_analysis(market_ids=None, max_trades_per_market=None):\n",
    "    \"\"\"\n",
    "    Load trade data for specific market IDs\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    market_ids : list, optional\n",
    "        List of specific market IDs to load\n",
    "    max_trades_per_market : int, optional\n",
    "        Maximum number of trades per market (None for all trades)\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Combined trade data from specified markets\n",
    "    \"\"\"\n",
    "    print(\"Loading market data...\")\n",
    "    market_data = load_main_dataset('data/cleaned_election_data.csv')\n",
    "    \n",
    "    if market_data is None:\n",
    "        print(\"Failed to load market data\")\n",
    "        return None\n",
    "    \n",
    "    # If market_ids not provided, use all markets\n",
    "    if market_ids is None:\n",
    "        market_ids = market_data['id'].tolist()\n",
    "    \n",
    "    print(f\"Selected {len(market_ids)} markets for analysis\")\n",
    "    \n",
    "    from src.utils.data_loader import load_trade_data, get_token_ids_for_market\n",
    "    \n",
    "    all_trades = []\n",
    "    for i, market_id in enumerate(market_ids):\n",
    "        try:\n",
    "            # Get market name if available\n",
    "            market_name = market_data.loc[market_data['id'] == market_id, 'question'].iloc[0] \\\n",
    "                         if 'question' in market_data.columns else f\"Market {market_id}\"\n",
    "            \n",
    "            print(f\"\\nLoading trades for market {i+1}/{len(market_ids)}: {market_name}\")\n",
    "            print(f\"Market ID: {market_id}\")\n",
    "            \n",
    "            # Try to load trade data using utility function\n",
    "            trades = load_trade_data(market_id)\n",
    "            \n",
    "            if trades is not None and len(trades) > 0:\n",
    "                print(f\"Successfully loaded {len(trades)} trades directly\")\n",
    "                \n",
    "                # Add market identifier\n",
    "                trades['market_id'] = float(market_id)\n",
    "                \n",
    "                # Sample if max_trades_per_market is specified\n",
    "                if max_trades_per_market is not None and len(trades) > max_trades_per_market:\n",
    "                    print(f\"Sampling {max_trades_per_market} trades from {len(trades)} total\")\n",
    "                    trades = trades.sample(max_trades_per_market, random_state=42)\n",
    "                \n",
    "                all_trades.append(trades)\n",
    "            else:\n",
    "                print(\"No trades found using default method, trying alternative approaches\")\n",
    "                \n",
    "                # Try to get token IDs for this market\n",
    "                token_ids = get_token_ids_for_market(market_id, main_df=market_data)\n",
    "                \n",
    "                if token_ids and len(token_ids) > 0:\n",
    "                    print(f\"Found {len(token_ids)} token IDs for market {market_id}\")\n",
    "                    \n",
    "                    # Try to locate token files directly\n",
    "                    from src.utils.data_loader import find_token_id_file\n",
    "                    \n",
    "                    market_trades = []\n",
    "                    for token_id in token_ids:\n",
    "                        try:\n",
    "                            token_file = find_token_id_file(token_id)\n",
    "                            if token_file:\n",
    "                                print(f\"Found token file: {os.path.basename(token_file)}\")\n",
    "                                \n",
    "                                # Load this token's trades\n",
    "                                import pyarrow.parquet as pq\n",
    "                                token_trades = pq.read_table(token_file).to_pandas()\n",
    "                                token_trades['market_id'] = float(market_id)\n",
    "                                token_trades['token_id'] = token_id\n",
    "                                \n",
    "                                market_trades.append(token_trades)\n",
    "                                print(f\"Loaded {len(token_trades)} trades for token {token_id}\")\n",
    "                        except Exception as e:\n",
    "                            print(f\"Error loading token {token_id}: {e}\")\n",
    "                    \n",
    "                    if market_trades:\n",
    "                        combined_market_trades = pd.concat(market_trades, ignore_index=True)\n",
    "                        \n",
    "                        # Sample if specified\n",
    "                        if max_trades_per_market is not None and len(combined_market_trades) > max_trades_per_market:\n",
    "                            print(f\"Sampling {max_trades_per_market} trades from {len(combined_market_trades)} total\")\n",
    "                            combined_market_trades = combined_market_trades.sample(max_trades_per_market, random_state=42)\n",
    "                        \n",
    "                        all_trades.append(combined_market_trades)\n",
    "                    else:\n",
    "                        print(f\"No trade data found for any tokens in market {market_id}\")\n",
    "                else:\n",
    "                    print(f\"No token IDs found for market {market_id}\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error loading trades for market {market_id}: {e}\")\n",
    "    \n",
    "    if not all_trades:\n",
    "        print(\"No trade data loaded for any markets\")\n",
    "        return None\n",
    "    \n",
    "    # Combine all trade data\n",
    "    combined_trades = pd.concat(all_trades, ignore_index=True)\n",
    "    \n",
    "    # Debug logging\n",
    "    print(f\"\\nTotal trades loaded: {len(combined_trades)} from {len(all_trades)} markets\")\n",
    "    print(\"\\nMarket-wise trade counts:\")\n",
    "    print(combined_trades['market_id'].value_counts())\n",
    "    \n",
    "    \n",
    "    \n",
    "    # Standardize trader ID and other columns\n",
    "    if 'maker' in combined_trades.columns and 'maker_id' not in combined_trades.columns:\n",
    "        combined_trades['maker_id'] = combined_trades['maker']\n",
    "    if 'taker' in combined_trades.columns and 'taker_id' not in combined_trades.columns:\n",
    "        combined_trades['taker_id'] = combined_trades['taker']\n",
    "    \n",
    "    # Create trader_id column\n",
    "    combined_trades['trader_id'] = combined_trades['maker_id']\n",
    "    \n",
    "    # Create trade_amount column if not present\n",
    "    if 'trade_amount' not in combined_trades.columns:\n",
    "        if 'size' in combined_trades.columns:\n",
    "            combined_trades['trade_amount'] = combined_trades['size']\n",
    "        else:\n",
    "            combined_trades['trade_amount'] = 1.0\n",
    "    \n",
    "    # Additional logging\n",
    "    unique_makers = combined_trades['maker_id'].nunique() if 'maker_id' in combined_trades.columns else 0\n",
    "    unique_takers = combined_trades['taker_id'].nunique() if 'taker_id' in combined_trades.columns else 0\n",
    "    unique_traders = combined_trades['trader_id'].nunique() if 'trader_id' in combined_trades.columns else 0\n",
    "    \n",
    "    print(f\"Unique traders identified: {unique_traders} (makers: {unique_makers}, takers: {unique_takers})\")\n",
    "    \n",
    "    return combined_trades"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "ea7f06aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scale_trade_volume(trades_df):\n",
    "    \"\"\"\n",
    "    Scale the trade volume data to appropriate units\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        DataFrame with scaled trade volumes\n",
    "    \"\"\"\n",
    "    print(\"Scaling trade volume data...\")\n",
    "    \n",
    "    # Create a copy to avoid modifying the original\n",
    "    df = trades_df.copy()\n",
    "    \n",
    "    # Check if we have trade_amount column\n",
    "    if 'trade_amount' in df.columns:\n",
    "        # Check if values are extremely large (likely in base units)\n",
    "        median_value = df['trade_amount'].median()\n",
    "        \n",
    "        if median_value > 10000:  # Threshold suggesting base units\n",
    "            scaling_factor = 1e6  # Standard scaling for USDC/USD\n",
    "            print(f\"Applying scaling factor of {scaling_factor:,.0f} to trade_amount\")\n",
    "            \n",
    "            # Store original values\n",
    "            df['trade_amount_original'] = df['trade_amount']\n",
    "            \n",
    "            # Scale values\n",
    "            df['trade_amount'] = df['trade_amount'] / scaling_factor\n",
    "            \n",
    "            print(f\"Volume before scaling: {df['trade_amount_original'].sum():,.2f}\")\n",
    "            print(f\"Volume after scaling: {df['trade_amount'].sum():,.2f}\")\n",
    "    \n",
    "    # Check for size column if trade_amount not present or was not scaled\n",
    "    elif 'size' in df.columns and 'trade_amount' not in df.columns:\n",
    "        # Convert size to numeric if needed\n",
    "        df['size'] = pd.to_numeric(df['size'], errors='coerce')\n",
    "        \n",
    "        # Check if values are extremely large\n",
    "        median_value = df['size'].median()\n",
    "        \n",
    "        if median_value > 10000:  # Threshold suggesting base units\n",
    "            scaling_factor = 1e6  # Standard scaling for USDC/USD\n",
    "            print(f\"Creating trade_amount from size with scaling factor of {scaling_factor:,.0f}\")\n",
    "            \n",
    "            # Create scaled trade_amount\n",
    "            df['trade_amount'] = df['size'] / scaling_factor\n",
    "        else:\n",
    "            # Use size directly\n",
    "            print(\"Using size directly as trade_amount\")\n",
    "            df['trade_amount'] = df['size']\n",
    "    \n",
    "    # Handle maker/taker filled amounts if present\n",
    "    elif all(col in df.columns for col in ['makerAmountFilled', 'takerAmountFilled']):\n",
    "        # Convert to numeric\n",
    "        df['makerAmountFilled'] = pd.to_numeric(df['makerAmountFilled'], errors='coerce')\n",
    "        \n",
    "        # Check if values are extremely large\n",
    "        median_value = df['makerAmountFilled'].median()\n",
    "        \n",
    "        if median_value > 10000:  # Threshold suggesting base units\n",
    "            scaling_factor = 1e6  # Standard scaling for USDC/USD\n",
    "            print(f\"Creating trade_amount from filled amounts with scaling factor of {scaling_factor:,.0f}\")\n",
    "            \n",
    "            # Create scaled trade_amount\n",
    "            df['trade_amount'] = df['makerAmountFilled'] / scaling_factor\n",
    "        else:\n",
    "            # Use makerAmountFilled directly\n",
    "            print(\"Using makerAmountFilled directly as trade_amount\")\n",
    "            df['trade_amount'] = df['makerAmountFilled']\n",
    "    \n",
    "    # Ensure trade_amount is clean (no invalid values)\n",
    "    if 'trade_amount' in df.columns:\n",
    "        # Replace any negative values with NaN\n",
    "        df.loc[df['trade_amount'] < 0, 'trade_amount'] = np.nan\n",
    "        \n",
    "        # Replace any extreme outliers (beyond 3 std from mean)\n",
    "        mean = df['trade_amount'].mean()\n",
    "        std = df['trade_amount'].std()\n",
    "        upper_limit = mean + 3 * std\n",
    "        \n",
    "        # Flag potential outliers but don't remove them\n",
    "        outliers = df['trade_amount'] > upper_limit\n",
    "        if outliers.sum() > 0:\n",
    "            print(f\"Identified {outliers.sum()} potential outliers (> {upper_limit:.2f})\")\n",
    "        \n",
    "        # Print summary statistics\n",
    "        print(\"\\nTrade amount summary statistics:\")\n",
    "        print(df['trade_amount'].describe())\n",
    "    \n",
    "    return df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "33dabdc3",
   "metadata": {},
   "source": [
    "## Define Target Markets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "77e8c6ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "Loading market data...\n",
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "Selected 2 markets for analysis\n",
      "\n",
      "Loading trades for market 1/2: Will Donald Trump win the 2024 US Presidential Election?\n",
      "Market ID: 253591.0\n",
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "Successfully loaded 1185000 trades directly\n",
      "\n",
      "Loading trades for market 2/2: Will Kamala Harris win the 2024 US Presidential Election?\n",
      "Market ID: 253597.0\n",
      "Loaded dataset with 1048575 rows and 54 columns\n",
      "No trade data found for market 253597.0\n",
      "No trades found using default method, trying alternative approaches\n",
      "Found 2 token IDs for market 253597.0\n",
      "Found token file: 69236923620077691027083946871148646972011131466059644796654161903044970987404.parquet 18-30-01-221.parquet\n",
      "Loaded 802000 trades for token 69236923620077691027083946871148646972011131466059644796654161903044970987404\n",
      "Found token file: 87584955359245246404952128082451897287778571240979823316620093987046202296181.parquet 18-30-01-396.parquet\n",
      "Loaded 444000 trades for token 87584955359245246404952128082451897287778571240979823316620093987046202296181\n",
      "\n",
      "Total trades loaded: 2431000 from 2 markets\n",
      "\n",
      "Market-wise trade counts:\n",
      "market_id\n",
      "253597.0    1246000\n",
      "253591.0    1185000\n",
      "Name: count, dtype: int64\n",
      "Unique traders identified: 113124 (makers: 113124, takers: 116804)\n"
     ]
    }
   ],
   "source": [
    "target_markets = [\n",
    "    \"Will Donald Trump win the 2024 US Presidential Election?\", \n",
    "    \"Will Kamala Harris win the 2024 US Presidential Election?\"\n",
    "]\n",
    "\n",
    "# Load main dataset\n",
    "market_data = load_main_dataset('data/cleaned_election_data.csv')\n",
    "\n",
    "# Filter to specific markets\n",
    "selected_markets = market_data[market_data['question'].isin(target_markets)]\n",
    "market_ids = selected_markets['id'].tolist()\n",
    "\n",
    "# Load ALL trades for these markets\n",
    "trade_data = load_trade_data_for_analysis(\n",
    "    market_ids=market_ids, \n",
    "    max_trades_per_market=None  # Load all trades\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "287ef71d",
   "metadata": {},
   "source": [
    "# Trader Classification and Analysis\n",
    "\n",
    "## 1. Basic Market Overview\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b2d9aa31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Market Trade Statistics:\n",
      "Total Trades: 2431000\n",
      "Unique Markets: 2\n",
      "Unique Traders: 113124\n"
     ]
    }
   ],
   "source": [
    "print(\"Market Trade Statistics:\")\n",
    "print(f\"Total Trades: {len(trade_data)}\")\n",
    "print(f\"Unique Markets: {trade_data['market_id'].nunique()}\")\n",
    "print(f\"Unique Traders: {trade_data['trader_id'].nunique()}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1009558",
   "metadata": {},
   "source": [
    "\n",
    "## 2. Identify Potential Whale Traders\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "abd033ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "def identify_whales(trades_df, default_threshold=0.01, generate_plots=True):\n",
    "    \"\"\"\n",
    "    Identify whale traders with visualization of different definitions\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    default_threshold : float\n",
    "        Default threshold for whale definition (as percentage, e.g., 0.01 for top 1%)\n",
    "    generate_plots : bool\n",
    "        Whether to generate visualization plots\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    tuple\n",
    "        Tuple containing (whale_ids, whale_results)\n",
    "    \"\"\"\n",
    "    print(\"Analyzing trader concentration and identifying whales...\")\n",
    "    \n",
    "    # Ensure we have the necessary columns\n",
    "    if 'trader_id' not in trades_df.columns or 'trade_amount' not in trades_df.columns:\n",
    "        print(\"Error: Missing required columns (trader_id, trade_amount)\")\n",
    "        return [], {}\n",
    "    \n",
    "    # Group trades by trader and calculate total volume\n",
    "    trader_volumes = trades_df.groupby('trader_id')['trade_amount'].sum().sort_values(ascending=False)\n",
    "    \n",
    "    # Calculate total volume\n",
    "    total_volume = trader_volumes.sum()\n",
    "    total_traders = len(trader_volumes)\n",
    "    \n",
    "    print(f\"Total traders: {total_traders:,}\")\n",
    "    print(f\"Total volume: {total_volume:,.2f}\")\n",
    "    \n",
    "    # Create cumulative volume percentages\n",
    "    cumulative_volumes = trader_volumes.cumsum()\n",
    "    cumulative_percentages = cumulative_volumes / total_volume * 100\n",
    "    \n",
    "    # Create DataFrame for analysis\n",
    "    trader_analysis = pd.DataFrame({\n",
    "        'trader_id': trader_volumes.index,\n",
    "        'volume': trader_volumes.values,\n",
    "        'cumulative_volume': cumulative_volumes.values,\n",
    "        'volume_pct': trader_volumes.values / total_volume * 100,\n",
    "        'cumulative_pct': cumulative_percentages.values\n",
    "    })\n",
    "    \n",
    "    # Calculate Gini coefficient\n",
    "    gini = calculate_gini(trader_volumes.values)\n",
    "    print(f\"Volume concentration (Gini coefficient): {gini:.4f}\")\n",
    "    \n",
    "    # Define percentile thresholds to evaluate\n",
    "    percentile_thresholds = [0.001, 0.01, 0.05, 0.1]\n",
    "    \n",
    "    # Calculate metrics for each threshold\n",
    "    threshold_metrics = []\n",
    "    for threshold in percentile_thresholds:\n",
    "        num_whales = max(1, int(total_traders * threshold))\n",
    "        whale_volume = trader_volumes.iloc[:num_whales].sum()\n",
    "        whale_volume_pct = whale_volume / total_volume * 100\n",
    "        \n",
    "        # Store metrics\n",
    "        threshold_metrics.append({\n",
    "            'threshold': threshold,\n",
    "            'threshold_label': f\"Top {threshold*100:.1f}%\",\n",
    "            'num_whales': num_whales,\n",
    "            'whale_volume': whale_volume,\n",
    "            'whale_volume_pct': whale_volume_pct,\n",
    "            'trader_pct': num_whales / total_traders * 100\n",
    "        })\n",
    "        \n",
    "        print(f\"Top {threshold*100:.1f}% definition ({num_whales:,} traders): {whale_volume_pct:.2f}% of volume\")\n",
    "    \n",
    "    # Calculate volume coverage thresholds\n",
    "    volume_thresholds = [50, 75, 90, 95]\n",
    "    coverage_metrics = []\n",
    "    \n",
    "    for pct in volume_thresholds:\n",
    "        # Find traders needed to reach this volume percentage\n",
    "        traders_needed = sum(cumulative_percentages < pct) + 1\n",
    "        traders_needed = min(traders_needed, len(trader_volumes))\n",
    "        \n",
    "        # Get the actual volume percentage\n",
    "        actual_pct = cumulative_percentages.iloc[traders_needed-1] if traders_needed <= len(cumulative_percentages) else 100\n",
    "        \n",
    "        coverage_metrics.append({\n",
    "            'volume_threshold': pct,\n",
    "            'threshold_label': f\"{pct}% Volume\",\n",
    "            'num_traders': traders_needed,\n",
    "            'actual_volume_pct': actual_pct,\n",
    "            'trader_pct': traders_needed / total_traders * 100\n",
    "        })\n",
    "        \n",
    "        print(f\"Traders needed for {pct}% volume: {traders_needed:,} ({traders_needed/total_traders*100:.4f}% of all traders)\")\n",
    "    \n",
    "    # Create combined metrics DataFrame\n",
    "    all_metrics = pd.DataFrame(threshold_metrics + coverage_metrics)\n",
    "    \n",
    "    # Generate visualizations\n",
    "    if generate_plots:\n",
    "        # Create figure for combined plots\n",
    "        fig, (ax1, ax2) = plt.subplots(1, 2, figsize=(16, 8))\n",
    "        \n",
    "        # 1. Lorenz curve\n",
    "        ax1.plot(np.linspace(0, 100, len(trader_volumes)), \n",
    "                 np.insert(cumulative_percentages.values, 0, 0), \n",
    "                 'b-', linewidth=2, label='Volume distribution')\n",
    "        ax1.plot([0, 100], [0, 100], 'k--', label='Perfect equality')\n",
    "        ax1.fill_between(np.linspace(0, 100, len(trader_volumes)), \n",
    "                          np.insert(cumulative_percentages.values, 0, 0), \n",
    "                          np.linspace(0, 100, len(trader_volumes)+1), \n",
    "                          alpha=0.2)\n",
    "        \n",
    "        # Add key percentiles\n",
    "        for p in [90, 95, 99, 99.9]:\n",
    "            # Calculate index for this percentile\n",
    "            idx = min(int(total_traders * (100-p)/100), len(trader_volumes)-1)\n",
    "            if idx >= 0:\n",
    "                # Get x and y coordinates\n",
    "                x = idx / total_traders * 100\n",
    "                y = cumulative_percentages.iloc[idx] if idx < len(cumulative_percentages) else 100\n",
    "                \n",
    "                # Add reference lines\n",
    "                ax1.plot([x, x], [0, y], 'r--', alpha=0.5)\n",
    "                ax1.plot([0, x], [y, y], 'r--', alpha=0.5)\n",
    "                \n",
    "                # Add label\n",
    "                ax1.text(x + 1, 10 + (p-90)*3, f'Top {100-p}%', fontsize=10)\n",
    "        \n",
    "        ax1.set_title(f'Trading Volume Distribution (Gini: {gini:.4f})')\n",
    "        ax1.set_xlabel('Cumulative % of Traders')\n",
    "        ax1.set_ylabel('Cumulative % of Volume')\n",
    "        ax1.grid(alpha=0.3)\n",
    "        ax1.legend()\n",
    "        \n",
    "        # 2. Whale definition comparison\n",
    "        percent_definitions = pd.DataFrame(threshold_metrics)\n",
    "        \n",
    "        # Plot bars for percentage of traders vs percentage of volume\n",
    "        bar_width = 0.35\n",
    "        x = np.arange(len(percent_definitions))\n",
    "        \n",
    "        ax2.bar(x - bar_width/2, percent_definitions['trader_pct'], \n",
    "               bar_width, label='% of Traders', color='skyblue')\n",
    "        ax2.bar(x + bar_width/2, percent_definitions['whale_volume_pct'], \n",
    "               bar_width, label='% of Volume', color='orange')\n",
    "        \n",
    "        # Set x-axis labels\n",
    "        ax2.set_xticks(x)\n",
    "        ax2.set_xticklabels(percent_definitions['threshold_label'])\n",
    "        \n",
    "        # Add value labels on bars\n",
    "        for i, v in enumerate(percent_definitions['trader_pct']):\n",
    "            ax2.text(i - bar_width/2, v + 1, f\"{v:.2f}%\", ha='center', fontsize=9)\n",
    "        \n",
    "        for i, v in enumerate(percent_definitions['whale_volume_pct']):\n",
    "            ax2.text(i + bar_width/2, v + 1, f\"{v:.2f}%\", ha='center', fontsize=9)\n",
    "        \n",
    "        ax2.set_title('Whale Definitions Comparison')\n",
    "        ax2.set_ylabel('Percentage')\n",
    "        ax2.set_ylim(0, 100)\n",
    "        ax2.grid(axis='y', alpha=0.3)\n",
    "        ax2.legend()\n",
    "        \n",
    "        plt.tight_layout()\n",
    "        plt.savefig('whale_definition_analysis.png', dpi=300)\n",
    "        plt.close()\n",
    "        \n",
    "        print(\"Whale definition analysis visualizations saved to whale_definition_analysis.png\")\n",
    "    \n",
    "    # Use the default threshold (1% by default)\n",
    "    num_whales = max(1, int(total_traders * default_threshold))\n",
    "    whale_ids = trader_volumes.head(num_whales).index.tolist()\n",
    "    \n",
    "    print(f\"\\nUsing top {default_threshold*100:.1f}% definition: {num_whales:,} whales\")\n",
    "    print(f\"Selected whale threshold volume: {trader_volumes.iloc[num_whales-1] if num_whales <= len(trader_volumes) else 0:.2f}\")\n",
    "    \n",
    "    # Return whale IDs and all results for further analysis\n",
    "    return whale_ids, {\n",
    "        'trader_analysis': trader_analysis,\n",
    "        'threshold_metrics': threshold_metrics,\n",
    "        'coverage_metrics': coverage_metrics,\n",
    "        'gini': gini,\n",
    "        'selected_threshold': default_threshold,\n",
    "        'selected_num_whales': num_whales\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "777a0bfa",
   "metadata": {},
   "source": [
    "# Gini coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "id": "5aab4779",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def calculate_gini(values):\n",
    "    \"\"\"\n",
    "    Calculate Gini coefficient for an array of values\n",
    "    \"\"\"\n",
    "    # Handle edge cases\n",
    "    if len(values) <= 1 or np.sum(values) == 0:\n",
    "        return 0\n",
    "    \n",
    "    # Sort values\n",
    "    sorted_values = np.sort(values)\n",
    "    n = len(sorted_values)\n",
    "    \n",
    "    # Calculate cumulative sum\n",
    "    cumsum = np.cumsum(sorted_values)\n",
    "    \n",
    "    # Calculate Gini coefficient using the formula\n",
    "    return (n + 1 - 2 * np.sum((n + 1 - np.arange(1, n+1)) * sorted_values) / np.sum(sorted_values)) / n\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c8cb6250",
   "metadata": {},
   "source": [
    "# Price Impact"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "ea3a563a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_whale_impact(trades_df, whale_ids):\n",
    "    \"\"\"\n",
    "    Analyze the impact of whale trades on market prices\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade-level data\n",
    "    whale_ids : list\n",
    "        List of whale trader IDs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with whale impact analysis results\n",
    "    \"\"\"\n",
    "    print(\"Analyzing whale trade impact...\")\n",
    "    \n",
    "    # Verify whale_ids is not None and not empty\n",
    "    if whale_ids is None or len(whale_ids) == 0:\n",
    "        print(\"Error: No whale trader IDs provided\")\n",
    "        return None\n",
    "    \n",
    "    # Make a copy of the data\n",
    "    df = trades_df.copy()\n",
    "    \n",
    "    # Check for required columns\n",
    "    required_cols = ['trader_id', 'price']\n",
    "    missing_cols = [col for col in required_cols if col not in df.columns]\n",
    "    if missing_cols:\n",
    "        print(f\"Error: Missing required columns: {missing_cols}\")\n",
    "        return None\n",
    "    \n",
    "    # Clean price data\n",
    "    df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "    df = df.dropna(subset=['price'])\n",
    "    \n",
    "    # Convert timestamp to datetime if needed\n",
    "    if 'timestamp' in df.columns:\n",
    "        if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):\n",
    "            try:\n",
    "                df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "                df = df.dropna(subset=['timestamp'])\n",
    "                print(f\"Converted {len(df)} valid timestamps\")\n",
    "            except Exception as e:\n",
    "                print(f\"Warning: Could not convert timestamps to datetime: {e}\")\n",
    "                # Create sequential index as timestamp substitute\n",
    "                df = df.sort_index().reset_index(drop=True)\n",
    "                df['timestamp'] = df.index\n",
    "    else:\n",
    "        print(\"No timestamp column found. Creating sequential index.\")\n",
    "        df = df.reset_index(drop=True)\n",
    "        df['timestamp'] = df.index\n",
    "    \n",
    "    # Sort by timestamp\n",
    "    df = df.sort_values('timestamp')\n",
    "    \n",
    "    # Add whale indicator\n",
    "    df['is_whale'] = df['trader_id'].isin(whale_ids)\n",
    "    \n",
    "    # Separate whale and non-whale trades\n",
    "    whale_trades = df[df['is_whale']]\n",
    "    non_whale_trades = df[~df['is_whale']]\n",
    "    \n",
    "    print(f\"Found {len(whale_trades)} whale trades and {len(non_whale_trades)} non-whale trades\")\n",
    "    \n",
    "    # Calculate price changes\n",
    "    df['price_change'] = df['price'].diff()\n",
    "    \n",
    "    # Calculate impact by market if market_id is available\n",
    "    if 'market_id' in df.columns:\n",
    "        print(\"Analyzing price impact by market...\")\n",
    "        market_impacts = []\n",
    "        \n",
    "        for market_id, market_df in df.groupby('market_id'):\n",
    "            # Skip markets with too few trades\n",
    "            if len(market_df) < 10:\n",
    "                continue\n",
    "                \n",
    "            # Sort by timestamp\n",
    "            market_df = market_df.sort_values('timestamp')\n",
    "            \n",
    "            # Calculate price changes\n",
    "            market_df['price_change'] = market_df['price'].diff()\n",
    "            \n",
    "            # Separate whale and non-whale trades\n",
    "            market_whale_trades = market_df[market_df['is_whale']]\n",
    "            market_non_whale_trades = market_df[~market_df['is_whale']]\n",
    "            \n",
    "            # Skip markets with no whale trades\n",
    "            if len(market_whale_trades) == 0:\n",
    "                continue\n",
    "                \n",
    "            # Calculate average metrics\n",
    "            whale_avg_change = market_whale_trades['price_change'].mean()\n",
    "            non_whale_avg_change = market_non_whale_trades['price_change'].mean()\n",
    "            \n",
    "            # Calculate directional impact\n",
    "            whale_pos_pct = (market_whale_trades['price_change'] > 0).mean() * 100\n",
    "            whale_neg_pct = (market_whale_trades['price_change'] < 0).mean() * 100\n",
    "            non_whale_pos_pct = (market_non_whale_trades['price_change'] > 0).mean() * 100\n",
    "            non_whale_neg_pct = (market_non_whale_trades['price_change'] < 0).mean() * 100\n",
    "            \n",
    "            market_impacts.append({\n",
    "                'market_id': market_id,\n",
    "                'total_trades': len(market_df),\n",
    "                'whale_trades': len(market_whale_trades),\n",
    "                'non_whale_trades': len(market_non_whale_trades),\n",
    "                'whale_avg_change': whale_avg_change,\n",
    "                'non_whale_avg_change': non_whale_avg_change,\n",
    "                'whale_pos_pct': whale_pos_pct,\n",
    "                'whale_neg_pct': whale_neg_pct,\n",
    "                'non_whale_pos_pct': non_whale_pos_pct,\n",
    "                'non_whale_neg_pct': non_whale_neg_pct\n",
    "            })\n",
    "        \n",
    "        # Create markets DataFrame\n",
    "        if market_impacts:\n",
    "            markets_df = pd.DataFrame(market_impacts)\n",
    "            \n",
    "            # Calculate weighted averages\n",
    "            weighted_whale_impact = np.average(\n",
    "                markets_df['whale_avg_change'].fillna(0),\n",
    "                weights=markets_df['whale_trades']\n",
    "            )\n",
    "            \n",
    "            weighted_non_whale_impact = np.average(\n",
    "                markets_df['non_whale_avg_change'].fillna(0),\n",
    "                weights=markets_df['non_whale_trades']\n",
    "            )\n",
    "            \n",
    "            print(f\"\\nWeighted average whale price impact: {weighted_whale_impact:.6f}\")\n",
    "            print(f\"Weighted average non-whale price impact: {weighted_non_whale_impact:.6f}\")\n",
    "            \n",
    "            # Calculate impact ratio if possible\n",
    "            if weighted_non_whale_impact != 0:\n",
    "                impact_ratio = weighted_whale_impact / weighted_non_whale_impact\n",
    "                print(f\"Impact ratio (whale/non-whale): {impact_ratio:.4f}\")\n",
    "            else:\n",
    "                impact_ratio = None\n",
    "                print(\"Impact ratio cannot be calculated (division by zero)\")\n",
    "            \n",
    "            # Create visualization\n",
    "            plt.figure(figsize=(15, 12))\n",
    "            \n",
    "            # 1. Market-by-market comparison\n",
    "            plt.subplot(2, 1, 1)\n",
    "            \n",
    "            # Sort markets by whale impact\n",
    "            sorted_markets = markets_df.sort_values('whale_avg_change')\n",
    "            \n",
    "            # Plot whale vs non-whale impact by market\n",
    "            plt.scatter(range(len(sorted_markets)), sorted_markets['whale_avg_change'], \n",
    "                       label='Whale impact', alpha=0.7, s=50, color='blue')\n",
    "            plt.scatter(range(len(sorted_markets)), sorted_markets['non_whale_avg_change'], \n",
    "                       label='Non-whale impact', alpha=0.7, s=50, color='orange')\n",
    "            \n",
    "            plt.axhline(y=0, color='r', linestyle='--')\n",
    "            plt.title('Price Impact by Market')\n",
    "            plt.xlabel('Markets (sorted by whale impact)')\n",
    "            plt.ylabel('Average Price Change')\n",
    "            plt.legend()\n",
    "            plt.grid(alpha=0.3)\n",
    "            \n",
    "            # 2. Direction comparison\n",
    "            plt.subplot(2, 1, 2)\n",
    "            \n",
    "            # Calculate average positive/negative percentages\n",
    "            avg_whale_pos = markets_df['whale_pos_pct'].mean()\n",
    "            avg_whale_neg = markets_df['whale_neg_pct'].mean()\n",
    "            avg_nonwhale_pos = markets_df['non_whale_pos_pct'].mean()\n",
    "            avg_nonwhale_neg = markets_df['non_whale_neg_pct'].mean()\n",
    "            \n",
    "            # Plot directional impact\n",
    "            labels = ['Whale', 'Non-whale']\n",
    "            pos_values = [avg_whale_pos, avg_nonwhale_pos]\n",
    "            neg_values = [avg_whale_neg, avg_nonwhale_neg]\n",
    "            neutral_values = [100 - avg_whale_pos - avg_whale_neg, \n",
    "                             100 - avg_nonwhale_pos - avg_nonwhale_neg]\n",
    "            \n",
    "            width = 0.35\n",
    "            x = np.arange(len(labels))\n",
    "            \n",
    "            plt.bar(x, pos_values, width, label='Positive impact', color='green')\n",
    "            plt.bar(x, neg_values, width, bottom=pos_values, label='Negative impact', color='red')\n",
    "            plt.bar(x, neutral_values, width, \n",
    "                   bottom=[pos_values[i] + neg_values[i] for i in range(len(pos_values))], \n",
    "                   label='Neutral', color='gray')\n",
    "            \n",
    "            plt.title('Direction of Price Impact')\n",
    "            plt.ylabel('Percentage of Trades')\n",
    "            plt.xlabel('Trader Type')\n",
    "            plt.xticks(x, labels)\n",
    "            plt.legend()\n",
    "            \n",
    "            plt.tight_layout()\n",
    "            plt.savefig('whale_impact_analysis.png', dpi=300)\n",
    "            plt.close()\n",
    "            \n",
    "            print(\"Whale impact analysis visualization saved to whale_impact_analysis.png\")\n",
    "            \n",
    "            return {\n",
    "                'market_impacts': markets_df.to_dict('records'),\n",
    "                'weighted_whale_impact': weighted_whale_impact,\n",
    "                'weighted_non_whale_impact': weighted_non_whale_impact,\n",
    "                'impact_ratio': impact_ratio,\n",
    "                'direction_metrics': {\n",
    "                    'whale_positive_pct': avg_whale_pos,\n",
    "                    'whale_negative_pct': avg_whale_neg,\n",
    "                    'non_whale_positive_pct': avg_nonwhale_pos,\n",
    "                    'non_whale_negative_pct': avg_nonwhale_neg\n",
    "                }\n",
    "            }\n",
    "    \n",
    "    # If market_id not available, perform overall analysis\n",
    "    print(\"Analyzing overall price changes...\")\n",
    "    \n",
    "    # Calculate metrics\n",
    "    whale_avg_change = whale_trades['price_change'].mean()\n",
    "    whale_median_change = whale_trades['price_change'].median()\n",
    "    whale_std_change = whale_trades['price_change'].std()\n",
    "    \n",
    "    non_whale_avg_change = non_whale_trades['price_change'].mean()\n",
    "    non_whale_median_change = non_whale_trades['price_change'].median()\n",
    "    non_whale_std_change = non_whale_trades['price_change'].std()\n",
    "    \n",
    "    print(f\"\\nWhale trades average price change: {whale_avg_change:.6f}\")\n",
    "    print(f\"Non-whale trades average price change: {non_whale_avg_change:.6f}\")\n",
    "    \n",
    "    # Calculate direction metrics\n",
    "    whale_pos_pct = (whale_trades['price_change'] > 0).mean() * 100\n",
    "    whale_neg_pct = (whale_trades['price_change'] < 0).mean() * 100\n",
    "    non_whale_pos_pct = (non_whale_trades['price_change'] > 0).mean() * 100\n",
    "    non_whale_neg_pct = (non_whale_trades['price_change'] < 0).mean() * 100\n",
    "    \n",
    "    print(f\"Whale trades causing price increases: {whale_pos_pct:.2f}%\")\n",
    "    print(f\"Whale trades causing price decreases: {whale_neg_pct:.2f}%\")\n",
    "    \n",
    "    # Calculate following behavior\n",
    "    df['next_is_whale'] = df['is_whale'].shift(-1)\n",
    "    df['prev_is_whale'] = df['is_whale'].shift(1)\n",
    "    \n",
    "    # Calculate price direction\n",
    "    df['price_direction'] = np.sign(df['price_change'])\n",
    "    df['next_price_direction'] = df['price_direction'].shift(-1)\n",
    "    df['prev_price_direction'] = df['price_direction'].shift(1)\n",
    "    \n",
    "    # Calculate how often non-whales follow whale direction\n",
    "    whale_followed = df[(df['prev_is_whale']) & (~df['is_whale']) & \n",
    "                      (df['price_direction'] == df['prev_price_direction'])]\n",
    "    whale_trades_with_followers = df[df['prev_is_whale'] & ~df['is_whale']]\n",
    "    \n",
    "    if len(whale_trades_with_followers) > 0:\n",
    "        following_ratio = len(whale_followed) / len(whale_trades_with_followers)\n",
    "        print(f\"Non-whale traders follow whale price direction: {following_ratio:.2%} of the time\")\n",
    "    else:\n",
    "        following_ratio = None\n",
    "        print(\"Could not calculate following ratio\")\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. Price change distribution\n",
    "    plt.subplot(2, 1, 1)\n",
    "    \n",
    "    # Calculate bins for histogram\n",
    "    bin_width = max(whale_std_change, non_whale_std_change) / 5\n",
    "    bins = np.arange(\n",
    "        min(whale_trades['price_change'].min(), non_whale_trades['price_change'].min()) - bin_width,\n",
    "        max(whale_trades['price_change'].max(), non_whale_trades['price_change'].max()) + bin_width,\n",
    "        bin_width\n",
    "    )\n",
    "    \n",
    "    # Plot histograms\n",
    "    plt.hist(whale_trades['price_change'].dropna(), bins=bins, alpha=0.5, \n",
    "             label=f'Whale trades (mean={whale_avg_change:.6f})', color='blue')\n",
    "    plt.hist(non_whale_trades['price_change'].dropna(), bins=bins, alpha=0.5, \n",
    "             label=f'Non-whale trades (mean={non_whale_avg_change:.6f})', color='orange')\n",
    "    \n",
    "    plt.axvline(x=0, color='r', linestyle='--')\n",
    "    plt.axvline(x=whale_avg_change, color='blue', linestyle='-')\n",
    "    plt.axvline(x=non_whale_avg_change, color='orange', linestyle='-')\n",
    "    \n",
    "    plt.title('Distribution of Price Changes')\n",
    "    plt.xlabel('Price Change')\n",
    "    plt.ylabel('Frequency')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # 2. Direction comparison\n",
    "    plt.subplot(2, 1, 2)\n",
    "    \n",
    "    # Plot directional impact\n",
    "    labels = ['Whale', 'Non-whale']\n",
    "    pos_values = [whale_pos_pct, non_whale_pos_pct]\n",
    "    neg_values = [whale_neg_pct, non_whale_neg_pct]\n",
    "    neutral_values = [100 - whale_pos_pct - whale_neg_pct, \n",
    "                     100 - non_whale_pos_pct - non_whale_neg_pct]\n",
    "    \n",
    "    width = 0.35\n",
    "    x = np.arange(len(labels))\n",
    "    \n",
    "    plt.bar(x, pos_values, width, label='Positive impact', color='green')\n",
    "    plt.bar(x, neg_values, width, bottom=pos_values, label='Negative impact', color='red')\n",
    "    plt.bar(x, neutral_values, width, \n",
    "           bottom=[pos_values[i] + neg_values[i] for i in range(len(pos_values))], \n",
    "           label='Neutral', color='gray')\n",
    "    \n",
    "    # Add value labels\n",
    "    for i, v in enumerate(pos_values):\n",
    "        plt.text(i, v/2, f\"{v:.1f}%\", ha='center', color='white', fontweight='bold')\n",
    "    \n",
    "    for i, v in enumerate(neg_values):\n",
    "        plt.text(i, pos_values[i] + v/2, f\"{v:.1f}%\", ha='center', color='white', fontweight='bold')\n",
    "    \n",
    "    plt.title('Direction of Price Impact')\n",
    "    plt.ylabel('Percentage of Trades')\n",
    "    plt.xlabel('Trader Type')\n",
    "    plt.xticks(x, labels)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('whale_impact_analysis.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Whale impact analysis visualization saved to whale_impact_analysis.png\")\n",
    "    \n",
    "    return {\n",
    "        'whale_impact': {\n",
    "            'avg_change': whale_avg_change,\n",
    "            'median_change': whale_median_change,\n",
    "            'std_change': whale_std_change,\n",
    "            'positive_pct': whale_pos_pct,\n",
    "            'negative_pct': whale_neg_pct\n",
    "        },\n",
    "        'non_whale_impact': {\n",
    "            'avg_change': non_whale_avg_change,\n",
    "            'median_change': non_whale_median_change,\n",
    "            'std_change': non_whale_std_change,\n",
    "            'positive_pct': non_whale_pos_pct,\n",
    "            'negative_pct': non_whale_neg_pct\n",
    "        },\n",
    "        'following_ratio': following_ratio\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10823468",
   "metadata": {},
   "source": [
    "# Usage section:"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "410443a0",
   "metadata": {},
   "source": [
    "# Trading Inequality"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "bc133471",
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_trading_inequality(trader_analysis_df, save_path='trading_inequality_analysis.png'):\n",
    "    \"\"\"\n",
    "    Create detailed visualizations of trading inequality\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trader_analysis_df : pd.DataFrame\n",
    "        DataFrame with trader volume analysis\n",
    "    save_path : str\n",
    "        Path to save the visualization\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with inequality metrics\n",
    "    \"\"\"\n",
    "    print(\"Generating trading inequality visualizations...\")\n",
    "    \n",
    "    # Calculate key metrics\n",
    "    total_traders = len(trader_analysis_df)\n",
    "    total_volume = trader_analysis_df['volume'].sum()\n",
    "    \n",
    "    # Sort by volume for analysis\n",
    "    sorted_df = trader_analysis_df.sort_values('volume', ascending=True)\n",
    "    \n",
    "    # Calculate percentiles\n",
    "    percentiles = [50, 90, 95, 99, 99.9]\n",
    "    percentile_data = {}\n",
    "    \n",
    "    for p in percentiles:\n",
    "        threshold = np.percentile(sorted_df['volume'], p)\n",
    "        traders_above = sum(sorted_df['volume'] > threshold)\n",
    "        volume_share = sorted_df[sorted_df['volume'] > threshold]['volume'].sum() / total_volume * 100\n",
    "        \n",
    "        percentile_data[p] = {\n",
    "            'threshold': threshold,\n",
    "            'traders_above': traders_above,\n",
    "            'traders_pct': traders_above / total_traders * 100,\n",
    "            'volume_share': volume_share\n",
    "        }\n",
    "        \n",
    "        print(f\"Top {100-p:.1f}% of traders (volume > {threshold:.2f}) control {volume_share:.2f}% of volume\")\n",
    "    \n",
    "    # Create 2x2 visualization\n",
    "    fig, axs = plt.subplots(2, 2, figsize=(16, 14))\n",
    "    \n",
    "    # 1. Lorenz curve (top left)\n",
    "    ax1 = axs[0, 0]\n",
    "    \n",
    "    # Calculate points for the Lorenz curve\n",
    "    x_lorenz = np.linspace(0, 100, len(sorted_df)+1)\n",
    "    y_lorenz = np.insert(np.cumsum(sorted_df['volume']) / total_volume * 100, 0, 0)\n",
    "    \n",
    "    # Plot Lorenz curve\n",
    "    ax1.plot(x_lorenz, y_lorenz, 'b-', linewidth=2, label='Volume distribution')\n",
    "    ax1.plot([0, 100], [0, 100], 'k--', label='Perfect equality')\n",
    "    ax1.fill_between(x_lorenz, y_lorenz, x_lorenz, alpha=0.2, color='blue')\n",
    "    \n",
    "    # Calculate Gini coefficient\n",
    "    gini = 1 - 2 * np.trapz(y_lorenz, x_lorenz) / 10000  # Area under perfect equality is 100*100/2\n",
    "    \n",
    "    # Add key percentiles\n",
    "    for p in [90, 95, 99, 99.9]:\n",
    "        # Get index for this percentile\n",
    "        idx = int(total_traders * (100-p) / 100)\n",
    "        if idx < len(sorted_df):\n",
    "            # Get trader percentage and volume percentage\n",
    "            x = 100 - p\n",
    "            y = 100 - percentile_data[p]['volume_share']\n",
    "            \n",
    "            # Add reference lines\n",
    "            ax1.plot([100-p, 100-p], [0, 100-y], 'r--', alpha=0.5)\n",
    "            ax1.plot([0, 100-p], [100-y, 100-y], 'r--', alpha=0.5)\n",
    "            \n",
    "            # Add label\n",
    "            ax1.text(100-p + 0.5, 5, f'Top {p:.1f}%', fontsize=9)\n",
    "    \n",
    "    ax1.set_title(f'Trading Volume Lorenz Curve (Gini: {gini:.4f})')\n",
    "    ax1.set_xlabel('Cumulative % of Traders')\n",
    "    ax1.set_ylabel('Cumulative % of Volume')\n",
    "    ax1.grid(alpha=0.3)\n",
    "    ax1.legend()\n",
    "    \n",
    "    # 2. Volume distribution histogram (top right)\n",
    "    ax2 = axs[0, 1]\n",
    "    \n",
    "    # Use log scale for better visualization\n",
    "    log_volumes = np.log10(sorted_df['volume'] + 1)  # +1 to handle zeros\n",
    "    \n",
    "    ax2.hist(log_volumes, bins=50, alpha=0.7, color='skyblue')\n",
    "    ax2.set_title('Trading Volume Distribution (Log Scale)')\n",
    "    ax2.set_xlabel('Log10(Volume)')\n",
    "    ax2.set_ylabel('Number of Traders')\n",
    "    \n",
    "    # Add percentile markers\n",
    "    for p in [50, 90, 95, 99]:\n",
    "        threshold = np.log10(np.percentile(sorted_df['volume'], p) + 1)\n",
    "        ax2.axvline(threshold, color='red', linestyle='--', alpha=0.5)\n",
    "        ax2.text(threshold + 0.1, ax2.get_ylim()[1]*0.9, f'{p}th', fontsize=9, rotation=90)\n",
    "    \n",
    "    ax2.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Top trader concentration (bottom left)\n",
    "    ax3 = axs[1, 0]\n",
    "    \n",
    "    # Prepare data for concentration chart\n",
    "    top_n_categories = ['Top 0.1%', 'Top 0.1-1%', 'Top 1-5%', 'Top 5-10%', 'Bottom 90%']\n",
    "    \n",
    "    # Calculate trader counts for each category\n",
    "    n_01pct = max(1, int(total_traders * 0.001))\n",
    "    n_1pct = max(1, int(total_traders * 0.01))\n",
    "    n_5pct = max(1, int(total_traders * 0.05))\n",
    "    n_10pct = max(1, int(total_traders * 0.1))\n",
    "    \n",
    "    # Calculate volume for each category\n",
    "    vol_01pct = sorted_df.iloc[-n_01pct:]['volume'].sum()\n",
    "    vol_01_1pct = sorted_df.iloc[-n_1pct:-n_01pct]['volume'].sum() if n_1pct > n_01pct else 0\n",
    "    vol_1_5pct = sorted_df.iloc[-n_5pct:-n_1pct]['volume'].sum() if n_5pct > n_1pct else 0\n",
    "    vol_5_10pct = sorted_df.iloc[-n_10pct:-n_5pct]['volume'].sum() if n_10pct > n_5pct else 0\n",
    "    vol_bottom90pct = sorted_df.iloc[:-n_10pct]['volume'].sum() if len(sorted_df) > n_10pct else 0\n",
    "    \n",
    "    # Calculate percentages\n",
    "    pct_01pct = vol_01pct / total_volume * 100\n",
    "    pct_01_1pct = vol_01_1pct / total_volume * 100\n",
    "    pct_1_5pct = vol_1_5pct / total_volume * 100\n",
    "    pct_5_10pct = vol_5_10pct / total_volume * 100\n",
    "    pct_bottom90pct = vol_bottom90pct / total_volume * 100\n",
    "    \n",
    "    volume_shares = [pct_01pct, pct_01_1pct, pct_1_5pct, pct_5_10pct, pct_bottom90pct]\n",
    "    \n",
    "    # Create bar chart\n",
    "    bars = ax3.bar(top_n_categories, volume_shares, color=['darkred', 'red', 'orange', 'gold', 'green'])\n",
    "    \n",
    "    # Add value labels\n",
    "    for bar in bars:\n",
    "        height = bar.get_height()\n",
    "        ax3.text(bar.get_x() + bar.get_width()/2., height + 0.5,\n",
    "                f'{height:.1f}%', ha='center', fontsize=10)\n",
    "    \n",
    "    ax3.set_title('Volume Distribution by Trader Category')\n",
    "    ax3.set_ylabel('% of Total Volume')\n",
    "    ax3.set_ylim(0, max(volume_shares) * 1.1)\n",
    "    ax3.grid(axis='y', alpha=0.3)\n",
    "    \n",
    "    # 4. Power law plot (bottom right)\n",
    "    ax4 = axs[1, 1]\n",
    "    \n",
    "    # Rank traders by volume (largest first)\n",
    "    ranked_volumes = sorted(sorted_df['volume'], reverse=True)\n",
    "    ranks = np.arange(1, len(ranked_volumes) + 1)\n",
    "    \n",
    "    # Plot volumes vs rank (log-log scale)\n",
    "    ax4.loglog(ranks, ranked_volumes, 'o', markersize=2, alpha=0.5)\n",
    "    \n",
    "    # Try to fit a power law\n",
    "    try:\n",
    "        from scipy import stats\n",
    "        # Use only volumes > 0 for log fitting\n",
    "        positive_volumes = np.array(ranked_volumes)\n",
    "        positive_volumes = positive_volumes[positive_volumes > 0]\n",
    "        positive_ranks = np.arange(1, len(positive_volumes) + 1)\n",
    "        \n",
    "        # Linear fit on log-log scale\n",
    "        slope, intercept, r_value, p_value, std_err = stats.linregress(\n",
    "            np.log10(positive_ranks), np.log10(positive_volumes)\n",
    "        )\n",
    "        \n",
    "        # Plot the fitted line\n",
    "        x_fit = np.logspace(0, np.log10(len(positive_ranks)), 100)\n",
    "        y_fit = 10**(intercept) * x_fit**slope\n",
    "        ax4.plot(x_fit, y_fit, 'r-', linewidth=2, \n",
    "                label=f'Power law fit: α={-slope:.2f}, R²={r_value**2:.2f}')\n",
    "        \n",
    "        print(f\"Power law exponent: α={-slope:.2f}, R²={r_value**2:.2f}\")\n",
    "    except:\n",
    "        print(\"Could not fit power law (scipy.stats not available)\")\n",
    "    \n",
    "    ax4.set_title('Trader Volume Rank Distribution')\n",
    "    ax4.set_xlabel('Trader Rank')\n",
    "    ax4.set_ylabel('Volume')\n",
    "    ax4.grid(True, which=\"both\", ls=\"-\", alpha=0.3)\n",
    "    ax4.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig(save_path, dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Trading inequality visualizations saved to {save_path}\")\n",
    "    \n",
    "    # Return inequality metrics\n",
    "    return {\n",
    "        'gini': gini,\n",
    "        'percentile_data': percentile_data,\n",
    "        'top_trader_shares': {\n",
    "            'top_0.1pct': pct_01pct,\n",
    "            'top_0.1_1pct': pct_01_1pct,\n",
    "            'top_1_5pct': pct_1_5pct,\n",
    "            'top_5_10pct': pct_5_10pct,\n",
    "            'bottom_90pct': pct_bottom90pct\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2aba16b2",
   "metadata": {},
   "source": [
    "# Behavior Over Time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "98feb13c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_trader_behavior_over_time(trades_df, whale_ids, time_unit='D'):\n",
    "    \"\"\"\n",
    "    Analyze how trading patterns evolve over time for whales vs non-whales\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    whale_ids : list\n",
    "        List of whale trader IDs\n",
    "    time_unit : str\n",
    "        Time unit for aggregation ('D' for day, 'W' for week, etc.)\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with temporal analysis results\n",
    "    \"\"\"\n",
    "    print(f\"Analyzing trader behavior over time (unit: {time_unit})...\")\n",
    "    \n",
    "    # Clean the data\n",
    "    df = trades_df.copy()\n",
    "    \n",
    "    # Ensure we have timestamps\n",
    "    if 'timestamp' not in df.columns:\n",
    "        print(\"Error: No timestamp column available\")\n",
    "        return None\n",
    "        \n",
    "    # Convert timestamp to datetime if needed\n",
    "    if not pd.api.types.is_datetime64_any_dtype(df['timestamp']):\n",
    "        try:\n",
    "            df['timestamp'] = pd.to_datetime(df['timestamp'], errors='coerce')\n",
    "            df = df.dropna(subset=['timestamp'])\n",
    "            print(f\"Converted {len(df)} timestamps to datetime format\")\n",
    "        except Exception as e:\n",
    "            print(f\"Error converting timestamps: {e}\")\n",
    "            return None\n",
    "    \n",
    "    # Add whale indicator\n",
    "    df['is_whale'] = df['trader_id'].isin(whale_ids)\n",
    "    \n",
    "    # Ensure price is numeric\n",
    "    if 'price' in df.columns:\n",
    "        df['price'] = pd.to_numeric(df['price'], errors='coerce')\n",
    "    \n",
    "    # Group by date and trader type\n",
    "    df['date'] = df['timestamp'].dt.floor(time_unit)\n",
    "    \n",
    "    # Calculate metrics by date and trader type\n",
    "    time_metrics = []\n",
    "    \n",
    "    for (date, is_whale), group in df.groupby(['date', 'is_whale']):\n",
    "        # Skip groups with no trades\n",
    "        if len(group) == 0:\n",
    "            continue\n",
    "            \n",
    "        metrics = {\n",
    "            'date': date,\n",
    "            'is_whale': is_whale,\n",
    "            'trader_type': 'Whale' if is_whale else 'Non-whale',\n",
    "            'trade_count': len(group),\n",
    "            'unique_traders': group['trader_id'].nunique(),\n",
    "            'volume': group['trade_amount'].sum(),\n",
    "            'avg_trade_size': group['trade_amount'].mean()\n",
    "        }\n",
    "        \n",
    "        # Add price metrics if available\n",
    "        if 'price' in group.columns:\n",
    "            metrics.update({\n",
    "                'avg_price': group['price'].mean(),\n",
    "                'price_std': group['price'].std(),\n",
    "                'price_range': group['price'].max() - group['price'].min() if len(group) > 1 else 0\n",
    "            })\n",
    "        \n",
    "        time_metrics.append(metrics)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    time_df = pd.DataFrame(time_metrics)\n",
    "    \n",
    "    # Check if we have enough data\n",
    "    if len(time_df) < 2:\n",
    "        print(\"Not enough temporal data to analyze\")\n",
    "        return None\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(15, 12))\n",
    "    \n",
    "    # 1. Activity over time (top)\n",
    "    plt.subplot(3, 1, 1)\n",
    "    \n",
    "    # Create pivot table for activity\n",
    "    pivot_activity = time_df.pivot_table(\n",
    "        index='date', columns='trader_type', values='trade_count'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Plot activity\n",
    "    pivot_activity.plot(ax=plt.gca())\n",
    "    plt.title('Trading Activity Over Time')\n",
    "    plt.ylabel('Number of Trades')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # 2. Volume over time (middle)\n",
    "    plt.subplot(3, 1, 2)\n",
    "    \n",
    "    # Create pivot table for volume\n",
    "    pivot_volume = time_df.pivot_table(\n",
    "        index='date', columns='trader_type', values='volume'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Plot volume\n",
    "    pivot_volume.plot(ax=plt.gca())\n",
    "    plt.title('Trading Volume Over Time')\n",
    "    plt.ylabel('Volume')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # 3. Trader participation over time (bottom)\n",
    "    plt.subplot(3, 1, 3)\n",
    "    \n",
    "    # Create pivot table for unique traders\n",
    "    pivot_traders = time_df.pivot_table(\n",
    "        index='date', columns='trader_type', values='unique_traders'\n",
    "    ).fillna(0)\n",
    "    \n",
    "    # Plot trader counts\n",
    "    pivot_traders.plot(ax=plt.gca())\n",
    "    plt.title('Trader Participation Over Time')\n",
    "    plt.ylabel('Number of Unique Traders')\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('trader_behavior_over_time.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Temporal analysis visualization saved to trader_behavior_over_time.png\")\n",
    "    \n",
    "    # Calculate correlation between whale and non-whale activity\n",
    "    if all(col in pivot_activity.columns for col in ['Whale', 'Non-whale']):\n",
    "        activity_correlation = pivot_activity['Whale'].corr(pivot_activity['Non-whale'])\n",
    "        print(f\"Correlation between whale and non-whale activity: {activity_correlation:.4f}\")\n",
    "        \n",
    "        # Calculate lead-lag relationship with a 1-period lag\n",
    "        whale_lead_corr = pivot_activity['Whale'].shift(1).corr(pivot_activity['Non-whale'])\n",
    "        nonwhale_lead_corr = pivot_activity['Non-whale'].shift(1).corr(pivot_activity['Whale'])\n",
    "        \n",
    "        if whale_lead_corr > nonwhale_lead_corr:\n",
    "            print(f\"Whales appear to lead non-whale activity (correlation: {whale_lead_corr:.4f})\")\n",
    "        else:\n",
    "            print(f\"Non-whales appear to lead whale activity (correlation: {nonwhale_lead_corr:.4f})\")\n",
    "    \n",
    "    # Calculate trends\n",
    "    if len(pivot_activity) >= 5:\n",
    "        # Calculate whale activity trend\n",
    "        if 'Whale' in pivot_activity.columns:\n",
    "            whale_trend = pivot_activity['Whale'].rolling(min(5, len(pivot_activity))).mean()\n",
    "            whale_trend_direction = np.sign(whale_trend.diff().mean())\n",
    "            print(f\"Whale activity trend: {'Increasing' if whale_trend_direction > 0 else 'Decreasing'}\")\n",
    "        \n",
    "        # Calculate non-whale activity trend\n",
    "        if 'Non-whale' in pivot_activity.columns:\n",
    "            nonwhale_trend = pivot_activity['Non-whale'].rolling(min(5, len(pivot_activity))).mean()\n",
    "            nonwhale_trend_direction = np.sign(nonwhale_trend.diff().mean())\n",
    "            print(f\"Non-whale activity trend: {'Increasing' if nonwhale_trend_direction > 0 else 'Decreasing'}\")\n",
    "    \n",
    "    return {\n",
    "        'time_data': time_df.to_dict('records'),\n",
    "        'activity_correlation': activity_correlation if 'activity_correlation' in locals() else None,\n",
    "        'whale_lead_correlation': whale_lead_corr if 'whale_lead_corr' in locals() else None,\n",
    "        'nonwhale_lead_correlation': nonwhale_lead_corr if 'nonwhale_lead_corr' in locals() else None,\n",
    "        'whale_trend_direction': whale_trend_direction if 'whale_trend_direction' in locals() else None,\n",
    "        'nonwhale_trend_direction': nonwhale_trend_direction if 'nonwhale_trend_direction' in locals() else None\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74498cc5",
   "metadata": {},
   "source": [
    "# Market Accuracy by Whale Activity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 133,
   "id": "a74068e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def analyze_market_accuracy_by_whale_activity(trades_df, market_data, whale_ids):\n",
    "    \"\"\"\n",
    "    Analyze how whale activity correlates with market prediction accuracy\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    market_data : pd.DataFrame\n",
    "        DataFrame with market-level data including accuracy metrics\n",
    "    whale_ids : list\n",
    "        List of whale trader IDs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with accuracy analysis results\n",
    "    \"\"\"\n",
    "    print(\"Analyzing market accuracy by whale activity...\")\n",
    "    \n",
    "    # Verify we have required columns in market_data\n",
    "    required_cols = ['market_id', 'brier_score']\n",
    "    missing_cols = [col for col in required_cols if col not in market_data.columns]\n",
    "    \n",
    "    if missing_cols:\n",
    "        print(f\"Error: Missing required columns in market_data: {missing_cols}\")\n",
    "        print(\"Required columns: market_id, brier_score (or other accuracy metric)\")\n",
    "        return None\n",
    "    \n",
    "    # Clean trades data\n",
    "    df = trades_df.copy()\n",
    "    df['is_whale'] = df['trader_id'].isin(whale_ids)\n",
    "    \n",
    "    # Calculate whale activity metrics per market\n",
    "    market_metrics = []\n",
    "    \n",
    "    for market_id, market_trades in df.groupby('market_id'):\n",
    "        whale_trades = market_trades[market_trades['is_whale']]\n",
    "        non_whale_trades = market_trades[~market_trades['is_whale']]\n",
    "        \n",
    "        # Skip markets with too few trades\n",
    "        if len(market_trades) < 10:\n",
    "            continue\n",
    "            \n",
    "        metrics = {\n",
    "            'market_id': market_id,\n",
    "            'total_trades': len(market_trades),\n",
    "            'whale_trades': len(whale_trades),\n",
    "            'non_whale_trades': len(non_whale_trades),\n",
    "            'whale_ratio': len(whale_trades) / len(market_trades) if len(market_trades) > 0 else 0,\n",
    "            'unique_whales': whale_trades['trader_id'].nunique(),\n",
    "            'unique_non_whales': non_whale_trades['trader_id'].nunique(),\n",
    "            'whale_volume': whale_trades['trade_amount'].sum() if 'trade_amount' in whale_trades else 0,\n",
    "            'non_whale_volume': non_whale_trades['trade_amount'].sum() if 'trade_amount' in non_whale_trades else 0,\n",
    "            'whale_volume_ratio': (\n",
    "                whale_trades['trade_amount'].sum() / market_trades['trade_amount'].sum() \n",
    "                if 'trade_amount' in market_trades and market_trades['trade_amount'].sum() > 0 \n",
    "                else 0\n",
    "            ),\n",
    "        }\n",
    "        \n",
    "        market_metrics.append(metrics)\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    metrics_df = pd.DataFrame(market_metrics)\n",
    "    \n",
    "    # Merge with market accuracy data\n",
    "    merged_df = metrics_df.merge(\n",
    "        market_data[['market_id', 'brier_score']], \n",
    "        on='market_id', \n",
    "        how='inner'\n",
    "    )\n",
    "    \n",
    "    if len(merged_df) == 0:\n",
    "        print(\"Error: Could not merge trade metrics with market accuracy data\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate correlations between whale activity and accuracy\n",
    "    whale_metrics = ['whale_ratio', 'unique_whales', 'whale_volume_ratio']\n",
    "    correlations = {}\n",
    "    \n",
    "    for metric in whale_metrics:\n",
    "        if metric in merged_df.columns:\n",
    "            corr = merged_df[metric].corr(merged_df['brier_score'])\n",
    "            correlations[f\"{metric}_correlation\"] = corr\n",
    "            print(f\"Correlation between {metric} and Brier score: {corr:.4f}\")\n",
    "    \n",
    "    # Group by whale activity level\n",
    "    merged_df['whale_activity_quantile'] = pd.qcut(\n",
    "        merged_df['whale_ratio'], \n",
    "        q=4, \n",
    "        labels=['Low', 'Medium-Low', 'Medium-High', 'High']\n",
    "    )\n",
    "    \n",
    "    # Calculate average accuracy by whale activity\n",
    "    accuracy_by_activity = merged_df.groupby('whale_activity_quantile')['brier_score'].mean()\n",
    "    \n",
    "    print(\"\\nAverage Brier score by whale activity level:\")\n",
    "    for activity, score in accuracy_by_activity.items():\n",
    "        print(f\"{activity} whale activity: {score:.4f}\")\n",
    "    \n",
    "    return {\n",
    "        'market_metrics': merged_df.to_dict('records'),\n",
    "        'correlations': correlations,\n",
    "        'accuracy_by_activity': accuracy_by_activity.to_dict()\n",
    "    }\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d9b760bb",
   "metadata": {},
   "source": [
    "# Whale Sentiment Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 134,
   "id": "b13b9007",
   "metadata": {},
   "outputs": [],
   "source": [
    "def analyze_whale_sentiment_alignment(trades_df, whale_ids):\n",
    "    \"\"\"\n",
    "    Analyze whether whales tend to agree with each other or take opposing positions\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    whale_ids : list\n",
    "        List of whale trader IDs\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with alignment analysis results\n",
    "    \"\"\"\n",
    "    print(\"Analyzing whale sentiment alignment...\")\n",
    "    \n",
    "    # Clean the data\n",
    "    df = trades_df.copy()\n",
    "    \n",
    "    # Filter to whale trades only\n",
    "    df = df[df['trader_id'].isin(whale_ids)]\n",
    "    \n",
    "    # Verify we have direction information\n",
    "    if 'side' in df.columns:\n",
    "        direction_col = 'side'\n",
    "    else:\n",
    "        print(\"Error: No trade direction information (side column) available\")\n",
    "        return None\n",
    "    \n",
    "    # Verify we have market_id\n",
    "    if 'market_id' not in df.columns:\n",
    "        print(\"Error: market_id column required for alignment analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Skip if there are too few whale trades\n",
    "    if len(df) < 100:\n",
    "        print(f\"Too few whale trades to analyze alignment: {len(df)}\")\n",
    "        return None\n",
    "    \n",
    "    # Calculate alignment for each market\n",
    "    market_alignment = []\n",
    "    \n",
    "    for market_id, market_df in df.groupby('market_id'):\n",
    "        # Skip markets with too few trades or whales\n",
    "        if len(market_df) < 10 or market_df['trader_id'].nunique() < 2:\n",
    "            continue\n",
    "        \n",
    "        # Map directions to numeric values\n",
    "        market_df['direction'] = market_df[direction_col].map({'buy': 1, 'sell': -1})\n",
    "        \n",
    "        # Drop rows with missing direction\n",
    "        market_df = market_df.dropna(subset=['direction'])\n",
    "        \n",
    "        if len(market_df) < 10:\n",
    "            continue\n",
    "        \n",
    "        # Calculate the average direction for each whale\n",
    "        whale_sentiments = market_df.groupby('trader_id')['direction'].mean()\n",
    "        \n",
    "        # Calculate alignment metrics\n",
    "        alignment_score = whale_sentiments.mean()  # How aligned are whales overall?\n",
    "        \n",
    "        # Consensus strength: how much do whales agree with each other?\n",
    "        # 1 = perfect agreement, 0 = complete disagreement\n",
    "        consensus_strength = np.abs(alignment_score)\n",
    "        \n",
    "        # Are whales mostly buying or selling?\n",
    "        sentiment = \"Bullish\" if alignment_score > 0 else \"Bearish\"\n",
    "        \n",
    "        # Calculate pairwise correlations between whale directions\n",
    "        if len(whale_sentiments) >= 3:\n",
    "            # Create time series of directions for each whale\n",
    "            if 'timestamp' in market_df.columns:\n",
    "                if not pd.api.types.is_datetime64_any_dtype(market_df['timestamp']):\n",
    "                    market_df['timestamp'] = pd.to_datetime(market_df['timestamp'], errors='coerce')\n",
    "                \n",
    "                pivot = market_df.pivot_table(\n",
    "                    index='timestamp',\n",
    "                    columns='trader_id',\n",
    "                    values='direction',\n",
    "                    aggfunc='last'\n",
    "                )\n",
    "                \n",
    "                # Calculate correlation matrix\n",
    "                corr_matrix = pivot.corr()\n",
    "                \n",
    "                # Extract upper triangle (excluding diagonal)\n",
    "                upper_triangle = np.triu(corr_matrix.values, k=1)\n",
    "                \n",
    "                # Calculate average pairwise correlation\n",
    "                avg_pairwise_corr = np.nanmean(upper_triangle) if np.sum(~np.isnan(upper_triangle)) > 0 else np.nan\n",
    "            else:\n",
    "                avg_pairwise_corr = np.nan\n",
    "        else:\n",
    "            avg_pairwise_corr = np.nan\n",
    "        \n",
    "        market_alignment.append({\n",
    "            'market_id': market_id,\n",
    "            'unique_whales': market_df['trader_id'].nunique(),\n",
    "            'total_whale_trades': len(market_df),\n",
    "            'alignment_score': alignment_score,\n",
    "            'consensus_strength': consensus_strength,\n",
    "            'sentiment': sentiment,\n",
    "            'avg_pairwise_correlation': avg_pairwise_corr\n",
    "        })\n",
    "    \n",
    "    # Check if we have alignment data\n",
    "    if not market_alignment:\n",
    "        print(\"No markets with sufficient data for alignment analysis\")\n",
    "        return None\n",
    "    \n",
    "    # Convert to DataFrame\n",
    "    alignment_df = pd.DataFrame(market_alignment)\n",
    "    \n",
    "    # Calculate summary statistics\n",
    "    avg_consensus = alignment_df['consensus_strength'].mean()\n",
    "    avg_pairwise_corr = alignment_df['avg_pairwise_correlation'].mean()\n",
    "    \n",
    "    print(f\"Average whale consensus strength: {avg_consensus:.4f}\")\n",
    "    print(f\"Average pairwise correlation between whales: {avg_pairwise_corr:.4f}\")\n",
    "    \n",
    "    # Count bullish vs bearish markets\n",
    "    bullish_markets = (alignment_df['alignment_score'] > 0).sum()\n",
    "    bearish_markets = (alignment_df['alignment_score'] < 0).sum()\n",
    "    \n",
    "    bullish_pct = bullish_markets / len(alignment_df) * 100\n",
    "    print(f\"Whales are bullish in {bullish_pct:.1f}% of markets\")\n",
    "    \n",
    "    # Create visualization\n",
    "    plt.figure(figsize=(15, 10))\n",
    "    \n",
    "    # 1. Consensus strength distribution\n",
    "    plt.subplot(2, 1, 1)\n",
    "    \n",
    "    plt.hist(alignment_df['consensus_strength'], bins=20, alpha=0.7)\n",
    "    plt.axvline(x=avg_consensus, color='r', linestyle='--', \n",
    "               label=f'Average consensus: {avg_consensus:.4f}')\n",
    "    \n",
    "    plt.title('Whale Consensus Strength Distribution')\n",
    "    plt.xlabel('Consensus Strength (0=Disagreement, 1=Agreement)')\n",
    "    plt.ylabel('Number of Markets')\n",
    "    plt.legend()\n",
    "    plt.grid(alpha=0.3)\n",
    "    \n",
    "    # 2. Pairwise correlation distribution\n",
    "    plt.subplot(2, 1, 2)\n",
    "    \n",
    "    non_nan_corrs = alignment_df['avg_pairwise_correlation'].dropna()\n",
    "    if len(non_nan_corrs) > 0:\n",
    "        plt.hist(non_nan_corrs, bins=20, alpha=0.7)\n",
    "        plt.axvline(x=avg_pairwise_corr, color='r', linestyle='--', \n",
    "                   label=f'Average correlation: {avg_pairwise_corr:.4f}')\n",
    "        \n",
    "        plt.title('Whale Pairwise Correlation Distribution')\n",
    "        plt.xlabel('Average Pairwise Correlation')\n",
    "        plt.ylabel('Number of Markets')\n",
    "        plt.legend()\n",
    "        plt.grid(alpha=0.3)\n",
    "    else:\n",
    "        plt.text(0.5, 0.5, \"Insufficient data for pairwise correlation analysis\", \n",
    "                ha='center', va='center', fontsize=12)\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('whale_sentiment_alignment.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(\"Whale sentiment alignment visualization saved to whale_sentiment_alignment.png\")\n",
    "    \n",
    "    return {\n",
    "        'market_alignment': alignment_df.to_dict('records'),\n",
    "        'avg_consensus_strength': avg_consensus,\n",
    "        'avg_pairwise_correlation': avg_pairwise_corr,\n",
    "        'bullish_markets_pct': bullish_pct\n",
    "    }"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "826fca15",
   "metadata": {},
   "source": [
    "# Lorenz Curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "a55493c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lorenz_curve_visualization(whale_analysis_df):\n",
    "    \"\"\"\n",
    "    Create Lorenz curve visualization for trader volume distribution\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    whale_analysis_df : pd.DataFrame\n",
    "        DataFrame with trader volume analysis\n",
    "    \"\"\"\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    \n",
    "    # Sort traders by volume\n",
    "    df = whale_analysis_df.sort_values('volume')\n",
    "    \n",
    "    # Calculate cumulative percentages\n",
    "    df['trader_pct'] = np.arange(1, len(df) + 1) / len(df) * 100\n",
    "    df['volume_pct'] = df['volume'].cumsum() / df['volume'].sum() * 100\n",
    "    \n",
    "    # Plot Lorenz curve\n",
    "    plt.plot(df['trader_pct'], df['volume_pct'], label='Trading volume distribution')\n",
    "    \n",
    "    # Plot line of equality\n",
    "    plt.plot([0, 100], [0, 100], 'k--', label='Perfect equality')\n",
    "    \n",
    "    # Fill the area representing the Gini coefficient\n",
    "    plt.fill_between(df['trader_pct'], df['trader_pct'], df['volume_pct'], alpha=0.2)\n",
    "    \n",
    "    # Calculate Gini coefficient\n",
    "    gini = 1 - np.trapz(df['volume_pct'], df['trader_pct']) / 5000  # Area under perfect equality is 5000 (100*100/2)\n",
    "    \n",
    "    # Add key percentiles\n",
    "    percentiles = [90, 95, 99, 99.9]\n",
    "    for p in percentiles:\n",
    "        threshold_idx = int(len(df) * (100 - p) / 100)\n",
    "        if threshold_idx < len(df):\n",
    "            x = df['trader_pct'].iloc[threshold_idx]\n",
    "            y = df['volume_pct'].iloc[threshold_idx]\n",
    "            plt.plot([x, x], [0, y], 'r--', alpha=0.5)\n",
    "            plt.plot([0, x], [y, y], 'r--', alpha=0.5)\n",
    "            plt.text(x + 1, y - 5, f'Top {100-p}%', fontsize=10)\n",
    "    \n",
    "    plt.title(f'Trading Volume Distribution (Gini Coefficient: {gini:.4f})')\n",
    "    plt.xlabel('Cumulative % of Traders')\n",
    "    plt.ylabel('Cumulative % of Volume')\n",
    "    plt.grid(alpha=0.3)\n",
    "    plt.legend()\n",
    "    \n",
    "    plt.tight_layout()\n",
    "    plt.savefig('trading_volume_lorenz.png', dpi=300)\n",
    "    plt.close()\n",
    "    \n",
    "    print(f\"Lorenz curve visualization saved as trading_volume_lorenz.png\")\n",
    "    return gini"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a73e0d4",
   "metadata": {},
   "source": [
    "# Run Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "f91bb8bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_whale_analysis_pipeline(trades_df, generate_plots=True):\n",
    "    \"\"\"\n",
    "    Run the complete whale analysis pipeline\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    generate_plots : bool\n",
    "        Whether to generate visualization plots\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with all analysis results\n",
    "    \"\"\"\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"COMPREHENSIVE WHALE TRADER ANALYSIS\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Step 1: Scale trade volumes\n",
    "    print(\"\\n1. SCALING TRADE VOLUMES\")\n",
    "    print(\"-\"*40)\n",
    "    cleaned_trades = scale_trade_volume(trades_df)\n",
    "    \n",
    "    # Step 2: Identify whales\n",
    "    print(\"\\n2. IDENTIFYING WHALE TRADERS\")\n",
    "    print(\"-\"*40)\n",
    "    whale_ids, whale_def_results = identify_whales(cleaned_trades, default_threshold=0.01, generate_plots=generate_plots)\n",
    "    \n",
    "    # Step 3: Visualize trading inequality\n",
    "    print(\"\\n3. ANALYZING TRADING INEQUALITY\")\n",
    "    print(\"-\"*40)\n",
    "    if 'trader_analysis' in whale_def_results:\n",
    "        inequality_results = visualize_trading_inequality(whale_def_results['trader_analysis'])\n",
    "    else:\n",
    "        print(\"Skipping inequality visualization as trader analysis is not available\")\n",
    "        inequality_results = None\n",
    "    \n",
    "    # Step 4: Analyze whale impact\n",
    "    print(\"\\n4. ANALYZING WHALE TRADE IMPACT\")\n",
    "    print(\"-\"*40)\n",
    "    impact_results = analyze_whale_impact(cleaned_trades, whale_ids)\n",
    "    \n",
    "    # Step 5: Analyze temporal behavior\n",
    "    print(\"\\n5. ANALYZING TEMPORAL TRADING PATTERNS\")\n",
    "    print(\"-\"*40)\n",
    "    time_results = analyze_trader_behavior_over_time(cleaned_trades, whale_ids)\n",
    "    \n",
    "    # Step 6: Analyze whale alignment\n",
    "    print(\"\\n6. ANALYZING WHALE SENTIMENT ALIGNMENT\")\n",
    "    print(\"-\"*40)\n",
    "    alignment_results = analyze_whale_sentiment_alignment(cleaned_trades, whale_ids)\n",
    "    \n",
    "    # Combine results\n",
    "    all_results = {\n",
    "        'whale_definition': whale_def_results,\n",
    "        'inequality': inequality_results,\n",
    "        'price_impact': impact_results,\n",
    "        'temporal': time_results,\n",
    "        'alignment': alignment_results\n",
    "    }\n",
    "    \n",
    "    # Generate summary report\n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"WHALE ANALYSIS SUMMARY\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    # Summarize whale definition\n",
    "    if whale_def_results:\n",
    "        print(f\"\\nWhale Definition: Top {whale_def_results['selected_threshold']*100:.1f}% of traders\")\n",
    "        print(f\"Number of Whales: {whale_def_results['selected_num_whales']:,}\")\n",
    "        \n",
    "    # Summarize inequality\n",
    "    if inequality_results:\n",
    "        print(f\"\\nTrading Inequality (Gini): {inequality_results['gini']:.4f}\")\n",
    "        for p in [99, 95, 90]:\n",
    "            if p in inequality_results['percentile_data']:\n",
    "                data = inequality_results['percentile_data'][p]\n",
    "                print(f\"Top {100-p:.1f}% of traders control {data['volume_share']:.2f}% of volume\")\n",
    "    \n",
    "    # Summarize price impact\n",
    "    if impact_results:\n",
    "        if 'weighted_whale_impact' in impact_results:\n",
    "            print(f\"\\nWeighted Average Whale Price Impact: {impact_results['weighted_whale_impact']:.6f}\")\n",
    "            print(f\"Weighted Average Non-Whale Price Impact: {impact_results['weighted_non_whale_impact']:.6f}\")\n",
    "            if impact_results['impact_ratio']:\n",
    "                print(f\"Impact Ratio (Whale/Non-Whale): {impact_results['impact_ratio']:.4f}\")\n",
    "        elif 'whale_impact' in impact_results:\n",
    "            print(f\"\\nWhale Average Price Change: {impact_results['whale_impact']['avg_change']:.6f}\")\n",
    "            print(f\"Non-Whale Average Price Change: {impact_results['non_whale_impact']['avg_change']:.6f}\")\n",
    "        \n",
    "        if 'following_ratio' in impact_results and impact_results['following_ratio']:\n",
    "            print(f\"Non-Whales Follow Whale Direction: {impact_results['following_ratio']:.2%} of the time\")\n",
    "    \n",
    "    # Summarize temporal patterns\n",
    "    if time_results:\n",
    "        if 'activity_correlation' in time_results and time_results['activity_correlation']:\n",
    "            print(f\"\\nWhale/Non-Whale Activity Correlation: {time_results['activity_correlation']:.4f}\")\n",
    "        \n",
    "        if 'whale_lead_correlation' in time_results and 'nonwhale_lead_correlation' in time_results:\n",
    "            lead_type = \"Whales\" if time_results['whale_lead_correlation'] > time_results['nonwhale_lead_correlation'] else \"Non-whales\"\n",
    "            print(f\"Leading Influence: {lead_type} appear to lead trading activity\")\n",
    "    \n",
    "    # Summarize alignment\n",
    "    if alignment_results:\n",
    "        print(f\"\\nWhale Consensus Strength: {alignment_results['avg_consensus_strength']:.4f}\")\n",
    "        print(f\"Whale Pairwise Correlation: {alignment_results['avg_pairwise_correlation']:.4f}\")\n",
    "        print(f\"Bullish Sentiment: {alignment_results['bullish_markets_pct']:.1f}% of markets\")\n",
    "    \n",
    "    print(\"\\n\" + \"=\"*80)\n",
    "    print(\"Analysis Complete. All visualizations saved.\")\n",
    "    print(\"=\"*80)\n",
    "    \n",
    "    return all_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d0061f84",
   "metadata": {},
   "source": [
    "# 4. Trader Classification\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "694eca45",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def classify_traders(trades_df):\n",
    "    \"\"\"\n",
    "    Classify traders based on their trading behavior\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    \n",
    "    Returns:\n",
    "    --------\n",
    "    pd.DataFrame\n",
    "        Trader classification results\n",
    "    \"\"\"\n",
    "    # Calculate trader metrics\n",
    "    trader_metrics = trades_df.groupby('trader_id').agg({\n",
    "        'trade_amount': ['sum', 'mean', 'count'],\n",
    "        'price': ['mean', 'std']\n",
    "    }).reset_index()\n",
    "    \n",
    "    # Flatten column names\n",
    "    trader_metrics.columns = ['trader_id', 'total_volume', 'avg_trade_size', 'trade_count', \n",
    "                               'avg_price', 'price_volatility']\n",
    "    \n",
    "    # Add classification logic\n",
    "    def classify_trader(row):\n",
    "        if row['total_volume'] > trader_metrics['total_volume'].quantile(0.95):\n",
    "            return 'Whale'\n",
    "        elif row['trade_count'] > trader_metrics['trade_count'].quantile(0.8):\n",
    "            return 'Active Trader'\n",
    "        elif row['avg_trade_size'] > trader_metrics['avg_trade_size'].quantile(0.8):\n",
    "            return 'Large Trade Trader'\n",
    "        else:\n",
    "            return 'Casual Trader'\n",
    "    \n",
    "    trader_metrics['trader_type'] = trader_metrics.apply(classify_trader, axis=1)\n",
    "    \n",
    "    # Print classification summary\n",
    "    print(\"\\nTrader Classification:\")\n",
    "    print(trader_metrics['trader_type'].value_counts(normalize=True))\n",
    "    \n",
    "    return trader_metrics\n",
    "\n",
    "# Classify traders\n",
    "trader_classification = classify_traders(trade_data)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55083382",
   "metadata": {},
   "source": [
    "\n",
    "# 5. Market Dynamics Visualization\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dcf433d2",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "plt.figure(figsize=(15, 10))\n",
    "\n",
    "# Trader Volume Distribution\n",
    "plt.subplot(2, 2, 1)\n",
    "sns.histplot(trader_classification['total_volume'], bins=50, kde=True)\n",
    "plt.title('Trader Volume Distribution')\n",
    "plt.xlabel('Total Trading Volume')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "# Trader Type Distribution\n",
    "plt.subplot(2, 2, 2)\n",
    "trader_classification['trader_type'].value_counts().plot(kind='pie', autopct='%1.1f%%')\n",
    "plt.title('Trader Type Distribution')\n",
    "\n",
    "# Price Changes by Trader Type\n",
    "plt.subplot(2, 2, 3)\n",
    "sns.boxplot(x='trader_type', y='total_volume', data=trader_classification)\n",
    "plt.title('Volume by Trader Type')\n",
    "plt.xticks(rotation=45)\n",
    "\n",
    "# Trade Frequency Distribution\n",
    "plt.subplot(2, 2, 4)\n",
    "sns.histplot(trader_classification['trade_count'], bins=50, kde=True)\n",
    "plt.title('Trade Frequency Distribution')\n",
    "plt.xlabel('Number of Trades')\n",
    "plt.ylabel('Frequency')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig('trader_analysis_plots.png')\n",
    "plt.close()\n",
    "\n",
    "print(\"\\nAnalysis complete. Visualization saved as trader_analysis_plots.png\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c324bc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_traders(trades_df, n_clusters=5):\n",
    "    \"\"\"\n",
    "    Classify traders into different types based on their behavior\n",
    "    \n",
    "    Parameters:\n",
    "    -----------\n",
    "    trades_df : pd.DataFrame\n",
    "        DataFrame with trade data\n",
    "    n_clusters : int\n",
    "        Number of clusters to create\n",
    "        \n",
    "    Returns:\n",
    "    --------\n",
    "    dict\n",
    "        Dictionary with classification results\n",
    "    \"\"\"\n",
    "    # Create a combined trader ID using both maker and taker\n",
    "    if 'maker_id' in trades_df.columns and 'taker_id' in trades_df.columns:\n",
    "        # Get all unique trader IDs from both maker and taker columns\n",
    "        all_traders = set(trades_df['maker_id'].dropna().unique()) | set(trades_df['taker_id'].dropna().unique())\n",
    "        all_trader_ids = list(all_traders)\n",
    "        \n",
    "        print(f\"Analyzing {len(all_trader_ids)} unique traders from maker/taker columns\")\n",
    "    elif 'trader_id' in trades_df.columns:\n",
    "        all_trader_ids = trades_df['trader_id'].unique()\n",
    "        print(f\"Analyzing {len(all_trader_ids)} unique traders from trader_id column\")\n",
    "    else:\n",
    "        print(\"Error: No trader identifier columns found\")\n",
    "        return None\n",
    "    \n",
    "    print(\"Calculating trader features...\")\n",
    "    \n",
    "    # Group by trader_id and calculate features\n",
    "    trader_features = []\n",
    "    \n",
    "    # For each trader, calculate features based on their maker and taker activities\n",
    "    for trader_id in all_trader_ids:\n",
    "        # Get all trades where this trader was involved (as maker or taker)\n",
    "        if 'maker_id' in trades_df.columns and 'taker_id' in trades_df.columns:\n",
    "            maker_trades = trades_df[trades_df['maker_id'] == trader_id]\n",
    "            taker_trades = trades_df[trades_df['taker_id'] == trader_id]\n",
    "            trader_trades = pd.concat([maker_trades, taker_trades]).drop_duplicates()\n",
    "        else:\n",
    "            trader_trades = trades_df[trades_df['trader_id'] == trader_id]\n",
    "        \n",
    "        # Skip traders with too few trades\n",
    "        if len(trader_trades) < 3:\n",
    "            continue\n",
    "            \n",
    "        # Basic activity metrics\n",
    "        trade_count = len(trader_trades)\n",
    "        \n",
    "        # Trade size metrics\n",
    "        if 'trade_amount' in trader_trades.columns:\n",
    "            avg_trade_size = trader_trades['trade_amount'].mean()\n",
    "            total_volume = trader_trades['trade_amount'].sum()\n",
    "            trade_size_volatility = trader_trades['trade_amount'].std() / avg_trade_size if avg_trade_size > 0 else 0\n",
    "        elif 'size' in trader_trades.columns:\n",
    "            avg_trade_size = trader_trades['size'].mean()\n",
    "            total_volume = trader_trades['size'].sum()\n",
    "            trade_size_volatility = trader_trades['size'].std() / avg_trade_size if avg_trade_size > 0 else 0\n",
    "        else:\n",
    "            avg_trade_size = np.nan\n",
    "            total_volume = np.nan\n",
    "            trade_size_volatility = np.nan\n",
    "        \n",
    "        # Trader diversity (market participation)\n",
    "        if 'market_id' in trader_trades.columns:\n",
    "            market_count = trader_trades['market_id'].nunique()\n",
    "            market_concentration = (trader_trades.groupby('market_id').size() / trade_count).max()\n",
    "        else:\n",
    "            market_count = 1\n",
    "            market_concentration = 1.0\n",
    "            \n",
    "        # Trading frequency\n",
    "        if 'timestamp' in trader_trades.columns:\n",
    "            trader_trades = trader_trades.sort_values('timestamp')\n",
    "            if len(trader_trades) > 1:\n",
    "                # Convert timestamp to datetime if it's not already\n",
    "                if not pd.api.types.is_datetime64_any_dtype(trader_trades['timestamp']):\n",
    "                    trader_trades['timestamp'] = pd.to_datetime(trader_trades['timestamp'])\n",
    "                \n",
    "                # Calculate time between trades in minutes\n",
    "                time_diffs = trader_trades['timestamp'].diff().dropna()\n",
    "                if len(time_diffs) > 0:\n",
    "                    try:\n",
    "                        avg_time_between_trades = time_diffs.mean().total_seconds() / 60\n",
    "                        trade_timing_regularity = time_diffs.std().total_seconds() / avg_time_between_trades if avg_time_between_trades > 0 else np.nan\n",
    "                    except:\n",
    "                        avg_time_between_trades = np.nan\n",
    "                        trade_timing_regularity = np.nan\n",
    "                else:\n",
    "                    avg_time_between_trades = np.nan\n",
    "                    trade_timing_regularity = np.nan\n",
    "            else:\n",
    "                avg_time_between_trades = np.nan\n",
    "                trade_timing_regularity = np.nan\n",
    "        else:\n",
    "            avg_time_between_trades = np.nan\n",
    "            trade_timing_regularity = np.nan\n",
    "            \n",
    "        # Trading direction bias\n",
    "        if 'side' in trader_trades.columns:\n",
    "            buy_count = (trader_trades['side'] == 'buy').sum()\n",
    "            sell_count = (trader_trades['side'] == 'sell').sum()\n",
    "            if buy_count + sell_count > 0:\n",
    "                buy_ratio = buy_count / (buy_count + sell_count)\n",
    "            else:\n",
    "                buy_ratio = 0.5\n",
    "        elif 'trade_direction' in trader_trades.columns:\n",
    "            buy_count = (trader_trades['trade_direction'] == 'buy').sum()\n",
    "            sell_count = (trader_trades['trade_direction'] == 'sell').sum()\n",
    "            if buy_count + sell_count > 0:\n",
    "                buy_ratio = buy_count / (buy_count + sell_count)\n",
    "            else:\n",
    "                buy_ratio = 0.5\n",
    "        else:\n",
    "            buy_ratio = 0.5\n",
    "            \n",
    "        # Store features\n",
    "        trader_features.append({\n",
    "            'trader_id': trader_id,\n",
    "            'trade_count': trade_count,\n",
    "            'avg_trade_size': avg_trade_size,\n",
    "            'total_volume': total_volume,\n",
    "            'trade_size_volatility': trade_size_volatility,\n",
    "            'market_count': market_count,\n",
    "            'market_concentration': market_concentration,\n",
    "            'avg_time_between_trades': avg_time_between_trades,\n",
    "            'trade_timing_regularity': trade_timing_regularity,\n",
    "            'buy_ratio': buy_ratio\n",
    "        })\n",
    "    \n",
    "    if not trader_features:\n",
    "        print(\"No trader features calculated\")\n",
    "        return None\n",
    "        \n",
    "    # Create DataFrame\n",
    "    trader_df = pd.DataFrame(trader_features)\n",
    "    print(f\"Calculated features for {len(trader_df)} traders\")\n",
    "    \n",
    "    # Select features for clustering\n",
    "    features_for_clustering = [\n",
    "        'trade_count', 'avg_trade_size', 'market_concentration', \n",
    "        'buy_ratio', 'trade_size_volatility'\n",
    "    ]\n",
    "    \n",
    "    # Filter to available features and remove any with all NaN values\n",
    "    available_features = []\n",
    "    for f in features_for_clustering:\n",
    "        if f in trader_df.columns and not trader_df[f].isna().all():\n",
    "            available_features.append(f)\n",
    "    \n",
    "    print(f\"Using {len(available_features)} features for clustering: {available_features}\")\n",
    "    \n",
    "    if len(available_features) < 2:\n",
    "        print(\"Insufficient features for clustering\")\n",
    "        return None\n",
    "        \n",
    "    # Handle missing values\n",
    "    X = trader_df[available_features].copy()\n",
    "    X = X.fillna(X.mean())\n",
    "    \n",
    "    # Standardize features\n",
    "    scaler = StandardScaler()\n",
    "    X_scaled = scaler.fit_transform(X)\n",
    "    \n",
    "    print(\"Performing clustering...\")\n",
    "    \n",
    "    # Apply K-means clustering\n",
    "    kmeans = KMeans(n_clusters=n_clusters, random_state=42, n_init=10)\n",
    "    trader_df['cluster'] = kmeans.fit_predict(X_scaled)\n",
    "    \n",
    "    # Calculate cluster profiles\n",
    "    cluster_profiles = trader_df.groupby('cluster')[available_features].mean()\n",
    "    cluster_sizes = trader_df['cluster'].value_counts().sort_index()\n",
    "    cluster_profiles['size'] = cluster_sizes.values\n",
    "    cluster_profiles['percentage'] = 100 * cluster_sizes / cluster_sizes.sum()\n",
    "    \n",
    "    # Interpret clusters\n",
    "    cluster_names = {}\n",
    "    for cluster_id in range(n_clusters):\n",
    "        profile = cluster_profiles.loc[cluster_id]\n",
    "        \n",
    "        # Calculate z-scores for this cluster compared to others\n",
    "        z_scores = {}\n",
    "        for feature in available_features:\n",
    "            feature_mean = cluster_profiles[feature].mean()\n",
    "            feature_std = cluster_profiles[feature].std()\n",
    "            if feature_std > 0:\n",
    "                z_scores[feature] = (profile[feature] - feature_mean) / feature_std\n",
    "            else:\n",
    "                z_scores[feature] = 0\n",
    "                \n",
    "        # Determine cluster type based on most extreme z-scores\n",
    "        top_feature = max(z_scores.items(), key=lambda x: abs(x[1]))\n",
    "        \n",
    "        if top_feature[0] == 'trade_count' and top_feature[1] > 1:\n",
    "            name = \"High Frequency Traders\"\n",
    "        elif top_feature[0] == 'avg_trade_size' and top_feature[1] > 1:\n",
    "            name = \"Whale Traders\"\n",
    "        elif top_feature[0] == 'market_concentration' and top_feature[1] > 1:\n",
    "            name = \"Market Specialists\" \n",
    "        elif top_feature[0] == 'buy_ratio':\n",
    "            if top_feature[1] > 1:\n",
    "                name = \"Bullish Traders\"\n",
    "            else:\n",
    "                name = \"Bearish Traders\"\n",
    "        elif top_feature[0] == 'trade_size_volatility' and top_feature[1] > 1:\n",
    "            name = \"Opportunistic Traders\"\n",
    "        else:\n",
    "            name = \"Balanced Traders\"\n",
    "            \n",
    "        cluster_names[cluster_id] = name\n",
    "    \n",
    "    # Add names to profiles\n",
    "    cluster_profiles['type'] = [cluster_names[i] for i in cluster_profiles.index]\n",
    "    \n",
    "    # Create visualizations\n",
    "    \n",
    "    # 1. PCA visualization of clusters\n",
    "    if len(available_features) >= 2:\n",
    "        pca = PCA(n_components=2)\n",
    "        X_pca = pca.fit_transform(X_scaled)\n",
    "        \n",
    "        # Create visualization DataFrame\n",
    "        viz_df = pd.DataFrame({\n",
    "            'PC1': X_pca[:, 0],\n",
    "            'PC2': X_pca[:, 1],\n",
    "            'Cluster': trader_df['cluster'],\n",
    "            'Type': trader_df['cluster'].map(cluster_names)\n",
    "        })\n",
    "        \n",
    "        # Calculate explained variance\n",
    "        explained_variance = pca.explained_variance_ratio_\n",
    "        \n",
    "        # Create PCA plot\n",
    "        plt.figure(figsize=(10, 8))\n",
    "        sns.scatterplot(data=viz_df, x='PC1', y='PC2', hue='Type', palette='viridis', s=50, alpha=0.7)\n",
    "        plt.title('Trader Types - PCA Visualization')\n",
    "        plt.xlabel(f'PC1 ({explained_variance[0]:.1%} variance)')\n",
    "        plt.ylabel(f'PC2 ({explained_variance[1]:.1%} variance)')\n",
    "        plt.legend(bbox_to_anchor=(1.05, 1), loc='upper left')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, 'trader_clusters_pca.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 2. Radar chart of cluster profiles\n",
    "        plt.figure(figsize=(12, 10))\n",
    "        \n",
    "        # Normalize profiles for radar chart\n",
    "        radar_df = cluster_profiles[available_features].copy()\n",
    "        for feature in available_features:\n",
    "            feature_max = radar_df[feature].max()\n",
    "            if feature_max > 0:\n",
    "                radar_df[feature] = radar_df[feature] / feature_max\n",
    "                \n",
    "        # Number of features\n",
    "        N = len(available_features)\n",
    "        \n",
    "        # Create angles for radar chart\n",
    "        angles = np.linspace(0, 2*np.pi, N, endpoint=False).tolist()\n",
    "        angles += angles[:1]  # Close the loop\n",
    "        \n",
    "        # Create subplot with polar projection\n",
    "        ax = plt.subplot(111, polar=True)\n",
    "        \n",
    "        # Add feature labels\n",
    "        plt.xticks(angles[:-1], available_features, size=12)\n",
    "        \n",
    "        # Plot each cluster\n",
    "        for cluster_id, name in cluster_names.items():\n",
    "            values = radar_df.loc[cluster_id].tolist()\n",
    "            values += values[:1]  # Close the loop\n",
    "            \n",
    "            ax.plot(angles, values, linewidth=2, label=name)\n",
    "            ax.fill(angles, values, alpha=0.1)\n",
    "            \n",
    "        plt.title('Trader Type Profiles', size=15)\n",
    "        plt.legend(loc='upper right', bbox_to_anchor=(0.1, 0.1))\n",
    "        plt.savefig(os.path.join(results_dir, 'trader_type_radar.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "        \n",
    "        # 3. Bar chart of cluster sizes\n",
    "        plt.figure(figsize=(12, 6))\n",
    "        \n",
    "        # Sort by size\n",
    "        sorted_profiles = cluster_profiles.sort_values('size', ascending=False)\n",
    "        \n",
    "        # Create bar chart\n",
    "        plt.bar(\n",
    "            range(len(sorted_profiles)), \n",
    "            sorted_profiles['size'],\n",
    "            tick_label=[f\"{cluster_names[i]}\\n({sorted_profiles.loc[i, 'percentage']:.1f}%)\" \n",
    "                       for i in sorted_profiles.index]\n",
    "        )\n",
    "        \n",
    "        plt.title('Trader Type Distribution')\n",
    "        plt.ylabel('Number of Traders')\n",
    "        plt.tight_layout()\n",
    "        plt.savefig(os.path.join(results_dir, 'trader_type_distribution.png'), dpi=300, bbox_inches='tight')\n",
    "        plt.close()\n",
    "    \n",
    "    return {\n",
    "        'trader_features': trader_df,\n",
    "        'cluster_profiles': cluster_profiles,\n",
    "        'cluster_names': cluster_names,\n",
    "        'feature_importance': feature_importance\n",
    "    }"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
